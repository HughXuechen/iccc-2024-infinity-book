 
 
 
 
I 
 
 
 
 
Filmmaking of the Future: A Co-Design-Led Investigation 
Into the Potential of Immersive Technologies to Enhance 
the Small and Medium Audiovisual Production Processes 
 
A Thesis Submitted for the Degree of Doctor of Philosophy 
 
 
 
By 
 
Aimone Bodini 
 
 
 
 
Department of Design 
 
College of Engineering, Design and Physical Sciences 
 
Brunel University London 
 
 
 
 
 
 
II 
Abstract 
In common with many other fields, the audiovisual (AV) industry is being transformed 
by the use of real-time graphics engines in combination with immersive technologies 
such as virtual reality (VR) and augmented reality (AR). This technological mixture 
enables what is known as virtual production (VP) and introduces professionals to 
numerous new ways of creating AV content. 
  
However, VP is still in a relatively early stage and there are various barriers to 
democratization that must be overcome if these technologies are to become widely 
used in the industry. Specifically, there is a need to promote and identify the best 
ways to facilitate the uptake of the technologies within the context of independent 
small and medium productions (SMPs).  
 
The main aim underscoring this PhD project is to investigate how VP can enhance 
the process of independent SMPs; the key output is a set of recommendations for 
implementing VP into current production practices.  
 
Recommendations are based upon a new VP process that focuses on immersive 
pre-visualization of filming locations. This process is enabled by using affordable, 
accessible, and easy-to-use immersive technologies to support creativity, 
communication, and collaboration during the pre-production phase of an AV product. 
 
Unlike previous studies in the field, this work was performed by adopting a co-design 
approach whereby professionals were actively engaged in and contributed to the 
research by sharing their valuable knowledge, creative ideas, and feedback. The 
overall methodological framework adopted to develop the research was design 
research methodology (DRM). 
 
The PhD project comprises five consecutive and interdependent studies: 
 
In the first study, the working habits, challenges, and perceptions towards VP were 
explored through a series of semi-structured interviews with professionals who 
 
 
 
 
III 
performed different roles within SMPs. This stage contributed to the initial 
understanding of the SMPs' operational context and the identification of the basic 
user requirements for adopting VP. 
 
The second study involved a new sample of professionals who engaged in a series 
of remote co-design workshops that validated the findings from the previous stage. 
This study also introduced into the project the method of design fiction, a process in 
which participants are prompted to conceptualise possible and probable ideas for the 
future use of VP in their work. This second study generated 14 initial scenarios on 
how alternative VP processes can benefit SMPs.  
 
In the third study, ideas from the second study were merged and extended into three 
highly detailed design fiction scenarios that were presented in an online 
questionnaire. The data collected from professionals who responded to the 
questionnaire allowed to identify the scenario considered to be the most valuable 
and worthwhile of being developed in practice.   
 
In the fourth study, a practical prototype was designed and developed based on the 
detailed scenario from the third study to aid professionals in the pre-production 
phase of an AV project. The prototype was then evaluated in person by different 
teams of professionals who employed it in a simulated alternative VP-enabled 
process. The prototype and process were seen as useful and ready to be 
implemented in a real-world environment.  
 
The fifth study encompassed the final stage of the project, which involved self-
reflection on the practical prototype as well as the process developed and evaluated 
in the fourth study. Accordingly, a set of recommendations based on the all the 
previous studies, was generated for the design of future VP processes for SMPs. 
 
Overall, this exploratory research contributes to better understanding of an emerging 
area of investigation – VP applied to SMPs – and highlights the urgency for further 
research activities.  
 
 
 
 
IV 
 
Keywords: Audiovisual Production, Co-Design, Design Fiction, Virtual Reality, 
Augmented Reality, Virtual Production, Location Scouting 
 
 
 
 
 
 
 
 
V 
Declaration 
 
I declare that this thesis was written by myself, Aimone Bodini, that the work 
contained herein is my own except where explicitly stated otherwise in the text. I 
declare that this work has not been submitted for any other degree or professional 
qualification. 
 
Aimone Bodini  
April 2023 
 
 
 
 
 
 
VI 
Acknowledgements 
 
Undertaking this PhD has been a life-changing experience, and it would not have 
been possible without the support, guidance and help I have received from many 
different people. 
 
I would like to start by thanking my first supervisor Dr, Vanja Garaj, for his trust, 
support and inspiration during these years. I appreciate him for giving me a chance 
to undertake this journey at Brunel University and pushing me into uncharted waters. 
 
I am incredibly thankful to my advisor Dr Federico Colecchia, for his kindness and 
understanding throughout this ride, Dr Arthi Manohar for her purposefulness in 
exchanging ideas and perspectives and Prof. David Harrison for always encouraging 
me and empathising with the subject of such investigation.  
 
I am grateful for the value brought to the research by companies, professionals, 
professors, and students that contributed to my study and showed a genuine interest 
in what I was doing.  Special thanks, therefore, go out to Giacomo, Emanuele and 
Maddalena. I must also thank my Brunel colleagues and friends for sparking talks, 
contributing ideas, and providing support when needed. Special thanks also go to 
Vangelis and Andrea for being my two beacons of light. I would especially like to 
thank Carlson for his long-standing and visionary belief in me. Moreover, I would not 
have managed to pursue this journey without sharing it professionally with Laila, 
Alban, Lulu, Aseel and Claude. Dulcis in fundo, Simone and Vittorio, I am so lucky I 
met you. 
 
Thanks to Tiro Associates for the countless coffees alongside the significant 
sponsorship contribution from StoryFutures, as without this crucial input, this 
research would not have been possible. 
 
 
 
 
 
 
 
VII 
Starting this PhD under unprecedented circumstances characterised by a global 
pandemic, forcing solitary confinement, and so increasing the sense of loneliness 
that such commitment already implies was one of the biggest challenges I faced in 
my life. My dearest friends proved to be so lightening up the darkest fog present at 
times in my mind and heart. Gian Guido, Davide, Philippe, Flavio, Martina, Paolo, 
Marta, Angelica, Matteo, Galliano, Pietro, Gabriele, Luca, Ennio, Emiliano, Davide: 
thank you.  
 
To the future me: along the way, other adversities may occur, and this work must be 
a testimony of how they can be overcome. 
 
Finally, I dedicate this achievement to my parents, Elisabetta and Flavio, for their 
unconditional love. To my pillar and brother Edoardo. To my grandmothers Maria 
and Attilia for always raising my optimism towards things and my grandfathers Piero 
and Tullio, who will always be remembered. 
 
 
 
 
 
 
 
VIII 
Publications arising from this PhD 
 
Journal papers 
 
Bodini, A., Colecchia, F., Manohar, A., Harrison, D. and Garaj, V., 2023. Using 
immersive technologies to facilitate location scouting in audiovisual media 
production: a user requirements study and proposed framework. Multimedia Tools 
and Applications, pp.1-22 
 
Bodini, A., Colecchia, F., Manohar, A., Harrison, D. and Garaj, V., 2023. Envisioning 
the future of virtual production in filmmaking: A remote co-design study. Multimedia 
Tools and Applications 
 
Conferences, Talks and Panel Discussions 
 
“The Magic of Virtual Production”, Speaker, VRDays Europe, Amsterdam, 
Videoconference (Due to COVID-19), 4 - 6 November 2020. 
 
“Virtual Location Scouting: A new approach enabled by Real-Time engines, 
Immersive technologies and Digital Twins”, ECR Speaker, BEYOND 2020, Belfast, 
Videoconference (Due to COVID-19), 30 November - 03 December 2020. 
 
“AV Production inside the Metaverse - Draw me like pixels”, Panel Moderator, 
VRDays Europe, Amsterdam, 13 - 17 November 2021. 
 
“The Future of AV”, Advisor, VRDays Europe, Rotterdam, 28 November - 02 
December 2022. 
 
 
 
 
 
 
 
 
IX 
Table of Contents 
1. 
Introduction ...............................................................................................................................2 
1.1 The Ever-Evolving Relationship Between Filmmaking and Technology.......................................2 
1.1.1 Virtual Production: Many Forms, Many Possibilities ..............................................................3 
1.2 Virtual Production for All: Shifting the Focus to Small and Medium Productions .........................5 
1.3 Research Aims ..............................................................................................................................6 
1.4 Research Questions ......................................................................................................................6 
1.5 Research Objectives .....................................................................................................................7 
1.6 The StoryFutures Project...............................................................................................................8 
1.7 Structure of the Thesis ..................................................................................................................8 
2. 
Literature Review ....................................................................................................................12 
2.1 Introduction ..................................................................................................................................12 
2.1.1 Definition of Virtual Production .............................................................................................12 
2.1.2 Benefits of Virtual Production ...............................................................................................14 
2.2 Sources ........................................................................................................................................16 
2.3 Review .........................................................................................................................................19 
2.3.1 Premise ................................................................................................................................19 
2.3.2 Academia .............................................................................................................................20 
2.3.3 Industry .................................................................................................................................23 
2.3.3.1 High-End Productions ...................................................................................................24 
2.3.3.2 Small and Medium Productions ....................................................................................29 
2.4 Conclusion of the Literature Review............................................................................................32 
3. 
Methodology ............................................................................................................................38 
3.1 Introduction ..................................................................................................................................38 
3.2 Design Research Methodology Framework ................................................................................40 
3.2.1 Using and Adapting the Design Research Methodology Framework ..................................42 
3.3 Co-Design ....................................................................................................................................47 
3.4 Design Fiction ..............................................................................................................................50 
3.4.1 Diegetic Prototypes ..............................................................................................................52 
3.5 Study Design ...............................................................................................................................52 
3.5.1 Design Methods ...................................................................................................................52 
3.5.1.1 Interviews ......................................................................................................................53 
3.5.1.2 Workshops ....................................................................................................................54 
3.5.1.3 Questionnaire................................................................................................................55 
3.5.1.4 User Testing..................................................................................................................56 
 
 
 
 
X 
3.5.2 Data Analysis Methods ........................................................................................................56 
3.5.3 Sampling ..............................................................................................................................57 
3.5.4 Limitations Due to COVID-19 ...............................................................................................60 
3.6 Chapter Summary .......................................................................................................................60 
4. 
Exploratory Study (DS-I, PS-I) ...............................................................................................63 
4.1 Introduction ..................................................................................................................................63 
4.2 Aim ...............................................................................................................................................63 
4.3 Method .........................................................................................................................................63 
4.4 Participants ..................................................................................................................................64 
4.5 Procedure ....................................................................................................................................66 
4.6 Findings .......................................................................................................................................67 
4.7 Discussion (PS-I) .........................................................................................................................67 
4.7.1 Common Challenges............................................................................................................67 
4.7.2 Role-Specific Challenges .....................................................................................................68 
4.7.3 Participants’ Vision of Immersive Technologies in the AV Pre-Production Process ...........70 
4.7.4 Description of the conceptual workflow ...............................................................................74 
4.7.5 Feedback on the Proposed Conceptual Workflow and Additional Insights .........................77 
4.8 Chapter Summary .......................................................................................................................80 
5. 
Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) ................................................................82 
5.1 Introduction ..................................................................................................................................82 
5.2 Aim ...............................................................................................................................................82 
5.3 Participants ..................................................................................................................................85 
5.4 Procedure ....................................................................................................................................86 
5.4.1 First Workshop: Board Framework ......................................................................................88 
5.4.2 Self-Reflection Task Between the Two Workshops .............................................................92 
5.4.3 Second Workshop: Board Framework .................................................................................93 
5.5 Findings .......................................................................................................................................97 
5.5.1 First Workshop (DS-IIA) .......................................................................................................97 
5.5.2 Second Workshop (PS-II, DS-IIB)........................................................................................99 
5.6 Discussion ................................................................................................................................ 106 
5.7 Diegetic Prototypes (PS-III) ...................................................................................................... 108 
5.8 Chapter Summary .................................................................................................................... 113 
6. 
Idea Filtering and Iteration (DS-III) ..................................................................................... 115 
6.1 Introduction ............................................................................................................................... 115 
6.2 Aim ............................................................................................................................................ 115 
6.3 Participants ............................................................................................................................... 116 
6.4 Structure of the Questionnaire ................................................................................................. 116 
 
 
 
 
XI 
6.4.1 Diegetic Prototypes ........................................................................................................... 118 
6.4.2 Adapting the Technology Acceptance Model to This Study ............................................. 120 
6.4.3 Open-Ended Questions..................................................................................................... 122 
6.4.4 Self-Evaluation Questions ................................................................................................. 123 
6.4.5 Online Platform ................................................................................................................. 123 
6.4.5.1 Pilot ............................................................................................................................ 124 
6.5 Results ...................................................................................................................................... 124 
6.5.1 Profiling ............................................................................................................................. 124 
6.5.2 Main Outcomes ................................................................................................................. 125 
6.5.3 DEPERO Pain Points ........................................................................................................ 133 
6.5.4 Additional Features to Implement Within DEPERO .......................................................... 137 
6.6 Discussion ................................................................................................................................ 139 
6.7 Chapter Summary .................................................................................................................... 141 
7. 
Prototype Design (PS-IV) and Testing (DS-IV) .................................................................. 143 
7.1 Introduction ............................................................................................................................... 143 
7.2 Aim ............................................................................................................................................ 143 
7.3 Participants ............................................................................................................................... 143 
7.4 Prototype Design (PS-IV) ......................................................................................................... 147 
7.4.1 Convenience of Pre-Existing Technologies ...................................................................... 147 
7.4.1.1 Overview of VR Headsets.......................................................................................... 147 
7.4.1.2 Overview of Mobile Capturing Software .................................................................... 148 
7.4.1.3 Overview of Immersive Sketching Software .............................................................. 148 
7.4.2 Prototype Description ........................................................................................................ 150 
7.4.2.1 Capturing and Retrieving a Digital Replica of the Filming Location .......................... 150 
7.4.2.2 Immersive Pre-Production in the Digital Replica of the Filming Location ................. 151 
7.4.3 Virtual Locations ................................................................................................................ 152 
7.4.3.1 Location 01: La Casa Gassia (Demonstration) ......................................................... 153 
7.4.3.2 Location 02: Tower D (Practice) ................................................................................ 154 
7.4.3.3 Location 03: Mont-Saint-Michel (Practice) ................................................................ 156 
7.5 Prototype Testing (PS-IV)......................................................................................................... 158 
7.5.1 Procedure .......................................................................................................................... 159 
7.5.1.1 Preparation ................................................................................................................ 159 
7.5.1.2 Execution ................................................................................................................... 162 
7.5.2 Results and Discussion (DS-IV) ........................................................................................ 169 
7.5.2.1 Questionnaire Results ............................................................................................... 169 
7.5.2.2 Think-Aloud and Group Discussions ......................................................................... 171 
7.6 Sub-Prototype: Drone Digital Twin ........................................................................................... 180 
7.6.1 Definition of Digital Twins .................................................................................................. 181 
 
 
 
 
XII 
7.6.2 Experiment Design ............................................................................................................ 183 
7.6.3 Results .............................................................................................................................. 184 
7.6.4 Discussion ......................................................................................................................... 193 
7.7 Chapter Summary .................................................................................................................... 198 
8. 
Discussion and Recommendations ................................................................................... 200 
8.1 Research Output ...................................................................................................................... 200 
8.1.1 General Discussion ........................................................................................................... 200 
8.1.2 Discussion on the Final Practical Output .......................................................................... 203 
8.1.3 Recommendations for Virtual Production Applied to Small and Medium Productions ..... 210 
8.2 Research Process .................................................................................................................... 218 
8.2.1 Discussion of Essential Elements ..................................................................................... 218 
8.2.2  Methods Recommendations ............................................................................................ 221 
8.3 Chapter Summary .................................................................................................................... 222 
9. 
Conclusions and Future Work............................................................................................ 224 
9.1 Research Overview: Objectives and Outcomes....................................................................... 224 
9.1.1 Meeting the Objectives Set to Answer Research Question 1.1 ........................................ 226 
9.1.2 Meeting the Objectives Set to Answer Research Question 1.2 ........................................ 227 
9.1.3 Meeting the Objectives Set to Answer Research Question 1.3 ........................................ 227 
9.2 Research Contributions ............................................................................................................ 229 
9.3 Limitations................................................................................................................................. 234 
9.3.1 The Topic .......................................................................................................................... 234 
9.3.2 COVID-19 Pandemic......................................................................................................... 235 
9.3.3 Data Collection .................................................................................................................. 235 
9.3.3.1 Data Collection for DS-IIA and PS-II ......................................................................... 235 
9.3.3.2 The Role of the Researcher ...................................................................................... 236 
9.3.3.4 Geographic and Cultural Biases ................................................................................ 236 
9.3 
Suggestions for Future Work ............................................................................................. 237 
9.4.1 Adaptability ........................................................................................................................ 237 
9.4.2 Further Research Opportunities: Emerging Technologies ............................................... 239 
9.4 
Summary ........................................................................................................................... 242 
References ......................................................................................................................................... 243 
Appendix I – Diegetic Prototypes.................................................................................................... 268 
Appendix II – Online Questionnaire ................................................................................................ 277 
Appendix III – User Testing Procedure ........................................................................................... 307 
Appendix IV – Ethical approvals and participant information sheets......................................... 320 
 
 
 
 
XIII 
Appendix V – Images Miscellaneous .............................................................................................. 330 
 
 
 
 
 
 
 
XIV 
List of Figures 
 
Figure 1.1 Outline of the Thesis .............................................................................................................10 
Figure 2.1 Green Screen Studio (top) and Stagecraft LED Volume (bottom) .......................................15 
Figure 2.2 Stage Appearance to Players (left) and Viewers (right) .......................................................29 
Figure 2.3 Adaptation of the Long Tail Concept (Anderson, 2004) .......................................................35 
Figure 3.1 Four Elements of the Design Process (Crotty, 1998)...........................................................38 
Figure 3.2 Design Research Methodology Framework (Blessing & Chakrabarti, 2009).......................41 
Figure 3.3 Research Methodology: Stages, Activities, Methods, and Outcomes (part one) ................44 
Figure 3.4 Research Methodology: Stages, Activities, Methods, and Outcomes (part two) .................45 
Figure 3.5 Research Methodology: Stages, Activities, Methods, and Outcomes (part three) ..............46 
Figure 3.6 Nature of This Research Within the Design Research Landscape ......................................48 
Figure 3.7 Science Fact and Science Fiction According to Rattay (2019) ............................................51 
Figure 4.1 Established Linear AV Workflow ..........................................................................................68 
Figure 4.2 Conceptual Workflow Incorporating Ideas and Feedback (Phases 1-2)..............................75 
Figure 4.3 Conceptual Workflow Incorporating Ideas and Feedback (Phase 3) ...................................76 
Figure 4.4 LiDAR Textured Mesh (left) and Wireframe (right)...............................................................77 
Figure 5.1 Flowchart of the Co-Design Remote Workshops .................................................................84 
Figure 5.2 Mural Board Designed for the First Workshop .....................................................................88 
Figure 5.3 Board Used for the Icebreaker Activity .................................................................................89 
Figure 5.4 Stages of the AV Filmmaking Process Identified in DS-I .....................................................90 
Figure 5.5 Boxes to Record Challenges Faced in Existing AV Production Workflows .........................91 
Figure 5.6 Pictures and Videos Shown to Prompt Participants .............................................................91 
Figure 5.7 Mural Board Designed for the Second Workshop ................................................................93 
Figure 5.8 Recapitulation of the Topics Discussed During the First Workshop ....................................94 
Figure 5.9 Visual Recapitulation of the Technologies Introduced During the First Workshop ..............94 
Figure 5.10 Boxes to Record Ideas During the Solo Brainstorming Activity .........................................95 
Figure 5.11 Boxes to Record Ideas During the Idea Iteration activity ...................................................95 
Figure 5.12 Bullseye Framework (left) and Participants’ Input Summaries (right) ................................96 
Figure 5.13 Mural Board After the First Workshop With Group 2..........................................................99 
Figure 5.14 Overview of the Mural Board After the Second Workshop With Group 1 ....................... 101 
Figure 5.15 Ideas Placed Within the Bullseye Framework by Participants ........................................ 101 
Figure 5.16 Visual Representation of the Idea Scoring System ......................................................... 102 
Figure 5.17 Visual Representation of the PS-III Phase (part one) ..................................................... 109 
Figure 5.18 Visual Representation of the PS-III Phase (part two) ..................................................... 110 
Figure 6.1 Fictional Logos................................................................................................................... 119 
Figure 6.2 Davis' (1989) Technology Acceptance Model ................................................................... 120 
 
 
 
 
XV 
Figure 6.3 Q7 Results: Average Team Size ....................................................................................... 125 
Figure 6.4 Q8 Results: Average Budget Size ..................................................................................... 125 
Figure 6.5 Visual Representation of Data Related to Perceived Usefulness ..................................... 128 
Figure 6.6 Q26: Most Valuable Scenario ............................................................................................ 128 
Figure 6.7 Q13 Results – Perceived Ease of Use of DEPERO.......................................................... 134 
Figure 7.1 3D Capture of La Casa Gassia ......................................................................................... 153 
Figure 7.2 3D Capture of Tower D Entrance at Brunel University ..................................................... 154 
Figure 7.3 Scene From A Clockwork Orange Set at the Entrance of Tower D .................................. 155 
Figure 7.4 3D Capture of Mont-Saint-Michel ...................................................................................... 156 
Figure 7.5 VR Viewing Mode (left) and Mixed Reality Viewing Mode (right)...................................... 158 
Figure 7.6 Layers' Functionality Inside Gravity Sketch....................................................................... 159 
Figure 7.7 Naming and Setup of VR Headsets .................................................................................. 160 
Figure 7.8 Collage of the 11 Sessions With a Total of 29 Participants .............................................. 162 
Figure 7.9 Gravity Sketch Avatars ...................................................................................................... 163 
Figure 7.10 Controllers' Instructions for Participants .......................................................................... 164 
Figure 7.11 User Testing Procedure Document Imported Within Gravity Sketch .............................. 164 
Figure 7.12 Capture Extracted From Google Maps............................................................................ 172 
Figure 7.13 Set Design Notes Drawn by Sketching Red Circles Around Props ................................ 173 
Figure 7.14 User-Generated Capture of a Sofa using Polycam ......................................................... 174 
Figure 7.15 Real Photos of Location 02 Imported Into the Virtual Scene .......................................... 175 
Figure 7.16 Location 01: La Casa Gassia at 1:1 (left) and 1:50 (right) Scales .................................. 176 
Figure 7.17 Three Participants in the Virtual Environment Simultaneously ....................................... 178 
Figure 7.18 Relationship Between Zhang et al. (2020) and This Work .............................................. 182 
Figure 7.19 Gravity Sketch .obj File, Opened With a Text Editor ....................................................... 183 
Figure 7.20 File in .kml Format to Import in Litchi, Opened With a Text Editor ................................. 184 
Figure 7.21 Scene From A Clockwork Orange (1971) Set Outside the Lecture Centre .................... 185 
Figure 7.22 Images From the Dataset Collected Using the DJI Mavic 3 ........................................... 185 
Figure 7.23 Movie Scene (top) and 3D Model Generated (bottom) ................................................... 187 
Figure 7.24 Different Levels of Detail Using Polycam and Blender ................................................... 188 
Figure 7.25 Steps Performed Using Gravity Sketch ........................................................................... 189 
Figure 7.26 Steps Performed in SketchUp ......................................................................................... 190 
Figure 7.27 Steps Performed in Google Earth ................................................................................... 191 
Figure 7.28 Steps Performed in Litchi (Cloud and Mobile Application) .............................................. 192 
Figure 7.29 Capture Artefacts: Tree Branches and Leaves (left), Handrails (right) ........................... 193 
Figure 7.30 Proposed Workflow for Immersive Planning and Drone Automation .............................. 195 
Figure 8.1 Alternative Representation of the Final Research Process .............................................. 200 
Figure 8.2 Illustration of the Practical Output Generated Throughout the Research ......................... 201 
Figure 8.3 Brief Description of Each Output Generated Throughout the Research........................... 202 
Figure 8.4 Representation of How the Research Contribution Was Generated ................................ 210 
 
 
 
 
XVI 
Figure 8.5 Conceptual Framework Proposed for Virtual Production Processes Applied to Small and 
Medium Productions ........................................................................................................................... 211 
Figure 8.6 Usefulness to Directors ..................................................................................................... 214 
Figure 8.7 Usefulness to Producers ................................................................................................... 215 
Figure 8.8 Usefulness to Cinematographers ...................................................................................... 216 
Figure I.1.0.1 Visual prompt for Story #1 - DEPERO ......................................................................... 270 
Figure I.1.0.2 Visual prompt for Story #2 - ALNINE............................................................................ 273 
Figure I.1.0.3 Visual prompt for Story #3 - OSMOS ........................................................................... 276 
Figure V.1.0.1 VP Staging Flowchart designed by Bazley (2022) - part 1 ......................................... 330 
Figure V.1.0.2 VP Staging Flowchart designed by Bazley (2022) -  part 2 ........................................ 331 
Figure V.1.0.3 Complete dataset of images captured by DJI Mavic 3 ............................................... 332 
Figure V.1.0.4 Captures created by participants using Polycam ....................................................... 333 
Figure V.1.0.5 Image generated using AI algorithm Stable Diffusion ................................................ 334 
Figure V.1.0.6 Experimentation of VR Storyboarding made by participants ...................................... 335 
Figure V.1.0.7 Some of the tasks and activities done in the virtual environment ............................... 336 
 
 
 
 
 
 
 
XVII 
List of Tables 
 
Table 1 High-End VP Virtual Production Characteristics ......................................................................33 
Table 2 Participant Sampling Strategy ..................................................................................................59 
Table 3 Summary of the Total Participant Pool (Interviews) .................................................................65 
Table 4 Summary of the Participant Pool (Workshops) ........................................................................85 
Table 5 Concepts Generated, Filtered, and Prioritized During the Second Workshop ...................... 103 
Table 6 Questions Adapted From the Technology Acceptance Framework ...................................... 122 
Table 7 Perceived Usefulness ............................................................................................................ 127 
Table 8 Features Suggested by Participants in Q15 .......................................................................... 139 
Table 9 Summary of the Total Participant Pool (User Testing) .......................................................... 146 
Table 10 Class Category Description According to Horvat et al. (2022) ............................................ 165 
Table 11 Questionnaire Questions in relation to Horvat et al. ............................................................ 166 
Table 12 Questionnaire From the End of the User Testing Session .................................................. 167 
Table 13 Results Comparison: Usefulness ........................................................................................ 170 
Table 14 Results Comparison: Ease of Use ....................................................................................... 171 
Table 15 Summary of Figure 8.5 ........................................................................................................ 212 
Table 16 Summary of Figure 8.6 ........................................................................................................ 214 
Table 17 Summary of Figure 8.7 ........................................................................................................ 215 
Table 18 Illustration of the Research Questions and Defined Objectives .......................................... 225 
 
 
 
 
 
 
 
XVIII 
Definition of Terms 
 
 
Term 
Acronym 
Definition 
 
Artificial 
intelligence 
AI 
In the context of this research, AI describes 
algorithms capable of generating new media 
content, such as images or texts. 
 
 
 
Augmented 
reality 
AR 
Real-time viewing of virtual elements in a real 
environment. 
 
Audiovisual 
AV 
A media product resulting from the 
combination of visual and audio components. 
 
Audiovisual 
industry 
AV industry 
The totality of all AV sectors and products (La 
Torre, 2014). 
 
Audiovisual 
sector 
AV sector 
A specific category of the AV industry 
characterized by its final output, production 
process, and distribution dynamics (La Torre, 
2014). 
 
Audiovisual 
production 
AV 
production 
The entirety of professionals working towards 
the completion of all the processes necessary 
to create an AV product. 
 
 
 
Audiovisual 
product 
AV product 
The final output generated by the AV 
production process. 
 
 
 
 
 
 
 
XIX 
Computer-
generated 
imagery  
CGI 
Imagery produced using computer graphics 
techniques. 
 
 
 
 
Design support 
/ 
Blessing and Chakrabarti (2009) use this term 
to define the outcome of a design research 
process. 
 
 
 
Digital twins 
DTs 
A digital simulation of a physical object or 
system that mutually exchanges data in real 
time.  
 
Extended reality 
XR 
An umbrella term describing the range of 
technologies or approaches that are used to 
supplement or merge the real and virtual 
environments. Both in academia and industry, 
it is commonly used interchangeably with 
mixed reality (MR). 
 
Mixed reality 
MR 
(See XR). 
 
 
 
Real-time 
rendering 
/ 
The process of rendering images at a rate 
rapid enough that the viewer does not see 
individual images, thus enabling a smooth 
interaction with the machine (Akenine-Moller, 
2018). 
 
Small and 
medium 
productions 
SMPs 
Includes single AV productions with medium 
budgets (less than $100,000), small budgets 
($20,000), and micro budgets (less than 
$4,000). 
 
 
 
 
 
XX 
Stakeholders 
/ 
Those involved in the AV production process. 
The term is used broadly to include directors, 
cinematographers, producers, and all 
professional figures participating in the 
projects. 
 
Visual effects 
VFX 
Visual elements (other live-action footage or 
CGI) added and integrated within pre-existing 
live-action footage. 
 
 
 
Virtual production 
VP 
An umbrella term to define a process having 
at its core real-time game engines combined 
with several other technologies. 
 
Virtual reality 
VR 
A simulated experience of an artificial or 
virtual environment that is commonly 
computer-generated in real time. 
 
Workflow 
/ 
In the AV industry, the term refers to the 
series of stages through which an AV product 
passes from inception to completion. In this 
work, it is used interchangeably with 
production process and pipeline. 
 
 
 
 
 
 
 
 
 
 
 
 
 
1 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Chapter 1 
 
INTRODUCTION 
 
 
1. Introduction 
 
 
 
2 
1. Introduction 
 
This chapter introduces the emerging field of virtual production (VP), describing its 
main characteristics and combination with immersive technologies. Additionally, the 
researcher presents the research aims, questions, and objectives at the centre of 
this research. Finally, the structure of this thesis is presented. 
 
1.1 The Ever-Evolving Relationship Between Filmmaking and Technology 
Since its inception, cinema has been deeply entangled with the technical mastery 
and technological advancements of its time. Some authors establish the birth of 
cinema with the Lumièrs brothers’ projection of their film to a paying audience in 
1895. However, many other inventors of the time were interested in capturing and 
projecting moving images (Nowell-Smith, 1996). Before the Lumièrs brothers, Léon 
Bouly developed his own version of the cinematograph in 1892. Edison patented an 
invention named Kinetoscope in 1891, and Muybridge was able, in 1878, to rapidly 
capture multiple images of a horse galloping. The innovations in perfecting, 
capturing, and projecting techniques, extra gears, and instruments has not stopped 
evolving. Different camera lenses to attach to the camera body have been invented, 
allowing filmmakers to capture close-up or wide shots of their subjects without 
physically moving the camera. George Eastman, the founder of Kodak, developed 
light-sensitive emulsions that he placed on glass plates and a cumbersome process 
to obtain images on flexible celluloid film, which marked a new era for photography 
and cinema. Mechanical contraptions to move the bulky and heavy cameras of the 
early days were developed, which introduced spectators to a new visual style. Then 
came colour, sound, light, handheld cameras, digital cameras, and computer 
graphics (CGs) software, to name a tiny fraction of the worldwide advancements that 
have been the centre of audiovisual (AV) production in the past 130 years. 
Every notable technological breakthrough that has benefited AV professionals has 
also required them to alter their production process to integrate such innovation. 
Modern film directors do not make movies in the same way they did 50, 25, or even 
10 years ago. Because filmmaking is a collaborative work, the same is valid for many 
other professional figures from different departments involved in developing an AV 
1. Introduction 
 
 
 
3 
product. Technological innovations require them to adapt, embrace new tools, and 
change their working habits. 
 
1.1.1 Virtual Production: Many Forms, Many Possibilities 
Among the latest innovation in the AV field is VP, which is an alternative to the 
established process, whose proponents claim that it fosters creativity while saving 
time and money. VP is an umbrella term that includes many technologies and 
practices. Further details about the term are provided in Section 2.1. 
 
Real-Time Game Engines 
It is generally agreed that this new process for producing AV products has at its core 
real-time graphics engines, or to be more precise, real-time game engines, which are 
commonly used in the gaming sector. These engines can produce computer-
generated images, which, in turn, can be modified through real-time interactions.  
Real-time game engines have improved considerably in recent years in the visual 
fidelity of realistic images; therefore, some filmmakers have introduced them in their 
production process.  
 
Virtual and Augmented Reality 
Many other technologies powered by these engines are becoming central and 
equally important in enabling VP. Virtual reality (VR) and augmented reality (AR) are 
the most common immersive technologies; VR immerses users in an artificial world 
when they wear a headset that occludes their sight of the real world, while AR 
supplements the real world with computer-generated visual elements. Filmmakers 
can employ VR and AR for many tasks, such as experiencing and working within an 
immersive digital replica of the filming location, which enables different crew 
members to collaborate virtually and remotely, pre-visualizing the scene without 
requiring travel to the physical location. This practice, in turn, reduces the carbon 
footprint and travel logistics, thus saving time and money. 
 
 
 
1. Introduction 
 
 
 
4 
LED Volumes 
Research on semiconductor devices such as LEDs started in the late ’60s (Borden 
and Pighini, 1969). It gradually advanced, improving the spectrum of colours that 
were reproducible on LED displays and reducing the distance between pixels 
(technically referred to as pixel pitch). Later, scientists assembled many LED 
displays together to form an array, the so-called LED wall, which was useful for 
displaying large-scale images to crowds attending concerts, events, fairs, and 
exhibitions. A notable example of an LED wall was used during the U2 PopMart 
world tour (Thomas, 2021). In recent years, LED walls have been built inside film 
studios (these are called LED volumes), often as an extended curved stripe. LED 
walls replace the blue or green screen widely adopted by AV producers and offer 
several benefits. Shooting inside an LED volume allows producers to display the 
scene’s background on the LED wall and edit the background in real time by using 
real-time game engines. Nevertheless, this does not come without some limitations 
and trade-offs that filmmakers must accept. For example, the cost of building an LED 
volume can be several million dollars, and renting such a facility can cost tens of 
thousands of dollars per day for small or medium LED volumes.  
 
Motion Capture 
Motion capture is a technique widely employed to animate fictional characters in 
video games or movies using animation data of real people wearing suits that are 
equipped with sensors and markers. Real-time game engines enhance this 
technique since it allows filmmakers to see the humans' performance on the fictional 
characters' bodies in real time.  
 
VR, AR, LED walls, and motion capture are merely a few technologies and 
techniques that can be part of the VP process. Many combinations are currently 
under experimentation by both AV industry players and academic researchers.  
 
VP is primarily associated with LED volumes among AV professionals and academic 
researchers. However, as described, establishing a VP process using an LED 
1. Introduction 
 
 
 
5 
volume may be expensive and out of reach for AV producers with different financial 
resources.  
 
1.2 Virtual Production for All: Shifting the Focus to Small and Medium 
Productions 
The most emblematic AV productions that have employed VP in recent years have 
been characterized by the vast amount of economic and human resources allocated. 
While exploring what may be possible through VP, one of the main challenges is the 
correct functioning and interoperability of hardware and software technologies. 
Consequently, complex workflows often result, as does the need to employ 
expensive gear and hire highly skilled professionals from other fields, such as 
engineers and computer scientists. AV producers who can afford to employ such a 
workforce as well as the time and technical resources are few and do not represent 
the whole ecosystem of the AV industry. 
 
While the VP process is used for advancing high-end productions, little consideration 
has been bestowed upon small and medium productions (SMPs), which, by 
definition, have limited economic and human resources. 
 
Shifting attention to explore the extent to which SMPs can employ VP is important, 
considering their vast presence in the AV industry. However, identifying more 
precisely the number of people involved in SMPs and the economic volume they 
represent within the AV industry is an arduous task because of its fragmented 
nature. Many researchers (La Torre, 2014; IDEA Consult 2013; Renée, 2015; Ibrus 
& Rohn, 2019) have retrieved data about specific AV sectors, especially feature 
films. These scholars have considered only specific countries or regions, which only 
partially describe the actual size of the market represented by SMPs and the number 
of professionals employed. 
 
Quantifying the accurate presence of SMPs across the AV industry is beyond the 
scope of this study. However, this researcher discovered the lack of a systematic 
1. Introduction 
 
 
 
6 
study that explores through a co-design approach the framework and employment of 
VP processes for filmmakers operating in a context with limited resources. 
 
1.3 Research Aims  
The overall aim that underscores this research is to present an exploration of VP's 
applications and potential in AV productions which have only limited resources. This 
area is a knowledge gap in the literature and industry applications. The work reports 
the specific VP-related needs of AV professionals who work on SMPs. Additionally, 
this researcher aimed to co-design, iterate, develop, and evaluate a new VP process 
of alternative workflows that employ immersive technologies.  
 
1.4 Research Questions 
The main research question addressed in this study is as follows: 
 
RQ1. To what extent can VP combined with immersive technologies be 
employed by AV professionals in SMPs? 
 
This main question leads to the following sub-questions: 
 
RQ1.1. What research already exists on this topic, and to what extent is VP already 
developed and employed by industry players in their making process? 
 
The intent of the first sub-question is to build an understanding of previous research 
and experimentation. Additionally, since the private sector has already dedicated 
substantial resources to advancing VP, it is crucial to include the perspective of 
industry players on this emerging field. 
 
RQ1.2. What are the challenges that SMPs face due to limited resources? 
 
The second sub-question was designed to explore the daily and practical difficulties 
professionals address when working with limited economic and human resources. 
 
1. Introduction 
 
 
 
7 
RQ1.3 What alternative VP process can be co-designed and developed to enable 
SMPs’ adoption of VP? 
 
This aim behind this third sub-question is to enable participants to contribute to the 
co-design, development, testing, and evaluation of an alternative VP process 
combined with immersive technologies.  
 
1.5 Research Objectives 
 
A. To review the academic literature and pre-existing processes employed by 
industry players regarding VP. 
 
B. To investigate the challenges faced by AV professionals who work on SMPs. 
 
C. To co-design with participants alternative VP processes combined with 
immersive technologies. 
 
D. To translate the outcomes of Studies 1-3 into a practical prototype (study 4) to 
be tested and evaluated by AV professionals. 
 
E. To discuss and self-reflect the implications of such a prototype in Study 5 and 
provide a set of recommendations upon which future work may advance 
research on the VP process applied to SMPs. 
 
 
1. Introduction 
 
 
 
8 
1.6 The StoryFutures Project 
This PhD project is part of StoryFutures: Gateway Cluster Partnership for 
Audiovisual Digital Creativity (AH/S002758/1), a creative industries research and 
development programme funded by the Arts and Humanities Research Council 
(AHRC). The overall aim that underscores the programme is to define and develop 
the next generation of storytelling approaches by exploring the opportunities offered 
by the latest developments in the immersive technologies of VR, AR, and mixed 
reality (MR). The StoryFutures consortium includes more than 35 academic and 
creative industries organizations based west of London. This work is complementary 
to the efforts established by other academics who participate in StoryFutures project 
when exploring an emerging field such as VP. These academics investigate VP 
applied to high-budget AV projects, while this researcher examined VP applied to AV 
productions that have limited resources, such as SMPs. 
 
1.7 Structure of the Thesis 
This thesis is divided into nine chapters; the present chapter offers an overview of 
the thesis' theme, aims, and contributions.  
 
In Chapter 2 is an overview of the definition of VP, its employment in both industry 
and academia, and its relation to how immersive technologies have been adopted 
and employed both in academia and the AV industry. 
 
Chapter 3 describes the design methodology chosen for this research as well as the 
reasons for its selection. This part also presents the design methods considered 
most appropriate to collect qualitative and quantitative data.  
  
Chapter 4 (exploratory study), Chapter 5 (idea co-generation), Chapter 6 (idea 
filtering and iteration), and Chapter 7 (prototype design and evaluation) contain 
consecutive studies that enabled the researcher to collect data and gather insights. 
These four works are interdependent. Findings that emerged from the exploratory 
interviews were crucial to structuring and defining the scope of the co-design 
workshops, which in turn were fundamental to co-design innovative ideas, which 
1. Introduction 
 
 
 
9 
were filtered, further iterated, and finally developed into a working prototype for 
stakeholders' evaluation.  
 
These progressive data collection and analysis stages guided the researcher to 
generate valuable output: an alternative workflow for pre-production, which 
participants evaluated as ready to be employed in a real-world scenario for further 
assessment.  
Chapter 8 discusses the findings of the research, while Chapter 9 explains the main 
contributions of this research and establishes directions for future work. 
 
 
1. Introduction 
 
 
 
10 
 
Figure 1.1 Outline of the Thesis
2. Literature Review 
 
 
 
11 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Chapter 2 
 
LITERATURE REVIEW 
 
 
2. Literature Review 
 
 
 
12 
2. Literature Review 
 
2.1 Introduction 
This section provides a clarification and analysis of both previous academic studies 
and pre-existing industry processes regarding VP, an emerging process in the AV 
field. From the review of the literature, the researcher ascertained that the VP 
process encompasses different applications, taking advantage of a wide range of 
technologies, especially the use of real-time game engines commonly employed to 
develop video games. 
This VP process assist the pre-production, production, and post-production 
processes for stakeholders' AV projects. Because of the many ways in which VP can 
be employed, Sebastian Sylwan, former chief technology officer at Weta Digital and 
member of the VES founding board, states that ‘there is no checklist of things you 
can go through and say, if you have all of these, this is virtual production’ (Thacker, 
2012). He further explains that the industry is still in the process of learning and 
exploring VP. Consequently, the researcher considered it appropriate to present an 
organized explanation and review to the reader. This approach identifies and 
differentiates how VP has been employed in different contexts and production sizes. 
Discovering and reviewing the state of VP in the academic literature and existing 
industry applications were of primary importance to identify the current knowledge 
gap. 
 
2.1.1 Definition of Virtual Production 
As Dunlop states (2014, p. 304), the VP process "is becoming the norm for any 
movie requiring large scale visual effects" (VFX). The term VP started to be used 
more frequently after the production of Avatar (Cameron, 2009). In recent years, an 
increasing number of iconic high-budget films, such as The Jungle Book (Favreau, 
2016), Ready Player One (Spielberg, 2018), and The Lion King (Favreau, 2019), as 
well as TV series, such as The Mandalorian (Favreau et al., 2019) and Westworld 
(Abrams et al., 2016), proved the potential of the most advanced VP techniques. 
These productions, which are set in imaginary worlds and therefore require heavy 
use of VFX achieved through CGs, found in VP a useful tool.  
2. Literature Review 
 
 
 
13 
 
Different industry players and academic researchers define VP differently; however, 
many authors agree that it is a process to pre-visualise, produce, and post-produce 
an AV project by taking advantage of real-time technologies and shifting the 
established workflow from linear to non-linear where possible to iterate creative 
decisions quickly.  
 
ACADEMIA 
INDUSTRY 
‘The virtual production process enables 
directors to view live footage of the 
actors on set integrated with 
placeholder versions of the CG 
elements of a shot’. 
Dunlop (2014) 
‘VP combines virtual and augmented 
reality with CGI and game-engine 
technologies to enable production crews 
to see their scenes unfold as they are 
composed and captured on set’. 
MPC in Kadner (2019) 
‘The concept of virtual production 
foresees to combine key aspects of 
media production in a real-time, or close 
to real-time, environment where 
creative decisions can be taken in direct 
consultation with other members 
of the team’. 
Helzle, Grau, and Knop (2015) 
‘Virtual production is where the physical 
and digital worlds meet’. 
Weta Digital in Kadner (2019) 
‘VP combines virtual and augmented 
reality with computer-generated 
imagery. All this is made possible by 
real-time game-engine technology’. 
Bennett et al. (2021) 
‘As VFX have grown to be a greater part 
of movies and television today, there is 
a growing divide between what the 
filmmakers can see through the camera 
on the live-action set, and what they 
have to imagine will be added digitally 
many months later. Virtual Production 
attempts to unite those two worlds in 
real-time’. 
Magnopus in Rogers (2020) 
2. Literature Review 
 
 
 
14 
 
Based on these definitions, VP is not a technology itself but rather an alternative to 
the established production process currently employed in AV projects. VP has at its 
core real-time game engines to which several other software and hardware 
technologies can be added and combined to produce an AV result. 
 
2.1.2 Benefits of Virtual Production  
The VP process has the potential to bring economic and creative benefits for 
stakeholders involved in the creation of an AV production. Adopting VP for scenes 
with VFX allows directors and other professionals involved on set to acquire real-
time feedback on VFX integration inside the scene. Hence, the director can see on 
the monitor a closer representation of the final appearance of the scene and quickly 
iterate the decision-making process, thus saving time and, therefore, money. 
Directors are not the only figures to benefit from VP. Actors and actresses can feel 
more immersed in new filming facilities designed explicitly for VP, which are 
characterized by an array of LED panels. This technique displays the scene 
background on the array, giving players a better idea of the setting than large, empty 
spaces surrounded by a monochromatic green screen. 
 
2. Literature Review 
 
 
 
15 
 
Figure 2.1 Green Screen Studio (top) and Stagecraft LED Volume (bottom) 
Furthermore, integrating the VP process with immersive technologies such as VR 
and AR allows industry players to push the boundaries even further. Wearing a VR 
headset, the director could be immersed and navigate freely in the virtual scene as if 
the crew were in a real location filming a live-action scene, a process with which 
shooting teams are familiar. 
Consequently, the director can ask the crew to make changes in the camera 
position, lighting, set design, and so on to better and more quickly recreate the 
vision, as they can shoot multiple takes with ease. 
2. Literature Review 
 
 
 
16 
Increasingly, productions adopting VP are aiming to complete the so-called final pixel 
on set, meaning that further post-production processes, such as the addition of VFX 
elements, is not needed and being able to obtain the final look of the image at the 
end of the shooting day (Pohl, 2019). 
 
Professionals in many other roles can benefit from VP. Cinematographers can try 
different camera movements, whether those be handheld or movements that 
simulate cranes or dolly systems. They can change the scene lighting, simulating the 
hard light of the sun at noon or replicating the sunset without time constraints, which 
would be a factor if they were shooting during the so-called golden hour on a live-
action set. 
 
The advantage of VP for scenographers is that they can immerse themselves in the 
virtual world through a headset and thus perceive the 3D volume of the scene, which 
allows them to make creative choices on where to place props and interiors and then 
pitch their ideas to the director. 
 
Even if they are accustomed to staying on the other side of the camera, actors and 
actresesse can also significantly benefit from the VP process; as producer Brian 
Binder explains:   
‘Let's say you're doing a show that takes place primarily on a bus, and instead of 
sitting there for day after day after day staring at the green screen through the 
windows, and the entire crew and all the cast being so disconnected from what's 
going on and what this thing is going to look like at the end of the day, we're 
actually able to bring that experience to everybody live on set’ (Pohl, 2019). 
A further explanation of the benefits of VP for the aforementioned roles and for other 
people involved in AV production is explained and discussed in the following 
sections. 
 
2.2 Sources 
This literature review presents materials from various sources, including online audio 
and video materials, social media posts from film industry insiders, blogs, software-
2. Literature Review 
 
 
 
17 
specific documentation as well as guides, and established sources such as 
academic papers and articles. 
 
Academic Digital Libraries 
Literature on VP was sought using the following keywords: virtual production, virtual 
reality cinematography, digital twin, location, capture location, film photogrammetry 
scan, virtual location scouting, and virtual filmmaking. 
Scopus and Google Scholar search engines were used to locate books, peer-
reviewed journal papers, conference articles, and PhD theses; other digital libraries, 
such as ‘Association for Computing Machinery’ (ACM) and ‘Institute of Electrical and 
Electronics Engineers’ (IEEE), were also consulted. 
  
Online Videos 
Numerous conferences focus on CG and game development, such as ‘Special 
Interest Group on Computer Graphics and Interactive Techniques’ (SIGGRAPH), 
‘Film & Media Exchange’ (FMX), Game Developers Conference (GDC), and Digital 
Dragons, offering videos from industry leaders sharing their experiences on the VP 
processes they developed and adopted for their projects. These resources allow a 
deeper examination of the strengths and features of current VP processes. 
Similarly, both Unreal Engine and Unity, the industry's two most popular software 
programs for VP, generated a large number of case study videos on specific projects 
to promote their real-time technologies (Unreal Engine, 2019a, 2019b) as well as 
articles (Blondin, 2019) and roundtables (Unreal Engine, 2018) where they interview 
their stakeholders and explain in detail the advantages of using their real-time 
engines. 
 
Facebook Groups 
There are numerous Facebook groups regarding VP and other topics relevant to this 
research, such as ‘Unreal Engine: Virtual Production’, ‘Virtual Production’, ‘Virtual 
Production Group’, ‘Remote Mocap’, ‘Virtual Reality’, ‘Volumetric Imaging’, ‘Virtual 
and Augmented Reality’. They are composed of people who are passionate about 
these topics and international professionals working in the field who often share their 
2. Literature Review 
 
 
 
18 
works and design processes, explain their approaches, and discuss further 
applications with other group members. Facebook groups are a valuable resource to 
acquire insights on general trends in VP, read feedback and opinions on current 
design processes, and identify potential experts to interview.  
 
Conferences Websites 
Generally, websites of renowned conferences and events for professionals in CG 
and VFX offer materials such as video recordings, interviews with professionals, and 
scientific papers. 
Among the conferences which have presented VP works in the past are SIGGRAPH, 
IEEE, Real Time Conference (RTC), Laval Virtual, GDC, and FMX. 
 
Podcasts 
Many times, podcasts are presented by a host who invites relevant figures in a 
specific field to discuss a topic in depth. Some podcasts, such as Behind the Screen, 
which is hosted by Carolyn Giardina, bring multiple leading professionals to the 
same table. Consequently, the discussion produces not only the vision of a single 
person but also a broader perspective on current trends and challenges in VP. 
Accordingly, the podcast Visual Disruptor, hosted by Mike Seymour and promoted by 
Unreal Engine, is highly relevant, as many VP topics are discussed with experts.  
 
Documentation and Guides 
Another source of important information related to these high-end production 
processes is the documentation provided by real-time technology companies such 
as Epic Games with their The Virtual Production Field Guide (Kadner, 2019), which 
explains in detail the advantages of using Unreal Engine for VP.  
As discussed in the following pages, Technicolor employs a similar strategy by 
providing an overview of its VP process, Genesis (2018), which was born in strict 
collaboration with another real-time technology company, Unity. 
 
 
 
2. Literature Review 
 
 
 
19 
2.3 Review 
Because the end goal of this research is to identify how immersive technologies can 
aid AV professionals in adopting the VP process, the literature review is organized to 
explain and discuss how VP has been impactful for stakeholders. 
Therefore, the literature review emphasises use cases rather than detailing the 
technology and technical innovations developed to date. 
However, some exceptions occur to facilitate the reader's understanding of how 
specific technologies work and why they can be helpful when needed. 
 
2.3.1 Premise 
The researcher located few studies while searching for relevant publications on VP 
and immersive technologies in media production overall. In other branches of 
knowledge, immersive technologies have been extensively researched in recent 
decades in fields including medicine (Satava, 1995), human factors (Furness, 1983), 
psychology (Gaggioli, 2001), manufacturing (Jayaram, Connacher, & Lyons, 1997), 
and education (Helsel, 1992), among others.   
It is argued that the reason for this different quantity of knowledge may be due to the 
different scopes and requirements of the media production sector. 
If functionality is favoured in some disciplines over a realistic representation of the 
virtual reality environment (VRE), the same cannot be said for a sector whose scope 
is to make AV products.  
It is possible that professionals in other disciplines were more inclined to accept the 
visual quality trade-off offered by immersive technologies of past decades. For 
example, an immersive simulation created to familiarize technical operators with 
machinery controls may not require a faithful visual representation of the real 
machinery and VRE. A minimal but functional interface and representation of the 
virtual objects and environment is sufficient to train operators and evaluate their 
performances.  
Therefore, a possible reason for the disproportionate number of studies that focus on 
the employment of immersive technologies in the AV sector can be explained by the 
overall visual representation of the VRE at the time, which is a trade-off that did not 
reach industry standards and expectations. 
2. Literature Review 
 
 
 
20 
Based on the researcher's professional experience in the AV industry, filmmakers 
usually have a keen eye for images. They are attentive and capable of spotting 
artefacts and inconsistencies while observing an image. 
Researchers conducting studies in other fields, such as those mentioned previously, 
do not seek to produce images through the employment of immersive technologies. 
The visual aspect is subordinate to other scopes. It is a tool to fulfil other tasks, so 
they can afford to have a simplified representation of the VRE as long as it suits their 
needs. 
 
Additionally, the search was extended to the media studies discipline to better 
understand other outputs presented in the current literature. The stance taken by 
media studies authors (Aylett & Louchart, 2005; Ryan, 2009; Bodini, 2017) has been 
shifting towards exploring whether and how these immersive technologies could be 
considered new media that are capable of telling stories and conveying meaning, 
similar to film, theatre, and arts. As expected, these studies have explored VR and 
AR as new media rather than new tools to integrate into AV production processes. 
 
Only in recent years has there been a growing interest among researchers to explore 
and experiment with these AV technologies to aid AV professionals (Kadner, 2019). 
It may be due to the technical advancements in immersive technologies, such as VR, 
AR, and real-time game engines (Unreal Engine, Unity), in image quality, 
affordability, and accessibility. Regarding VR devices, it is worth mentioning the 
breakthrough represented by the headset Oculus DK1, which was invented by 
Palmer Luckey in 2012 and has significantly contributed to a new approach for 
making VR headsets and enhancing immersive experiences (Blake, 2019). 
 
2.3.2 Academia  
An AV product is the result of activities performed by an AV production team, ranging 
from organizational and legal tasks to creative or technical assignments. However, 
among the existing academic works, most researchers have focussed their efforts on 
helping filmmakers in specific activities, such as pre-visualizing VFX elements for a 
scene (de Goussencourt, Dellac, & Bertolino, 2015). 
2. Literature Review 
 
 
 
21 
This need to understand how the final scene will appear started with the invention of 
cinema and fictional AV productions. Disney produces animated movies by 
dedicating effort to pre-visualizing the final images and animations using 
storyboards. This approach is also valid in live-action movies where directors of the 
calibre of Alfred Hitchcock or Orson Welles rely on detailed planning before shooting 
begins (Okun & Zwerman, 2020). VFX elements appear in almost every modern 
movie production (Zimmer, Drochtert, & Geiger et al., 2017) for both creative and 
economic reasons; hence, the main creative challenge is real-time pre-visualization 
that combines both real and virtual elements in the shot. 
This faithful representation shows cinematographers and directors an image as close 
as possible to the final image after post-production processes.  
Additionally, from an economic perspective, deciding to add VFX elements can be 
costly, so carefully planning each shot is crucial. 
 
Researchers at the Filmakademie Baden designed the ‘Virtual Production Editing 
Tool’ (VPET), an AR tool developed for consumer technologies such as iPad and 
iPhone, to enable independent filmmakers to perform pre-visualization on set in a 
relatively affordable and accessible way (Spielmann et al., 2018). 
One of the main features of a tool set such as VPET allows the so-called set 
extension of part of the film set. In this way, production designers can visualize an 
augmented version of the pre-existing scenography for the final scene on their tablet 
or smartphone and communicate their vision to people in other departments. 
Furthermore, Zimmer, Drochter, and Geiger et al. (2017) developed an accessible 
and easy-to-use AR tool set to enable an independent director to plan and pre-
visualize a film scene. Once in a location-specific context, this AR tool set allows the 
user to place and manipulate virtual elements (objects, characters, etc.) in real-world 
environments (streets, football fields, etc.) planned for the movie's filming location. 
Then, they can pre-visualise elements that are not available during pre-production 
but will be used during the shooting phase.  
 
Bennet and Carter (2014) adopt a practice-led approach to explore how VP could be 
used by filmmakers performing motion capture for short animated films. The 
2. Literature Review 
 
 
 
22 
feedback received from the participants was positive overall and highlighted aspects 
to improve, such as data management for the large files generated by motion 
capture, the need for virtual characters designed for motion capture, and the need to 
work with professional performers.  
 
Additionally, Bouvile, Gouranton, and Arnaldi (2016) investigate how VR can improve 
the performances of actors and actresses  who must manage the impediments 
imposed by VFX on set. 
 
‘Not being able to see what is around them, they cannot perceive occlusions nor 
avoid obstacles. The performance becomes even more difficult when they are 
asked to play opposite virtual partners. First, they must avoid missing eye contact 
when conversing with a character who is not actually there. Second, they must 
give the illusion of maintaining a consistent eye-line while following a moving 
virtual character or a virtual object’ (Bouvilee, Gouranton, and Arnaldi, 2016). 
 
The result of their experimental study shows how VR-trained actors and actresses  
perform as well as their classically trained peers during shooting; the authors foresee 
a future in which a lighter and more affordable technical setup may be available to 
improve the quality of work and acting performances. 
 
Kuchelmeister (2020) compares the production time required to shoot a live-action 
short film with one generated using real-time rendering. He finds some advantages 
in the freedom to change the scene in the virtual environment at any point, although 
he recognizes the significant resources required to undertake this kind of VP and the 
expertise needed in various domains. In fact, before producing the short film in the 
real-time game engine, it was necessary for Kuchelmeister to research how to 
integrate the virtual set created in Unity, develop the virtual character to be 
animated, record the motion capture performance, and clean the same motion 
capture animation. He concludes by anticipating the development of more intuitive 
tools that will make VP more accessible. 
 
2. Literature Review 
 
 
 
23 
Instead of working on a more versatile tool set, others researchers (Lin et al., 2018; 
Chiu, Huang, & Ouhyoung, 2017; Muender, Fröhlich, & Malaka, 2018) have studied 
specifically how VR filmmakers could use real-time game engines to experiment with 
different cinematography solutions, while virtually exploring different lighting 
scenarios and camera movements. 
This kind of system would benefit cinematographers during the pre-visualization 
phase and allow aspiring cinematographers to learn more about cinematography 
techniques and technicalities.  
 
The potential to remotely collaborate in VR when planning a scene has been proven 
successful and is perceived as useful in a real-life pre-production scenario by a 
participant in Ardal et al.'s (2019) experiment. 
Allowing participants to collaborate in the same virtual space, having the same visual 
context of the environment, and acknowledging the presence of other collaborators 
through a virtual avatar combined with the potential to communicate verbally have 
been evaluated by the same participants involved by Ardal et al. as similar to real-
world situations. 
 
Among these different studies, common themes emerge from their conclusion 
chapters: Constant experimentation with more advanced and recent technologies is 
needed, and evaluating new methods, processes, frameworks, and tools must be 
conducted in real-world scenarios that directly involve potential stakeholders. 
Although VP targets different roles (directors, cinematographers, actors &actresses,  
and production designers), the technology has been adopted during pre-production 
phases for pre-visualizing scenes. 
 
2.3.3 Industry  
Shifting the focus to relevant VP processes and techniques developed by the 
industry players, it is first necessary to distinguish between high-end productions that 
have at their disposal immense financial resources (hundreds of millions of dollars) 
and those with far less means and capabilities, such as SMPs.  
 
2. Literature Review 
 
 
 
24 
Another important note is the wide variety of AV products that can be generated 
depending on the scope of an AV production. 
In his book The Economics of the Audiovisual Industry: Financing TV, Film and Web, 
La Torre (2014) analyses the main economic and financial features of the AV 
industry, explaining that the industry is determined by the sum of all AV sectors, 
which differs in the nature of the product generated, production processes, and 
distribution dynamics. 
The majority of relevant AV productions that employ VP are feature films or TV 
series. However, the numbers of other AV sectors are many: commercials, 
documentaries, music videos, and video art, among others. Explaining to the reader 
how each differs, sometimes slightly and sometimes significantly, would require 
additional effort and may distract from the main aim of this research. 
 
Nevertheless, it is crucial to underscore, to offer a better idea of its considerable 
impact, that not only can VP be adopted for movie making but the core concepts of 
such new processes can also be employed efficaciously in many other AV sectors. 
This ever-evolving context is supported by La Torre's (2014) conclusion that the 
taxonomy presented in his book ‘should also be analyzed considering its ‘work in 
progress’ nature’ since the difference between AV products ‘is less relevant than it 
previously was’ (2014). 
2.3.3.1 High-End Productions 
One of the most expensive movies ever made, Avatar (Cameron, 2009), directed by 
James Cameron, is considered the birthplace of VP. This film sparked interest 
among significant industry players to further develop the VP process for their high-
end productions.  
Every AV production has specific challenges. In the most ambitious productions, 
filmmakers push the boundaries of AV production to achieve never-before-seen 
sequences. Hence, they develop specific film sets, technologies, or custom 
workflows. One of the many examples is Gravity (2013), wherein director Alfonso 
Cuaron, cinematographer Emanuel Lubezki, and VFX supervisor Tim Webber 
combined their efforts to achieve their notable zero-gravity shot. They built a one-of-
a-kind contraption consisting of an LED-panel stage, a robotic arm, an Arri Alexa 
2. Literature Review 
 
 
 
25 
camera and ‘a row of extremely talented technicians with their laptops’ (Seymour, 
2013).  
One can see from this example that the specific need drove most of the process 
creation required for each production, and this is true for the most recent VP 
processes.  
 
To recreate a familiar and filmmaker-friendly setup for Rogue One: A Star Wars 
Story (2016), director Gareth Edwards and Industrial Light & Magic (ILM) R&D team 
developed an effective custom process. 
As Jutan and Ellis (2017) state: 
 ‘Gareth Edwards is a hands-on filmmaker, often operating the ARRI Alexa 
camera on set. He does not like to be constrained to the initial sequence planning, 
opting instead to try alternative angles to find the most interesting shot. Our 
system provided this freedom within the pure digital environments of Rogue One’. 
Jutan and Ellis suggest that placing live-action directors in live-action environments 
can significantly enable them to shape their vision without worrying about the 
technology involved, provided that the way of shooting is similar to one with which 
they are accustomed.  
Jutan and Ellis decided to employ off-the-shelf devices for the VP setup, including 
the HTC Vive, iPad Mini, Gamevice controller, and a motion capture (mocap) tracker. 
However, despite their affordable and accessible hardware setup, their greatest 
achievement is their custom ILMvCAM application which communicates in real time 
with their Zeno application framework, which was developed in house in 1997 and 
has been continually updated since then by a highly skilled team. 
 
In making The Mandalorian (Favreau et al., 2019), ILM specifically built Stagecraft, a 
facility that has a curved video wall positioned behind the actors and actresses. The 
wall is 20 feet high, 180 feet wide, and comprises 1,326 LED panels. The images on 
the LED wall are generated in CG and manipulated in real time using Unreal Engine 
4.  
The use of real-time technology allows the director to see the CG environment 
change on the LED wall according to the camera movements.  
2. Literature Review 
 
 
 
26 
One of the benefits of employing this process is the convincing lighting from the LED 
wall that bounces off actors and actresses and real props on set. The result is that 
reflections and tonalities on metallic surfaces as well as on actors and actresses skin 
and costumes are more coherent with the virtual environment, which is not 
achievable using green screen techniques. The LED panels' pixel pitch is an 
essential factor influencing the final picture: The shorter the pixel pitch, the clearer 
the image on the LED panel and the less risk of encountering a technical issue such 
as a moiré pattern, which would compromise the image by creating strange-looking 
wavy patterns.  
According to Seymour's (2020a, 2020b) article on fxguide, the Stagecraft screens 
have a 2.84 mm pixel pitch. A best practice to avoid the moiré pattern is to use 
cameras and lenses capable of recreating a certain degree of field depth to defocus 
the background. Longer lenses and lower iris aperture (T-stops) narrow the field 
depth and, therefore, significantly defocus both background and foreground. ILM 
primarily used lenses larger than 50 mm and generally exposed the shots between 
2.5 and 3.5 T-stops. Over 50% of the first season of The Mandalorian was filmed 
with the VP process. 
 
Similar to ILM's Zeno tool, Technicolor's MPC studio developed a VP process named 
Genesis and evolved its custom VFX pipeline, as Tovell and Williams (2018) explain. 
The main goal with Genesis is ‘to provide the foundations and tools to produce a 
higher quality result from the pre-viz stage, and therefore give the rest of the VFX 
process a huge head start’. 
This approach is possible because of a strict collaboration with real-time engine 
company Unity, which enabled the substantial customization of the system's 
behaviour in three fundamental aspects: (a) the creation of a platform for remote 
collaboration with different devices; (b) the creation of a virtual camera capable of 
integration with a wide variety of standard filmmaking gear, such as a dolly and 
wheels as heads, for example; and (c) the generation of high-quality film output 
which can be re-used by the VFX department as a starting point for their work.  
Once again, a key ingredient in this process was that Technicolor’s Genesis could 
rely on pre-existing in-house processes, such as Tessa, which is a solid and mature 
2. Literature Review 
 
 
 
27 
asset management system that organizes and stores meta-data produced on set 
during the VP process (such as camera position, props position, snapshots, etc.) and 
enables 3D artists to fine-tune a scene according to the meta-datapreviously 
generated using Autodesk’s Maya 3D software.  
Additionally fundamental was the adoption of the universal scene description (USD) 
format, which was developed by Pixar to create (a) a standard format for 3D data 
(modelling, shading, animation, lighting, effects, and rendering) that is readable by 
many software programs as well as (b) scalable (allowing high or low-poly 
representation) and (c) suitable for teamwork since it enables non-destructive 
collaborative editing in which previous edits made by others can be retrieved. 
As with the JSON and .fbx formats, the USD format effectively transfers data back 
and forth from Maya and Unity, allowing a quick and continuous iteration of the 
virtual set. 
Similar to Edwards' Rogue One experience, veteran cinematographer Caleb 
Dechanel, while shooting The Lion King, offered a similar opinion on adopting this 
process, stating: 
‘If somebody had asked me, you know, five years ago – would you be working on 
a film at the cutting edge of film technology? – I would say – Are you crazy? – but 
I actually find it much more agreeable than I thought from the point of view that is 
very similar to what I'm used to doing. I mean[,] I find myself making the same 
kind of[,] you know[,] decisions in the same way. The same eye towards telling a 
story’ (Movie Trailer, 2019). 
Employing Genesis for an AV production such as The Lion King – the story is set in 
the African savannah and the entirety of the environment was recreated via CG – 
allowed director Jon Favreau and his collaborators to conduct virtual scouting to 
decide the shooting location, as explained by Moving Picture Company’s (MPC) VFX 
supervisor Rob Legato:  
‘What it did (Virtual Production) was to allow us to have five or six people in VR at 
any one time location scouting, talking about where the animals are going to start 
and stop, all the blocking, the actor blocking of that and figure out what the action 
is and what's the best vantage point to shoot it from. And we were able to hop 
2. Literature Review 
 
 
 
28 
from location to location, literally miles and miles of fabricated (CG) Africa’ 
(Giardina, 2019). 
 
The interest in developing processes for virtual scouting has also been expressed by 
other players in the industry, including The Third Floor, a studio that specialises in 
pre-visualizing scenes for high-budget movies that contain a vast amount of VFX. 
Their immersive application, Pathfinder, was initially developed for the TV show 
Game of Thrones and further developed to create an intuitive and filmmaker-centred 
tool that enables virtual scouting of real-world locations (virtual location scouting) and 
is digitized with 3D capturing techniques to recreate a digital twin (DT) of that 
location.  
 
The company also adopted ‘virtual set scouting when the scene was set in an 
imaginary city like the one [in] ‘King's Landing’ (The Third Floor Inc., 2020). They 
virtually explored the city, which had previously been digitally reconstructed by the 
virtual art department using 3D modelling software, which allowed users to visit 
different areas of the set, including interiors, backlots, or sets built in real-world 
locations. When wearing the VR headset, directors could start blocking actors and 
actresses, a phase in which they decide where players will stay or move in a scene. 
The blocking phase is also related to the lighting design of the scene. Using a virtual 
viewfinder, cinematographers can test different camera angles, positions, or lenses 
and take a picture to review later. Production designers can freely manipulate 
construction and objects, experimenting with different stylistic choices. 
 
In addition to feature-length blockbuster movies, professionals in a number of other 
AV sectors are employing VP to create projects for advertising (Seymour, 2022), 
music videos (Katy Perry, 2020), or broadcast (Webster, 2020; Vizrt, 2022). 
An excellent example of the VP process applied to the broadcast sector is the 2020 
League of Legends Worlds Championship (Webster, 2020), which was broadcast 
employing the VP process. This enabled the blending of the physical and digital 
worlds in real time, virtually extending the physical set of common broadcasting 
studios (Figure 2.2) and adding 2D or 3D graphics and animation. 
2. Literature Review 
 
 
 
29 
 
 
Figure 2.2 Stage Appearance to Players (left) and Viewers (right) 
This alternative approach to broadcasting produces changes both for AV 
professionals (by requiring them to operate a new workflow) and for the audience 
(who now have a new format with which engage).  
 
2.3.3.2 Small and Medium Productions  
Academics and professionals do not have a common agreement on the meaning of 
the term independent productions.  
As stated by film critic and professor Emanuel Levy, ‘Over the years the definition [of 
independent] has blurred’, increasing unclarity and confusion that exist over the 
definition of 'independent’ (Levy, 1999). In his book Cinema of Outsiders: The Rise 
of American Independent Film, Levy reports different interpretations of the definition 
of independent offered by other authors and film directors; two criteria are common 
in their statements: First, freedom is provided to directors to express their vision 
without compromise or constraint imposed by a committee represented by major 
studios. 
The second commonality is budget size. The Sundance Institute, a nonprofit 
organization born to support and promote independent filmmakers, uses the term 
indie to identify productions with budgets below $1 million (Renée, 2014). Similarly, 
the nonprofit organization Film Independent created the Spirit Awards to recognize 
notable independent productions; one award category is named after filmmaker John 
Cassavetes and highlights films with budgets of $1 million or less (this amount was 
formerly $500,000; Spirit Awards, 2022). 
2. Literature Review 
 
 
 
30 
Nevertheless, AV productions are not limited to feature films. They can range from 
commercials to art installations, documentaries to music videos, and TV 
broadcasting to online vlogs. Each AV sector features different characteristics in 
business model and budget size. For instance, $1 million can label a feature film as 
low-budget but can also be an exorbitant budget for a music video. 
This relative labelling further complicates the definition of independent AV 
productions.  
Despite limiting their investigation to a European level only, IDEA Consult (2013) 
reports that the majority (51%) of AV firms that responded to their survey fall in the 
category of less than five employees, which further reinforces the idea that the AV 
industry is ‘is characterized by firms with a weak organizational structure, small 
dimensions, small number of employees’ (La Torre, 2014). 
To improve the findings in this PhD thesis, the researcher considered it appropriate 
to outline an arbitrary definition of the AV productions that represent the population in 
this research. Inspired by the European Union (European Commission, 2022) and 
UK government's (FCDO, 2022) categorization of small and medium enterprises 
(SMEs), this research uses the term small and medium productions to identify those 
AV productions with a maximum budget of $100,000 for medium productions and 
$20,000 for small productions. 
 
For the independent science fiction movie I Am Mother (Last Pixel, 2019), 
independent Australian studio Last Pixel developed a VR application to storyboard 
the film, which is set within a futuristic space similar to a spaceship. Only 10% of the 
movie was set outside of the spaceship. After completing most of the storyboarding 
in VR, director Grant Sputore states, ‘I've gotten so used to storyboarding in this way 
(VR) [that] I wasn't exactly about to go back to pencil sketches on the back of a 
napkin’. 
Similar to Pathfinder, Last Pixel's VR application offers a series of tool sets, such as 
a virtual viewfinder, and the freedom to manipulate the virtual environment.  
 
Filmmaker and software engineer Matt Workman investigated and developed various 
VP processes that are autonomously accessible and usable for independent 
2. Literature Review 
 
 
 
31 
filmmakers. In 2018, Workman developed Cinetracer with Epic's game engine 
Unreal 4, and he continually iterates this tool set. Cinetracer is sold on the video 
game platform Steam, which, through its gamer-friendly user experience (UX) and 
user interface (UI), the game has recently attracted significant interest from the 
filmmaking community, leading Workman to showcase the application at 
conferences such as SIGGRAPH (Unreal Engine, 2019c) and FMX (Cinematography 
Database, 2019). 
Cinetracer is a sandbox (a game genre where there is any specific goal or linear 
story to follow, but which instead provides to the player a great degree of freedom 
and creativity) single-player experience that allows the user to photograph and light 
realistic environments with real-world film equipment. It enables filmmakers to 
virtually pre-visualize (on a 2D computer monitor) the scene they intend to shoot. 
Consequently, they can be more prepared and have the opportunity to explore 
different creative ideas. In Cinetracer, users can set the scene by placing 3D objects 
(set design), lights and cameras (cinematography), or even virtual characters 
(acting) by using elements within Cinetracer's library or importing their own assets. In 
one of his first experiments (Cinematography Database, 2018), Workman captured 
an interior environment using Leica's BLK360, a high-end light detection and ranging 
(LiDAR) scanner that combines 360 photographs and laser data to generate a point 
cloud (each point has unique XYZ coordinates) of the interior that has been scanned. 
Finally, Workman started using Cine Design (a Cinema4D plugin on which 
Cinetracer is based) to add virtual elements such as props, lights, and characters to 
pre-visualize the scene that would be shot in a specific real-world location. Later, the 
point cloud data are elaborated on an iPad Pro through the Autodesk ReCap Pro 
application, and they are converted into a 3D mesh by the 3D modelling software 
Cinema4D. These processes are performed in a 2D modality by interacting with the 
software on an iPad touchscreen or by using a mouse and a keyboard connected to 
a desktop PC. 
 
 
 
2. Literature Review 
 
 
 
32 
2.4 Conclusion of the Literature Review 
This descriptive approach to the current literature that is relevant to VP demonstrates 
the infancy of the field. Although new opportunities enabled by this production 
process have already arisen, many aspects require further investigation. 
 
Overall, the industry is paving the way in developing and experimenting with practical 
VP innovations. If this new production process leads towards time and cost savings, 
then these high-end productions, consider a strategically good investment allocating 
significant resources to their internal R&D departments to advance increasingly 
efficient and effective VP processes,  
 
Academics are motivated to investigate this field, and this PhD work is an example of 
such interest. Some are dedicating their efforts to mapping and coding industry 
trends among high-end productions. However, others argue that the picture they are 
trying to capture will miss crucial pieces. VP processes developed by these high-end 
production companies represent a valuable asset for their owners. They are the 
result of years of R&D investments, and therefore, their owners are interested in 
keeping their knowledge and expertise private and as one of the participants 
interviwed states: ‘If you are not working within Netflix’s virtual production 
department, you will always be late’ (PI04, leading expert). 
In this chapter, some papers published by industry players were used as examples, 
but their work may not be explained in detail in these papers for this reason. 
 
An alternative to rsearch VP, may be integrating researchers in these high-end 
production companies and working closely with industry veterans to improve VP 
processes. However, publishing new knowledge may generate conflicts with these 
private companies’ strategies to maintain the confidentiality of their breakthroughs. 
Additionally, it is important to remember that the aforementioned studios, such as 
MPC or ILM, developed custom VP processes – Genesis and Zeno, respectively – to 
fit and answer their specific needs. Therefore, the research efforts dedicated to 
improving those VP processes are not likely to be extended and generalized to other 
AV production companies. 
2. Literature Review 
 
 
 
33 
Unreal and Unity are focussing their efforts on providing tools to enable more AV 
professionals to use VP, however, as identified by Bennett et al. (2021) and Jobin 
(2022), today few people have sufficient knowledge to set up a VP process. 
 
 
Table 1 High-End VP Virtual Production Characteristics 
ADVANTAGES 
DISADVANTAGES 
A custom VP process is designed to be 
integrated with one’s current and 
specific pipeline. See ILM’s Zeno (Jutan 
& Ellis, 2017) or Technicolor’s Genesis 
(Tovell & Williams, 2018). 
These VP processes are not 
generalizable to other AV productions 
since communication between 
proprietary systems is challenging 
(Kavakli & Cremona, 2022). 
High-quality assets are integrated into 
the virtual scene. While shooting inside 
LED volumes, such detailed imagery 
enables the acquisition of the final pixel 
on set. (Pohl, 2019). 
Establishing high-end VP processes 
requires many highly skilled and 
multidisciplinary professionals 
(Bennett et al., 2021). 
Custom VP processes remain 
confidential and may represent an 
advantage against competitors. 
Custom VP processes cannot be 
improved by those outside the 
company. 
 
Implementing high-end VP processes 
demands significant technical resources 
(Jobin, 2022) 
 
 
Despite partial access to VP's internal structures, paying attention and observing the 
pre-existing high-end VP processes enabled the researcher to determine the need 
for further research in this field. 
 
1. Exploration of additional benefits brought by VP is required. Existing contributions 
by other authors have illustrated the potential of pre-visualizing VFX in camera 
(ICVFX) while shooting (de Goussencourt, Dellac, & Bertolino, 2015; Zimmer et al., 
2. Literature Review 
 
 
 
34 
2017; Spielmann et al., 2018). This real-time visualization favours a quick 
assessment of the shot, which accelerates iteration and decision-making. However, 
many shots or entire AV productions do not require VFX to be added. Additionally, 
many experts refer to VP as an umbrella, but there is no clear definition of VP's 
beginning or end. Therefore, further exploration is required to discover what other 
valuable applications of VP may offer AV professionals.  
 
1.1 Virtual is not limited to LED volumes. Many experts agree that VP is a broad term 
that includes many technologies; hence, it is limiting to think about VP as a process 
that occurs only inside LED volume facilities and only offers ICVFX. 
This association between LED volumes and VP has likely been caused by the most 
emblematic VP realized in recent times: The Mandalorian (2019), which was shot 
inside ILM’s LED volume Stagecraft. However, these facilities represent only one of 
the many combinations that can be achieved between real-time engines and other 
technologies (such as VR and AR). The Lion King (2019) and The Jungle Book 
(2016) were not shot using LED volumes.  
 
This fever for LED volumes is now being reconsidered. Industry expert Nathan 
Bazley (2022) designed a flowchart (presented in Appendix V) that may enable those 
in AV production companies to think twice before deciding to adopt LED volumes. 
Bazley believes that, in many cases, it would be more convenient or economical to 
shoot in real locations or in studios. Similarly, Favreau, after several years of 
extensively using LED volumes, recognized the limit of LED volumes when shooting 
scenes with hard light, such as sunlight. Because of this aesthetic need, Favreau 
and his team opted for a traditional location and set-based shooting for The 
Mandalorian (Desowitz, 2023).  
 
2. VP processes for SMPs are limited. The investigation that was presented in this 
chapter highlights a significant knowledge gap about the benefits that VP can bring 
to AV professionals working in SMPs as opposed to those in large-scale film 
productions. Future researchers should explore the challenges faced by AV 
professionals working in SMPs to better understand their resources and priorities as 
2. Literature Review 
 
 
 
35 
well as the requirements for designing and evaluating successful VP processes for 
SMPs. Not only is this an urgent knowledge gap to fill, but it is also speculated that 
such an investigation could be financially appealing. Leipzig (2014) reports that 
despite the SMPs' small budgets compared to blockbuster production budgets, the 
independent world is composed of a much larger number of projects. Anderson 
(2004) popularizes the long tail concept, pointing to a new business model for media 
consumption and explaining that niche contents (the tail), as opposed to hits (the 
head), represent a new and relevant market: ‘Combine enough nonhits on the Long 
Tail and you have got a market bigger than the hits’. 
 
 
 
Figure 2.3 Adaptation of the Long Tail Concept (Anderson, 2004) 
 
 
3. VP presents limited academic research. Few researchers outside of academia 
have explored opportunities enabled by VP through practical designs. Those 
2. Literature Review 
 
 
 
36 
undertaking this path have focussed on designing and prototyping alternative 
technical VP processes that are limited to specific tasks and, therefore, to specific 
AV roles. Zimmer et al. (2017), Spielmann et al. (2018), and Stamm, Teall, and 
Benedicto (2016) have agreed that their work only scratches the surface of what is 
possible for SMPs and that future scholars should consider technicalities or different 
AV figures. A VP process which by design extends its adaptation to several AV 
functions and better represents the profoundly collaborative nature of the AV 
production process is missing.  
 
3.1 Stakeholder involvement in the design process is missing.  
Researchers developing alternative VP processes have formally involved 
participants during the evaluation phase (Ardal et al., 2019; Trottnow et al., 2015) or, 
alternatively, have collected informal feedback at conferences and events when 
presenting their work (Zimmer et al., 2017; Spielmann et al., 2018). Furthermore, 
they have not provided much detail on the participants’ profiles, the AV sectors 
where they operate, their specific roles, their challenges, or their needs. Previous 
studies have not included space for AV professionals during the design process of 
the alternative workflows enabled by VP. An iterative design process – starting with 
their current challenges, passing through idea co-generation, and concluding with 
evaluating the alternative VP process co-designed with SMP AV professionals – has 
not yet been explored. 
 
The following chapter describes the methodology adopted in this research and how 
this PhD scholar intends to cover the identified gaps in the knowledge. 
 
 
 
 
 
 
 
 
 
37 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Chapter 3 
 
METHODOLOGY 
3. Methodology 
 
 
 
38 
3. Methodology  
 
‘We are like dwarfs on the shoulders of giants, so that we can see more than they, 
and things at a greater distance, not by virtue of any sharpness of sight on our 
part, or any physical distinction, but because we are carried high and raised up by 
their giant size’ Bernard of Chartres. 
 
3.1 Introduction 
Undertaking any kind of research requires scholars, especially novices, to fully 
understand how previous authors have performed this process. 
 
According to Crotty (1998), researchers should frame the research design by taking 
a stance in four hierarchical elements: epistemology, theoretical perspective, 
methodology, and methods. Gray (2004, p. 16) supports the hierarchical nature of 
these elements, which better describes this interdependence: ‘The choice of 
methods will be influenced by the research methodology chosen. This methodology, 
in turn, will be influenced by the theoretical perspectives adopted by the researcher, 
and, in turn, by [the] researcher’s epistemological stance’. Consequently, he further 
advises researchers to start the research process by reflecting on what it means to 
know (2004). 
 
 
Figure 3.1 Four Elements of the Design Process (Crotty, 1998) 
 
The epistemological stance can fall into three categories: objectivism, constructivism, 
and subjectivism (Crotty, 1998). 
3. Methodology 
 
 
 
39 
With an objectivist stance, researchers believe that there is an objective truth to 
discover and that they have no influence on the subject of the investigation. 
Researchers adopting a constructivist epistemology consider themselves to be a part 
of the phenomenon they are researching. They see themselves as inherently 
involved and responsible for affecting the outcome. This belief leads to different 
interpretations and opinions of the phenomenon depending on the researcher. A 
subjectivist stance imposes the subject over the object. The interaction with the 
matter of the study does not affect the meaning. 
 
The epistemological stance a scholar chooses is deeply linked with a specific 
theoretical perspective. Positivism and interpretivism are among the most influential. 
Objectivism is linked to positivism, which states that reality is what is available to the 
senses. It exists separately from the researcher, and enquiries should be based on 
scientific observations. Consequently, positivism is directly linked to quantitative 
research strategies.  
Conversely, constructivism is linked to interpretivism, which asserts that studying 
social reality requires researchers to employ qualitative strategies that are suited to 
investigate abstract and unique phenomena.  
 
After reviewing these different epistemological stances and theoretical perspectives, 
the researcher decided to adhere to the principles of constructivism and take an 
interpretivist theoretical perspective. This decision was made because the 
filmmaking process is a hub of complex, dynamic, and diverse human activities. 
Many stakeholders are involved in the production process, and each has different 
needs, priorities, and capabilities. A successful project depends on the ability to 
comprehend these different viewpoints and combine them. It is challenging to 
examine elements from different perspectives and to understand others’ reality, but 
this is what the filmmaking process is all about: it is a ‘choral’ work.  
 
Adhering to a constructivist stance means that knowledge is considered a human 
construction, and the researcher and participants co-construct understanding. How 
can this be done in practice? Cross (1999, as cited by Feast & Melles, 2010) 
3. Methodology 
 
 
 
40 
suggests that this is possible by making artefacts, meaning that new knowledge can 
be generated after making and reflecting upon these artefacts. This procedure to 
acquire new knowledge inspired the researcher to develop, test, and evaluate a 
design tool (artefact), which became one of the main aims and contributions of this 
PhD work. 
 
Explaining the philosophical stance taken and the reasoning behind it is necessary 
for the reader to appropriately interpret this work (Huff, 2009). Furthermore, since 
PhD is the abbreviation of the Latin term philosophie doctor, which, in turn, comes 
from the Greek meaning ‘lover of wisdom’, the researcher felt obligated to state his 
philosophical stance and his belief towards knowledge.  
 
3.2 Design Research Methodology Framework 
A solid methodological framework on which to lay the foundation is crucial. In the 
words of Frankfort-Nachmias and Nachmias (1996), ‘It is the methodology that 
makes a topic of investigation scientific’. Therefore, searching for previous 
knowledge on how to structure a PhD investigation was necessary. 
This chapter aims to explain the design research methodology (DRM) framework 
and the rationale for its adoption. 
 
Blessing and Chakrabarti (2009) ideated and proposed the DRM framework because 
of the lack of scientific rigour in design research. Today, it is widely accepted among 
researchers (Cifter, 2011; Nickpour, 2012; Wang, 2015). This systematic approach 
allows design researchers to conduct their study efficiently and effectively. The 
framework is divided into four stages which, if executed properly, may lead to the 
generation of new knowledge in the design field. 
 
Research clarification, descriptive study I (DS-I), prescriptive study I (PS-I), and 
descriptive study II (DS-II) are the main stages of the DRM framework ideated by 
Blessing and Chakrabarti. 
3. Methodology 
 
 
 
41 
 
Figure 3.2 Design Research Methodology Framework (Blessing & Chakrabarti, 2009) 
 
 
Research Clarification Phase 
As shown in Figure 3.2, the DRM framework starts with the research clarification 
(RC) phase, which asks the researcher to establish the research focus and goal as 
well as determine why it is worthwhile to investigate that specific problem and what 
contribution is expected. Additionally, Blessing and Chakrabarti (2009) recommend 
defining a clear initial reference model, which will be used to evaluate the final 
outcome (design support) of the research. Developing a design support is possible 
after an extensive review of the work of previous researchers in the chosen field. The 
RC stage profoundly influences the next stages of the DRM framework, as it 
elucidates which approaches and methods are ideal to gather data during DS-I to 
better understand the context and the problems around the topic. RC also guides the 
development of support for the PS and its evaluation during DS-II. 
 
3. Methodology 
 
 
 
42 
Descriptive Study I  
DS-I allows the researcher to understand the complexity of the problem and provides 
insights on how to develop (PS stage) and later (DS-II stage) evaluate the support 
that was established for the PS. According to Blessing and Chakrabarti (2009), this 
understanding can be obtained by reviewing the literature regarding empirical 
research or undertaking empirical research.  
 
Prescriptive Study I  
At this level, the researcher wants to create a design support system to answer a 
particular requirement or issue identified in RC and DS-I. It is critical to have 
specified at this stage the researcher’s perspective on the function of the support, 
how it will be assessed, and how it will affect the initial reference model. The goals of 
this stage are to construct an expected support based on the findings of DS-I, to 
define how the support is intended to be utilized, and to build a strategy for its 
assessment in DS-II. 
 
Descriptive Study II 
This step requires the researcher to evaluate the support developed. Blessing and 
Chakrabarti (2009) distinguish two types of evaluation: application evaluation, which 
is concerned with determining the usability and applicability of the design support, 
and success evaluation, which is concerned with determining whether the support 
has the desired impact. 
After conducting the empirical studies needed, the outcome of the evaluation is 
compared with the initial reference model. 
 
3.2.1 Using and Adapting the Design Research Methodology Framework  
This section explains the DRM framework's ideal suitability for answering the three 
research questions in this study. The framework established a systematic approach 
that led the researcher to a specific outcome in each stage. First, through the RC 
stage, it was possible to answer RQ1.1. The activity related to this stage was a 
literature review of academic studies and a critical review of innovative processes 
employed by industry professionals. RQ1.2 was answered upon successful 
3. Methodology 
 
 
 
43 
completion of the DS-I (exploratory interviews to understand the context where 
SMPs operate) and DS-IIA (confirmation of DS-I findings). Then, PS-I and the 
following iterations led to the creation of design support, which, according to Blessing 
and Chakrabarti, is the ultimate goal of design research (p. 33). Developing and 
iterating design support was necessary to answer RQ1.3. 
 
In addition to this clear distinction between these stages, Blessing and Chakrabarti 
(2009) state that the DRM framework is intended to be flexible and adjusted 
depending on the specific researcher’s needs. According to Fricke (1993), 
structuring a custom approach for one’s research goal leads to better results 
compared to researchers who follow a predefined research process step by step. 
Reich (1995) further supports this statement. When critically reviewing a 
mathematical theory of design, such as the general design theory. Reich expresses 
that existing methodologies should be seen as a models from which to take 
inspiration rather than a strict diktat to follow. Hence, Figures 3.3; 3.4 and 3.5 
illustrate which aspects of the DRM framework were adapted to better suit this 
investigation’s purpose. 
 
3. Methodology 
 
 
 
44 
 
Figure 3.3 Research Methodology: Stages, Activities, Methods, and Outcomes (part one) 
3. Methodology 
 
 
 
45 
 
 
Figure 3.4 Research Methodology: Stages, Activities, Methods, and Outcomes (part two) 
3. Methodology 
 
 
 
46 
 
 
Figure 3.5 Research Methodology: Stages, Activities, Methods, and Outcomes (part three) 
3. Methodology 
 
 
 
47 
 
As new information is gathered and processed, researchers commonly re-examine 
previous considerations and reinterpret assumptions made in earlier stages of the 
process. Adding iterations, such as PS-I, in combination with iterations of DS-I 
allowed the researcher to continuously improve and evaluate the design support 
generated, leading, in DS-IV, to the development of highly detailed design support, 
which in turn enabled the researcher to draw reflections from it. 
 
 
3.3 Co-Design  
According to Sanders and Stappers (2008), co-design refers ‘to the creativity of 
designers and people not trained in design working together in the design 
development process’. This approach of actively involving participants is not new. It 
was already in use in the '70s in Norway, Sweden, and Denmark, where workers 
were encouraged to create new workplace systems to improve the value of industrial 
production. The Scandinavian participatory design (PD) movement was not isolated 
in this current of thought; many other researchers, such as Papanek (1972) and 
Cross (1972), started shifting their attention towards this design approach where 
users are not only passive subjects but also collaborators involved in the design 
process. 
 
Figure 3.6 illustrates the distinction among different human-centred design research 
approaches. 
 
3. Methodology 
 
 
 
48 
 
Figure 3.6 Nature of This Research Within the Design Research Landscape 
 
 
This replacement of the term PD with co-design, is relatively new, which contributes 
to confusion among researchers (2008). 
In this regard, Szebeko and Tan (2010) distinguish between the terms, explaining 
that co-design requires researchers to engage participants from the beginning to the 
end of the design process. In PD, this can be limited to a specific stage. 
Aware of this distinction, this researcher refers to all collaborative activities as co-
design because participants were crucial in developing, iterating, and evaluating 
different design ideas.   
Nevertheless, it was considered valuable to consider the PD principles outlined by 
Spinuzzi (2005) because co-design is rooted in PD. Additional considerations on 
how to engage participants in the research process were provided by other authors: 
Muller et al. (1993), Bødker, Kensing, and Simonsen (2004), Schuler (1993), and 
Robertson and Simonsen (2012). 
 
led by design
led by research
user
as partner
user
as subject
critical design
probes
usability testing
human factors and 
ergonomics
contextual
inquiry
lead- user 
innovationi
nquiry
design and
emotion
user- centered design
particpatory design 
research
"Scandinavian"
generative design 
research
generative 
tools
This
Research
3. Methodology 
 
 
 
49 
Co-design is a specific approach to constructing an item (a product, a service, an 
interface, a building, etc.). Consequently, it shares the same goal as the design itself: 
changing existing situations into preferred ones. How? This is where co-design 
differs from other design approaches, such as user-centred design. User-centred 
design is a common approach in which trained researchers observe and interview 
primarily passive users whose role is to perform prescribed activities and provide 
feedback on product ideas generated by others. User-centred design was the most 
effective product design approach in the '90s, but its current usefulness is debatable 
(Sanders, 1992). The modern complex world requires a more holistic, 
multidisciplinary approach, according to Sanders and Stappers (2008). In this 
scenario, it is preferable to work on the purpose of a specific design solution rather 
than on product-specific features. 
  
Co-design is also recognized as appropriate when envisioning the future use of 
immersive technologies, and Robertson and Simonsen (2012) as well as Sanders 
and Stappers (2008) indicate that co-design is a mutual learning process for both 
designers and users. Designers keep track of existing technologies and their unique 
features, limits, and business contexts. They are aware of the state of the art and the 
latest advancements in such technologies. Therefore, they can share this knowledge 
with users, informing and prompting them towards the generation of innovative 
ideas. In turn, users inform designers and researchers of their context, process, 
abilities, habits, and preferred scenarios.  
Actively involving users is the key to discovering the current situation and giving 
insights and inspiration to the researcher to envision new solutions as believed by 
Robertson & Simonsen (2012) when stating: ‘If we are to design the futures we wish 
to live, then we need those whose futures they will be to actively participate in their 
design’. 
 
As expressed in Chapter 1, the research purpose is to investigate the opportunities 
that new immersive technologies present to the AV field. As explained, the human 
component in the AV field is dominant throughout the production process. Therefore, 
the researcher believed it to be crucial to consider the opinions, perspectives, and 
3. Methodology 
 
 
 
50 
ideas generated by users and stakeholders. Furthermore, stakeholders must 
participate in the co-designing process since the aim behind RQ1.3 is to generate 
design support that might be introduced in their current workflow. 
The process of generating innovative ideas together with participants is described in 
Chapter 5 where participants were involved in remote 1 workshops using online tools 
such as Mural (2023) facilitating collaboration and discussions.  
 
3.4 Design Fiction  
The term design fiction was created by science fiction author Bruce Sterling in 
Shaping Things (2005). Sterling describes design fiction as the act of ‘deliberate 
blurring of fact and fiction’ and later as ‘the deliberate use of diegetic prototypes to 
suspend disbelief about change’ (Sterling, 2013).  
It is essential to introduce design fiction by citing Sterling because his contribution 
increased awareness in the scientific community that imagination can be the fuel for 
fiction and science. Many modern inventions have been inspired by fictional stories 
shown in cinema and television or told in science fiction books. 
Before being fully functional real-world inventions, these ideas were presented in 
fictional media as diegetic prototypes, according to David Kirby, author of The Future 
Is Now: Diegetic Prototypes and the Role of Popular Films in Generating Real-World 
Technological Development. Among the many examples, Kirby offers one relevant to 
the nature of this thesis because it relates to the real-world impact of a story based 
on VR technology. He considers the science fiction movie The Lawnmower Man 
(1992) and explains that its production required the development of several diegetic 
prototypes to represent the virtual world exploited by the protagonist. This movie 
highlights ‘the potential of virtual reality and three-dimensional (3-D) interactive 
technologies’ to the public, and ‘the diegetic prototypes developed directly resulted in 
funding opportunities and the ability to construct real-life prototypes’. To extend 
Kirby’s observation into the present, it is possible to examine another movie: 
Spielberg’s Ready Player One (2018), based on Ernst Cline’s novel of the same 
name. This movie depicts not only VR technology but also the metaverse (a network 
of virtual worlds accessible via the internet) and presents many of the implications 
(social, cultural, economic, etc.) of such a speculative scenario. 
3. Methodology 
 
 
 
51 
In recent years, many researchers have been interested in exploring design research 
through design fiction (Auger, 2013; Bleecker, 2009; Grand & Wiedmer, 2010; 
Markussen & Knutz, 2013; Morrison, Tronstad, & Martinussen, 2013; Rattay, 2019). 
 
 
Figure 3.7 Science Fact and Science Fiction According to Rattay (2019) 
After research to understand why many academics adopted design fiction for their 
studies, it was noted that such an approach can encourage a creative and open 
environment to grow and foster bold and provocative ideas (Figure 3.7).  
Approaching design research using design fiction means answering what-if 
questions in relation to a specific future scenario where new technologies are likely. 
Such a question aims to initiate a critical discussion around the many implications 
introduced by a fictional but probable and preferable scenario. 
Huusko et al. (2018) support the idea that integrating design fiction elements into the 
co-design strategy may be beneficial for those scholars wanting to envision the 
introduction and development of new technologies. Consequently, during the co-
design workshops held during DS-IIA, DS-IIB, and PS-II, the two design approaches 
were combined with the expectation of obtaining valuable data. 
 
 
 
3. Methodology 
 
 
 
52 
3.4.1 Diegetic Prototypes 
Diegetic prototypes explain future technological needs and feasibility to viewers 
(Kirby, 2010); in this study, they were developed and employed in DS-III. Diegetic 
prototypes were preferred to other techniques, such as cards scenarios, which 
describe a hypothetical scenario without giving many details (Lucero et al., 2016). 
Card scenarios is a technique used mainly in workshops to start the conversation 
around a topic but leaves participants with the duty of extending that initial scenario. 
Since this degree of freedom was granted while participants brainstormed ideas in 
PS-II, diegetic prototypes were considered ideal for facilitating an in-depth 
assessment and evaluation of participants' design fiction scenarios. 
 
3.5 Study Design 
The researcher adhered to the principles of constructivism and assumed an 
interpretivist theoretical perspective; consequently, qualitative rather than 
quantitative methods were employed to undertake this research. 
 
3.5.1 Design Methods 
A complex issue with people at its centre, such as the one examined in this study, is 
challenging to capture with existing measures that reduce participants to a statistical 
mean that overlooks the uniqueness of individuals (Creswell, 2013). Therefore, this 
researcher almost exclusively used qualitative methods to collect data. 
 
As reported and reviewed in Chapter 2, VP is a recent AV production process, and 
advancements are evolving quickly. Therefore, listening to experts share their 
previous experiences in the field is essential when planning to investigate such a 
new topic. Concurrently, understanding which perspectives of stakeholders to 
enhance is crucial. Qualitative methods are often used to collect people’s thorough 
perspectives, to acquire insights into problems, and to identify a phenomenon that 
has not been studied (Flick, Kardoff, & Steinke, 2004) or to identify when an issue 
should be explored (Creswell, 2013). According to Creswell, qualitative researchers 
want precisely this: ‘to empower individuals to share their stories, hear their voices’ 
(Creswell, 2013, p. 48). 
3. Methodology 
 
 
 
53 
 
Qualitative methods such as interviews, workshops, observations, and 
questionnaires were used to collect data. Due to the COVID-19 pandemic, these 
methods had to be restructured, sometimes slightly and sometimes considerably. 
Social research had previously been conducted online (Lupton, 2020), but the 
pandemic forced this manner to become the norm. In this regard, Lupton created a 
crowdsourced document containing many techniques for fieldwork that avoid in-
person interactions. Some of them, such as online interviews and video-based co-
design workshops, were used for this study. 
 
DS-IV participants tested the design support ideated and evaluated its effectiveness 
and usability; consequently, qualitative methods, such as observations and group 
discussion, were combined with quantitative methods. Participants were asked to 
complete a survey based on the technology acceptance model (TAM; Davis, 1989). 
Quantitative methods are, in fact, usually employed when testing an existing theory 
(Bryman, 2016). In DS-IV, the goal is to understand better the design support that 
might benefit the stakeholders. 
 
According to Creswell (2013), deciding to use both qualitative and quantitative 
methods in the same research can enable the researcher to acquire a significantly 
deeper understanding of complex topics. This mixed-methods approach was 
adopted during DS-IIB, DS-III, and DS-IV. 
 
3.5.1.1 Interviews 
Throughout the history of social sciences, interviewing subjects to gather data has 
been widely used in qualitative research. Interviews are fundamental to understand 
how subjects experience and see the world. According to Frey and Fontana (1991), 
three types of interviews are commonly used: structured, unstructured, and semi-
structured. During structured interviews, each participant receives an identical set of 
questions. Conversely, those conducting unstructured interviews use a more 
conversational and casual approach. This type of interview is used when the 
objective is to have a more profound, complete, and authentic reply from the 
3. Methodology 
 
 
 
54 
participants. In semi-structured interviews, the researcher asks participants several 
specific questions but also allows participants to take the initiative and discuss 
related topics with flexibility.  
 
For this study, in-depth semi-structured online interviews with professionals working 
in the AV field were planned for the DS-I stage. During this phase, the goal was to 
collect data regarding current pre-production, production, and post-production 
practices. Starting with exploratory interviews, the researcher investigated the 
current challenges and issues in many different roles (director, cinematographer, set 
designer, producer, etc.). Understanding the context and the current pain points in 
each role was necessary to understand the context where SMPs operate. 
 
3.5.1.2 Workshops 
The word workshop initially identified a ‘room or building where things are made 
or repaired using machines and/or tools’ (Cambridge University Press, 2022). 
However, this term is now part of everyday language and can be applied in different 
contexts. In design research, a workshop can be identified as ‘an arrangement 
whereby a group of people learn, acquire new knowledge, perform creative problem-
solving, or innovate to a domain-specific issue’ (Ørngreen & Levinsen, 2017). These 
arrangements can be held in person or remotely, and the researcher or facilitator 
plans numerous tasks to gather data for the study. For example, a workshop may 
begin with an introduction to a specific topic and continue with group discussions and 
creative activities, such as brainstorming, mapping, creating collages, or drawing. 
Typically, simple tools are provided to participants to generate ideas, drawings, and 
mock-ups. Organizing a workshop is challenging, but it can lead to acquiring a 
substantial volume of precious data to further analyze and discuss. The design 
workshop approach is often used in generative research, in which individual 
participants or groups generate and validate design direction in response to a design 
challenge or brief. Workshops may also be utilized as an evaluative tool, in which 
participants are asked to assess ideas, provide input, and offer insights into the 
design iteration and improvement process (Hanington & Martin, 2019). 
 
3. Methodology 
 
 
 
55 
After gathering initial data through exploratory interviews during DS-I, the researcher 
determined the most appropriate structure for the workshops. It was possible to unite 
different stakeholders and create an environment where they could freely exchange 
thoughts and be inspired by each other’s inputs. However, it is essential to mention 
that there were many difficulties in engaging with professionals, as they have little 
time to dedicate to academic and non-paid activities. 
An additional challenge was posed by the COVID-19 restrictions, which did not allow 
arrangement of physical workshops. Therefore, it was necessary to consider 
alternative solutions. In this regard, the online service MURAL was identified as 
functional for the workshops. This service was specifically designed for virtual 
workshops; all participants and the facilitator were provided with a series of digital 
tools similar to those commonly used during in-person workshops, including 
interactive sticky notes, boards, stopwatches, tables, images, and much more.   
Brainstorming was one of the most useful activities that led to the generation of 
many ideas to further discuss and evaluate. The basic concepts and initial ideas 
resulting from this activity were refined in PS-II and used as a starting point for DS-
III. 
 
3.5.1.3 Questionnaire 
In DS-III, the researcher considered it useful to adopt a questionnaire to collect 
quantitative and qualitative data on three design fiction scenarios that were 
generated during PS-III; these were presented in the questionnaire as written stories. 
Quantitative data were meant to be captured by adapting Davis' (1989) TAM and 
other closed-ended questions. 
For collecting qualitative data, some open-ended questions asked respondents to 
explain the reasoning behind their answers to closed-ended questions. 
After analyzing the questionnaire data, the researcher filtered from the three 
scenarios that which would be most valuable for AV professionals and could be 
further developed into a prototype in PS-IV. 
 
The questions that asked participants to evaluate the perceived usefulness and ease 
of use of elements that were presented in the DS-III design fiction scenarios were 
3. Methodology 
 
 
 
56 
also asked of participants who experienced the prototype firsthand in DS-IV. This is 
because the researcher considered it significant to collect participants’ feedback on 
the concrete implementation of the design fiction scenario.  
 
3.5.1.4 User Testing  
As a result of findings from DS-III, an actual prototype was designed, developed, and 
tested. During PS-II, the researcher planned to identify and extend one of the 
concepts generated during the workshops. The choice of which concept to develop 
was determined by (a) the degree of innovation a specific concept represented and 
(b) the degree of technical feasibility that participants believed would offer real 
benefits according to considerations they made throughout the study.  
 
To evolve the chosen idea into a basic prototype, it was crucial to identify and test 
pre-existing hardware devices and software applications considered appropriate to 
achieve such a result.  
Different groups of AV professionals tested the prototype, which had been ideated 
during an in-person user testing session in which the researcher was a facilitator.  
Both quantitative (through a post-experience questionnaire) and qualitative data 
(through a group discussion) were collected. 
The same TAM adaptation employed in DS-III for the online questionnaire was used 
to evaluate the questionnaire. Evaluating the qualitative data was inspired by the 
framework proposed by Horvat et al. (2022), and the prototype testing is further 
explained in Section 7.5.1. 
 
3.5.2 Data Analysis Methods 
One of the key challenges in using qualitative methods is that they generate 
substantial data (Bryman, 2016). To analyze participants’ responses to interviews, 
workshops, open-ended questions, transcripts, and discussions among participants 
during workshops, thematic analysis was considered appropriate for this study due 
to its flexibility (Braun & Clarke, 2006). In fact, during this phase, thematic analysis is 
instrumental in identifying common themes across participants’ interviews. The vast 
3. Methodology 
 
 
 
57 
amount of data generated by using qualitative methods means that keeping track of 
all the materials can be an issue (Bryman, 2016). 
The computer-assisted qualitative data analysis software NVivo12 was used to 
organize, analyze, and find insights into qualitative data sources, such as interviews 
(Lewins, 2001). After transcribing each interview, data were coded and later grouped 
into general themes. The qualitative data analysis process has three phases: 
transcribing, coding, and grouping (Cho & Lee, 2014). The original qualitative data 
were first filtered and transcribed to be analyzed and detailed for further analysis 
(Bailey, 2008). Participants’ social talking that was irrelevant to the study topic was 
not reported in the transcription.  
Quantitative data analysis derived from the questionnaire in DS-III and DS-IV were 
manually imported in Excel, and the frequency with which each option was selected 
for the closed-ended questions was calculated. 
 
3.5.3 Sampling 
Many sampling techniques can be employed to conduct social science research, 
depending on the nature and type of the research (Etikan et al., 2016). Because of 
the exploratory nature of this study, the researcher decided to adopt non-random 
sampling techniques, such as purposeful and snowball sampling. 
 
Such techniques are employed when researchers have limited time and resources 
as well as when the goal is not to make population-wide generalizations (Etikan et 
al., 2016). One of this technique’s limitations is that participants are selected based 
on subjective criteria established by researchers. 
However, one of the advantages of purposeful sampling is that participants receive 
in-depth and detailed information about the topic under investigation.  
 
The criteria were determined based on the knowledge gap identified in the literature 
review, which indicated that the exploration of the VP process for AV professionals 
with limited resources has yet to be investigated. Therefore, among the population of 
AV professionals, participant selection was based on the budget and team size of 
the productions in which they were usually involved. 
3. Methodology 
 
 
 
58 
 
After having identified a number of participants through purposeful sampling, the 
researcher also adopted snowball sampling, a technique where participants suggest 
additional people who may want to be involved in the study. To do so, the researcher 
provided instructions about the kind of participants to involve in the study. 
 
Snowball sampling (Parker, Scott, & Geddes, 2019) proved crucial in increasing the 
sample size and tackling the critical challenge of involving AV professionals as 
participants. These people  are immersed in a highly stressful environment (Alony, 
Whymark, & Jones 2007) and work long hours (Hesmondhalgh & Baker 2010), 
having little time left to dedicate to other activities. In fact, due to the insular nature of 
the AV industry, the researcher found it difficult to engage people in the film and TV 
industry as participants.  
 
As with the critiques of purposeful sampling, snowball sampling is criticized for the 
biases associated with participants suggesting additional participants. However, as 
this is exploratory research, external validity is not sought (Parker, Scott, & Geddes, 
2019). This researcher aimed to lay the groundwork in this new field, and future 
works will strengthen the generalization of the findings. 
 
Additionally, it is essential to mention a characteristic of the current AV industry. In 
Local Hollywood, Goldsmith (2010) explains that major studios and SMP enterprises 
(p. 87) commonly split some of the AV production processes across the globe. 
Goldsmith describes this phenomenon as a cross-pollination of places, people, and 
service providers that pushes the development of common approaches so that 
everyone is on the same page and both people and places become interchangeable 
and interoperable (p. 20). An additional analysis on the AV players' current strategy 
is offered by Lotz (2021), who reports the case of the streaming service and 
production company Netflix: ‘Examining the locations in which Netflix has established 
production facilities shows a multinational presence’. He continues, ‘Netflix largely 
relies on contracting other production companies to make its series and films’. 
Relying on existing companies in a specific country means involving professionals 
3. Methodology 
 
 
 
59 
from that country who are compliant with international standard processes 
(Goldsmith, 2010, p. 153). 
Therefore, potential biases that are introduced by recruiting professionals from one 
cultural context rather than another have relative importance since the workflows for 
AV productions are rather homogeneous. 
 
Additional and more specific details about the participants are provided in each 
chapter where fieldwork is presented and discussed. Table 2 presents an overview 
of the participants involved. 
 
Table 2 Participant Sampling Strategy 
Phase of 
DRM 
Research methods Sampling technique 
Sampling 
size 
Participants involved 
in previous phases 
Code name 
DS-I 
Semi-structured 
interview 
Purposive sampling 
Snowball sampling 
20 
participants 
/ 
PI  
(participant 
interview) 
DS-IIA 
PS-II 
DS-IIB 
Co-design online 
workshop 
Purposive sampling  
Snowball sampling 
15 
participants 
1 
PW  
(participant 
workshop) 
DS-III 
Questionnaire 
Purposive sampling   
Snowball sampling 
30 
participants 
12 
PQ  
(participant 
questionnaire) 
DS-IV 
User testing 
Purposive sampling 
Snowball sampling 
29 
participants 
5 
PT  
(participant 
testing) 
 
Some participants were involved in multiple phases of the research because they 
were considered gatekeepers who were able to add new participants.  
 
The research involved 94 participants, 76 of whom were involved in one research 
phase only. Consequently, the vast majority of participants were new to the research 
and could objectively evaluate what was discussed and generated in previous 
phases by other participants. Such a strategy further strengthened the studies. 
3. Methodology 
 
 
 
60 
Furthermore, the AV industry includes a variety of professionals with diverse 
responsibilities and needs; therefore, throughout the research, people in different 
roles were involved, such as directors, assistant directors, executive producers, 
producers, assistant producers, cinematographers, camera operators, set designers, 
editors, sound designers, 3D artists, VFX artists, and VP experts.  
 
3.5.4 Limitations Due to COVID-19  
The ethnographic approach was initially born in the late 19th century to research 
cultures, human behaviour, and social relations in the Western colonies. Design 
ethnography was initially considered an appropriate design method to create 
empathy with stakeholders involved in the design process. Adopting such an 
approach requires researchers to examine issues from the perspective of the 
subjects under study (Stickdorn et al., 2011).  
To do so, typically, an ethnographic approach begins with the researcher identifying 
and interacting with the so-called gatekeeper, an individual who is a member of a 
cultural group. This gatekeeper is the initial contact for the researcher and leads the 
researcher to other participants (Hammersley & Atkinson, 1995). According to 
Creswell (2013), the researcher is then required to spend extensive time in the field 
to collect data on the field issue and form an insider perspective. 
 
However, due to the state of emergency caused by the COVID-19 pandemic, this 
approach was challenging or, in many cases, not possible. Consequently, the 
researcher’s previous work experience in the AV field was helpful since he could act 
as a gatekeeper himself. Additionally, this researcher’s background simplified the 
decoding of tacit knowledge rooted in participants’ stories and anecdotes throughout 
the research process. 
 
3.6 Chapter Summary 
This chapter described the systematic procedure developed and implemented to 
investigate to what extent the VP process can be adopted by SMPs. It explained the 
novel methodology employed to fill the current gap of knowledge which sees 
filmmakers out of the ideation and development process discourse when designing 
3. Methodology 
 
 
 
61 
new VP processes. For this reason, it was thought as optimal to adopt a co-design 
approach and therefore involve filmmakers from the beginning to the end of the 
research process. Adopting such research process to investigate a field such as VP 
is currently missing in the literature and considered optimal to build and validate new 
knowledge. A detailed description of each step of the research process undertook is 
explained in Figure 3.3. when introducing the DRM framework by Blessing and 
Chakrabarti and how it was adapted to better suit the goal of this PhD thesis.   
 
Qualitative and quantitative methods were used, including interviews, workshops, 
questionnaires, and user testing. After acknowledging the impact of an external 
factor in the COVID-19 pandemic, the researcher employed and adapted a mix of 
remote and in-person data collection methods to meet the research goal. 
 
In the following chapters, the research questions are answered through different 
studies (DS-I, DS-II, DS-III, PS-I, and PS-II), and the objectives, design, samplings, 
data collection, and data analysis of the study are explained with more details. 
 
 
 
 
62 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Chapter 4 
 
EXPLORATORY STUDY 
 
 
 
 
 
 
 
 
 
 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
63 
4. Exploratory Study (DS-I, PS-I) 
 
4.1 Introduction 
Conducting interviews was considered by the researcher to be the most appropriate 
technique because of the novelty of VP, as detailed insights were required from 
participants who adopted this process in the past or might benefit from its use in the 
future. 
 
According to O’Leary’s (2010) study process, there are four stages in an interview: 
(a) planning the interview, (b) developing the interview questions, (c) conducting the 
interview, and (d) analyzing the data. In the preparation stage, the researcher 
identified the participants, the time and location for the interviews, and how the 
interview would be conducted.  
 
4.2 Aim 
The researcher expected that data gathered from the interviews would enable a 
better understanding of the current workflow, challenges, and issues that AV 
professionals encounter daily. The researcher also expected that people in different 
roles would provide different answers because of their different perspectives 
regarding a production. 
An additional goal of this study phase was to identify the user requirements for a 
potential immersive application capable of assisting stakeholders in their work. In this 
regard, at the end of each interview, a simple conceptual workflow ideated and 
proposed by the researcher was presented to prompt participants to evaluate and 
eventually further develop the workflow proposed with new insights and feedback. 
 
4.3 Method 
The study involved 20 AV professionals in semi-structured, one-on-one online 
interviews. Establishing the appropriate number of participants for in-depth 
interviews is not a trivial decision, and Hennik et al. (2016) offer an answer this 
question. In their study, they interviewed 25 participants and find that, after 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
64 
interviewing nine participants, the range of thematic issues was identified. 
Nonetheless, only after 16-24 interviews did they develop a rich understanding of the 
issue. Additionally, O’Reilly and Parker (2013) agree that the interview process 
should continue until no new insights are added and no new patterns emerge from 
the data. Within the context of this study, the saturation of the analysis codes was 
reached after interviewing two thirds of the participants. The final one third of 
interviews reinforced and added detail to the themes, thereby offering slightly 
different perspectives on the various topics identified. This addition was helpful not 
only for noting all the issues raised by the stakeholders but also for gaining a deeper 
understanding of the problem and its context.    
 
4.4 Participants 
The 20 study participants were all active in the AV industry at the time of the study 
and worked in a variety of AV sectors (feature ﬁlms, short ﬁlms, documentaries, 
commercials, music videos, and video art). The participants were based in the US 
(9), Canada (1), UK (3), and Italy (7). The majority (85%) were 25-40 years of age, 
which is the generation referred to as millennials (Strauss, 1991). Millennials have 
grown up experiencing digital technology and represent the next generation of 
ﬁlmmakers. Three participants were over 40 years of age, two of whom were leading 
VP experts.    
The sample of participants comprised relevant stakeholders (18) and leading experts 
(2). The ﬁrst group included those involved in the pre-production phase of a project, 
such as directors and cinematographers, who operated in SMPs. As the potential 
users of the final workflow resulting from this study, they were well suited to share 
their current approach to location scouting, to comment on pre-production 
challenges, and to offer a reliable evaluation of the conceptual workflow in the form 
of a diagram in Figures 4.2 and 4.3) ideated and proposed by the researcher based 
on the critical analysis of the literature review. The participants in the second group 
were leading VP experts whom the researcher chose to involve to gather more 
information on the state-of-the-art technology and to listen to their experiences 
adopting the technology in major blockbuster productions. In addition to providing 
expert input, the second group commented on speciﬁc stakeholder needs for 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
65 
participation in high-end structured productions. This clariﬁcation diﬀerentiated the 
needs of stakeholders in high-end productions as opposed to those in SMPs. Seven 
of 18 participants worked on projects involving real-time technologies, VR, and AR, 
while the remaining 11 understood the macro concepts surrounding immersive 
technologies and how they can be adopted.  
Table 3 Summary of the Total Participant Pool (Interviews) 
PARTICIPANT ROLE 
DESCRIPTION 
PI01 
First assistant 
director 
Assisting directors and producers on daily tasks 
PI02 
Producer 
Overseeing the entire process and actively seeking funding 
PI03 
Cinematographer 
Operating cameras and lighting on set, working closely with 
director 
PI04 
Leading expert 
Designing and overseeing the VP process on blockbuster 
movie production 
PI05 
Leading expert 
Designing and overseeing the VP process on blockbuster 
movie production 
PI06 
Producer 
Overseeing the entire process and actively seeking funding 
PI07 
Producer 
Overseeing the entire process of commercials 
PI08 
Director 
Directing short ﬁlms and commercials 
PI09 
Director 
Directing short ﬁlms and commercials 
PI10 
Cinematographer 
Operating cameras and lighting on set, working closely with 
director 
PI11 
Director 
Directing short ﬁlms and commercials 
PI12 
Cinematographer 
Operating cameras and lighting on set, working closely with 
director 
PI13 
Director 
Directing short ﬁlms 
PI14 
Director 
Directing short ﬁlms 
PI15 
Producer 
Overseeing the entire process and actively seeking funding 
PI16 
Director and 
producer 
Overseeing the production of corporate videos and social 
media content 
PI17 
Producer 
Involved during the development phase of a project 
PI18 
R&D video 
technician 
Designing systems for remote and low-latency live streaming 
services 
PI19 
Set designer 
Involved during the preparation of independent film and TV 
sets 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
66 
PI20 
Video consultant 
Involved by companies to design video strategies and 
oversee production 
 
4.5 Procedure 
Semi-structured interviews were conducted using videoconferencing software. Each 
of the interviews were approximately 60 minutes in length. The data generated by 
each interview were recorded through interview scripts. Interviews were performed in 
either English or Italian. Responses from non-English speaking participants were 
transcribed and translated into English. 
 
The interviews were split into two parts. The ﬁrst part was conducted to acquire a 
broad view of the participants’ perspectives on their challenges during the pre-
production phase of an AV project, especially when they are required to shoot in a 
real-world location. In the ﬁrst part of the interview, four standard ethnographically 
oriented questions were used to learn more about participants and their background. 
Participants were asked about their job titles, years of experience, previous projects, 
and challenges faced in the making of their projects: 
 
1) Could you brieﬂy tell me more about your background and your role today? 
2) What is your experience and knowledge about immersive technology? 
3) What are your challenges when doing pre-production for a project? 
4) What are your challenges when dealing with location scouting? 
 
The ﬁfth question presented the core of the interview and allowed participants to 
freely envision ways of taking advantage of immersive technologies: 
5) How can immersive technology, such as VR and AR, solve some of these 
challenges? 
 
The second part of the interview was dedicated to presenting the conceptual 
workflow ideated by the researcher to each participant for empowering stakeholders 
during the pre-production phase. After presenting the proposed workflow, 
participants provided their feedback, offered new ideas, and asked questions to gain 
a deeper understanding. 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
67 
 
4.6 Findings 
After completing the interview process, data were analyzed, following the six steps in 
the analysis phase presented by Braun and Clarke (2006). The main goals of this 
phase were to (a) identify the most relevant and common themes emerging from the 
data gathered, and (b) express feedback on the conceptual workflow presented in 
the second part of the interview. To facilitate the thematic analysis, Nvivo12 (QSR 
International, 2021) was employed to process the data (interviews’ transcripts). 
Initially, the process involved a phase of data familiarization, followed by the 
systematic coding of transcripts to identify relevant insights. Subsequently, main 
themes emerged from the coded data were named and reported in detail in the 
following chapter. 
 
4.7 Discussion (PS-I) 
The data collected from the participants allowed the researcher to identify daily 
challenges that were common to all participants involved in SMPs and those that 
were role-speciﬁc. 
 
4.7.1 Common Challenges 
Making a professional AV production requires coordination of contributions from 
people with diﬀerent skill sets, from pre-production to post-production. 
 
Consequently, eﬃcient communication across the diﬀerent departments throughout 
the process was identiﬁed as key by most participants. The way that needs, issues, 
tasks, and ideas are communicated is crucial regardless of whether the information 
shared regards technical details on where to park the truck outside the location or 
creative ideas, such as the eﬀects that need to be achieved through lighting. 
 
Preparation is crucial to avoid unexpected problems during shooting, which is 
generally the most expensive phase of the entire process, and to enable the 
exploration of different creative solutions. 
 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
68 
A combination of communication and preparation is pre-visualization. Participants 
noted that pre-visualization is useful in the pre-production phase. Even a rough 
visual representation of how the creative people, generally the director, envision the 
scene can significantly facilitate communication across the whole team. This visual 
information is beneficial not only for the director’s creative collaborators, such as the 
cinematographer and costume designer, but also for those in more organizational 
roles, such as the producer or assistant director, who are required to plan and 
manage the production. 
 
 
Figure 4.1 Established Linear AV Workflow 
4.7.2 Role-Specific Challenges 
a) Directors  
When approaching an AV production, directors are responsible for identifying the 
optimal way of visually translating what is written on the script. This involves 
coordination of different people’s roles to enable directors to achieve their vision. 
However, as PI10 (cinematographer) stated, ‘not everybody speaks the same 
language’. The same words of a script can be interpreted diﬀerently by diﬀerent 
readers. Consequently, aligning all crew members to the same vision is one of the 
main challenges for directors throughout the production process, particularly during 
pre-production. Different visual materials, such as mood boards, are currently used 
to address this challenge. This can be combined with detailed storyboards to share 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
69 
proposed solutions. These approaches can also be useful when directors are 
seeking funding and need to pitch their project to potential funders. 
 
b) Cinematographers  
Crucial in recreating the optimal visual appearance of the project, cinematographers 
propose the most appropriate creative and technical solutions to directors. They 
have a keen eye for images and deep knowledge of required technical gear (e.g., 
cameras, movements, lenses, ﬁlters, and lights) to fulﬁl the director’s vision. 
Nevertheless, sometimes it is not possible for them to anticipate which ﬁlming and 
lighting equipment are ideal. This is additionally relevant to aspiring and new 
cinematographers with limited experience. This conservative attitude may lead them 
to recreate lighting setups or camera movements used in previous projects to reduce 
the risk of mistakes and delays in the production; however, it may limit their creative 
potential. Cinematographers are involved in the location scouting phase and during 
the subsequent technical scouting phase, during which they become aware of 
technical information, such as ceiling height, availability of electrical power sources, 
and the presence of reﬂective surfaces, just to name a few elements. 
 
c) Producers  
Producers organise and oversee the whole process, including budgeting the script 
and securing funding, arranging logistics during production, identifying a facility for 
post-production, and ensuring the ﬁnal delivery. Throughout the entire workﬂow, a 
quality producer addresses in advance those problems that may arise in later phases 
of the production process. This includes obtaining permission for shooting on public 
streets, ensuring catering has considered food allergies or speciﬁc requests, and 
writing the daily call sheet to estimate the budget needed to complete the project. 
Producers have several tasks to complete before the beginning of the shooting 
phase, and careful planning can make the diﬀerence between failure and success. 
‘Any problem that gets brought up on set is inﬁnitely more expensive than a 
problem that was brought up beforehand, because beforehand it’s just a problem 
that doesn’t have a value to it...You can’t foresee all problems, but it kills you if 
there’s a problem you could have foreseen’  PI06, producer. 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
70 
 
Study participants in this role reported that they need to communicate with all crew 
members for logistical reasons, understanding their speciﬁc needs and evaluating 
potential solutions. As explained by PI07 (producer), their duty and need are to keep 
everyone on the same page because ‘streamlining communication tends to kind of 
always be an issue, and something gets lost in translation sometimes’. Before and 
during the production phase, producers share a variety of documents and ensure 
that everyone has a clear idea of what is expected of them. Similar to directors and 
cinematographers, producers are deeply inﬂuenced by the nature of the chosen 
location. Depending on the ﬁndings from location and technical scouting, they will 
organize the production phase diﬀerently. 
 
4.7.3 Participants’ Vision of Immersive Technologies in the AV Pre-Production 
Process 
Participants were asked to express their vision of how immersive technologies such 
as VR and AR might allow them to solve their challenges; they explained that these 
tools could enable them to save time, improve the use of ﬁnancial resources, and 
enhance their creativity. The main beneﬁts they expected are listed below. 
 
1) Avoid travelling and save time during location auditioning  
The workﬂow that is proposed in this chapter will enable users to experience 
locations remotely within immersive environments, which could be useful to support 
the decision-making process during a preliminary phase called location auditioning. 
In this phase, many options are considered. The proposed conceptual workflow 
avoids physical travel from location to location, thereby saving time, optimizing use 
of ﬁnancial resources, and reducing the overall environmental footprint. Having the 
opportunity to immerse oneself in the virtual location and explore it remotely could 
overcome several limitations of 2D photos, which are currently used to preselect the 
possible locations. 
‘If I could wear the headset and be back in the room, where I took the 
photographs...go home and instead of having only my memory or photo in two 
dimensions being able to see the space in three dimensions, I think it would make 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
71 
me think much more clearly about where and how I want to place the equipment.’ 
PI12, cinematographer. 
 
The participants felt that physically scouting the chosen location at least once after 
the virtual screening is still vital, which suggests that the proposed conceptual 
workflow could be integrated within existing workﬂows without necessarily replacing 
established processes in their entirety. 
 
2) Remote collaboration  
Several participants speculated that virtualising the location scouting process would 
also favour collaboration among team members based in diﬀerent geographical 
locations. 
 
3) Lack of constraints  
During the interview, a participant noted the following: ‘There are a lot of 
independent productions that don’t allow time for location scouts, which I really don’t 
like, and then I just get thrown into it on the day, and I’m not sure’ PI10, 
cinematographer. 
The new workﬂow that is proposed in this chapter allows professionals to access a 
digital capture of the selected location at any time, which enables them to spend 
more time exploring the virtual space, thereby facilitating the generation of creative 
output. 
 
4) Virtually audition props and costumes  
PI06 (producer) commented on the beneﬁts of virtual exploration ahead of physical 
location scouting in terms of saving time and using ﬁnancial resources more 
efficiently in relation to, for example, improved choice of dresses and furniture to be 
rented: ‘The director hopefully could sit there and look at [it] and go – I don’t like it. I 
don’t like it. Okay, this is the one that we should run because I like the way it looks in 
the actual scene’ PI06, producer. 
 
5) Facilitate logistics  
4. Exploratory Study (DS-I, PS-I) 
 
 
 
72 
Having the ability to perform location and technical scouting virtually may allow 
different department heads to address many logistical and technical questions that 
are usually answered by producers. Some of the most common questions that need 
to be answered before shooting to enable the production to run smoothly are the 
following: ‘Where to park the truck? Where to store the equipment? Where are the 
power sources? Where to create a holding area? Where to create the production 
oﬃce?’ (PI06, producer). 
 
6) Pre-visualise the lighting setup  
When planning the lighting setup, the proposed conceptual workflow may be useful 
to pre-visualise how a particular light model or disposition will affect the look of the 
picture (e.g., how a hard light or soft light would illuminate actors’ and actresses 
faces). Similarly, pre-visualizing the impact of sunlight coming directly or bouncing 
from a window is crucial and can aﬀect the director and cinematographer’s 
decisions.  
Being able to simulate how sunlight will inﬂuence the scene lighting on a speciﬁc day 
and time would be useful because ‘sometimes during location scouting, you’re not 
necessarily there at the exact right time of when you intend to shoot’ (PI10, 
cinematographer). Some cinematographers currently rely on non-immersive mobile 
applications, such as Helios Pro (Chemical Wedding, 2021). 
 
7) Pre-visualise camera movements  
By taking advantage of VR, it may be possible to pre-visualize complex camera 
movements that are achievable with expensive gear, such as lights, cranes, or 
dollies, and then evaluate their use in production if they are considered appropriate 
to fulﬁl the cinematographer and director’s vision. Having such an opportunity is 
useful for professionals when renting or purchasing the required equipment for 
production because they have tested it virtually in advance. 
 
8) Pitching and fundraising  
4. Exploratory Study (DS-I, PS-I) 
 
 
 
73 
This workﬂow has the potential to facilitate the creation of a storyboard and a teaser 
to pitch to potential funders and investors. In this regard, PI12 provided the following 
example: 
 
‘Yes, let’s take in example the idea of using a crane...Guys, this is how it would 
look like if we take the cherry-picker and do the shot from top to bottom. To do so, 
we have to spend £1,200 or more because we need the crane and three 
operators. That’s it. What do we do? Do we spend it or not?’ PI12, 
cinematographer. 
 
Furthermore, as explained by PI08, this application can have the following beneﬁt: 
‘Empower beginning or mid-career directors who want to be ambitious and are 
trying to push the limits and are very creative, very innovative, and are looking at 
creating something that doesn’t exist and they might not have the resources for. I 
think it’s for visionaries’ PI08, director. 
 
9) Communication among crew members  
PI12 (cinematographer) offered an example of his relationship with the key grip, who 
is responsible for positioning and setting lights to illuminate the scene as desired by 
the cinematographer: 
'Sometimes you explain all the work to the key grip and he doesn’t remember 
everything you explained to him. At the end of each scene, you have to explain it 
all over again, and sometimes you have to talk to the director, to the client, you 
are busy with other things’ PI12, cinematographer. 
 
This process is usually implemented verbally or with a roughly drawn scheme. 
However, it is not rare for one of the people involved in the conversation to forget 
some details and information about the setup. The participant speculated that 
providing key grips with a VR device on set so that they can immerse themselves in 
the pre-visualisation of the lighting setup would lead to better and more eﬀective 
communication and would reduce delays and risk of mistakes. A similar principle can 
also be applied in other contexts. One example is the collaboration between the 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
74 
cinematographer and director, where moving virtual cameras, cranes, lights, and 
props can be completed more efficiently and transparently. 
 
4.7.4 Description of the conceptual workflow 
In the second part of the interviews, participants were verbally presented with the 
concept of using VP to facilitate collaboration among all crew members within the 
same virtual environment during the pre-production phase. The discussions with 
participants helped to expand and refine this concept into a more articulated 
conceptual workflow for SMPs that involve shooting in real-world locations. This 
workflow consists of three main steps, illustrated in Figures 4.2 and 4.3. 
 
The initial step in the conceptual workflow involves capturing data of the real location 
to create a virtual replica where all crew members can collaborate. This can be 
achieved through techniques such as photogrammetry or LiDAR technologies. The 
second step requires users to set up and prepare the virtual location by importing all 
the assets required for the project, which were not included in the digital capture 
conducted in step one (e.g. pieces of furniture not present in the real location). 
Special attention was given to ensuring flawless compatibility among different 
formats of the 2D/3D assets for import, eliminating the need for additional format 
conversion or extra steps to make them work. To enhance accessibility and usability, 
both the digital replica of the location capture and all other assets should be 
available on the cloud, allowing retrieval from any device with access to the project. 
The third step is the actual collaborative phase, enabling crew members to start pre-
production activities within an immersive environment (the digital replica of the 
shooting location). This can be done remotely, granting them the ability to rapidly 
iterate through various creative and technical decisions. It was mentioned also how 
different roles within the crew would require different toolsets to execute their tasks 
and activities. For instance, Cinematographers would appreciate access to various 
lighting options to set up their preferred light design. 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
75 
 
Figure 4.2 Conceptual Workflow Incorporating Ideas and Feedback (Phases 1-2) 
CAPTURE LOCATION
Point Cloud
Mobile LiDar
LSM (or equivalent)
Hardware
D = Director
C = Cinematographer
SD = Set Designer
P = Producer
AD = Assistant Director
LSM = Location Scouting Manager
LEGEND
WHO
PHASE
HOW
DATA
Capture of the Virtual Location
CONVERT TO 3D 
ASSET
WHO
PHASE
HOW
DATA 
UPLOAD 3D ASSET 
TO CLOUD
.obj - .fbx - ...
Mobile App
VR App
LSM (or equivalent)
D - C - SD - P - LSM - AD
LSM (or equivalent)
Mobile App
Software
INITIALISE VR 
APP
Already existing hw&sw solutions
solution proposed and to be developed
WEAR VR 
HEADSET
D - C - SD - P - LSM -  
AD
Standalone Headset
Hardware
Software
VR App
D - C - SD - P - LSM - AD
DOWNLOAD 3D 
ASSET FROM CLOUD
Setup of the Virtual Location
1
Already existing hw&sw solutions
2
2a
2b
2c
Already existing hw&sw solutions
WHO
PHASE
HOW
WHO
PHASE
HOW
4. Exploratory Study (DS-I, PS-I) 
 
 
 
76 
 
Figure 4.3 Conceptual Workflow Incorporating Ideas and Feedback (Phase 3) 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
77 
4.7.5 Feedback on the Proposed Conceptual Workflow and Additional Insights 
The positive feedback and comments received from all participants on the initial 
proposed conceptual workflow were used to add elements to what initially ideated by 
the researcher and to strengthen the concept. The result of the integration is 
illustrated in Figures 4.2 and 4.3, which are conceptually part of the same diagram. 
 
The visual quality of the digital location captures, which were obtained via either 
LiDAR scan (Alban, 2021) or photogrammetry (Figure 4.4), when showed to 
participants, were highlighted as critical by participants during the interviews. Similar 
remarks were offered about the integration of all other relevant virtual elements in 
the scene at later stages of the production process. 
 
 
 
Figure 4.4 LiDAR Textured Mesh (left) and Wireframe (right) 
 
The trade-off between affordability and output quality of the available digital capture 
mobile hardware and software meant that it was necessary to evaluate whether this 
conceptual workflow could be beneﬁcial for ﬁlm professionals. Most participants 
thought that having the ability to move freely in a 3D space (through the six-degrees-
of-freedom movements allowed by many standalone VR headsets) is a greater 
beneﬁt than having a high-ﬁdelity representation of the location without the freedom 
to explore the surrounding space. 
 
Cinematographers also remarked about the quality of the virtual lighting simulation. 
Simulating reﬂections and proper lighting has long been a challenge in real-time 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
78 
CGs. Participants noted the potential detrimental eﬀect of inconsistency between 
pre-visualisation and the real production scenario, particularly in receiving misleading 
information. Nevertheless, having the opportunity to place lighting equipment in a 
virtual location was considered useful to gain a better understanding of the space 
required for lights and other lighting-related equipment, such as stands, booms, 
ﬂags, and jibs.  
 
‘Even without realism, if I place a light from above, representing roughly the lighting 
eﬀect, the director can ﬁll the gap of the lack of representation with his imagination to 
visualize how it would look on set in reality’  PI12, cinematographer. 
 
The proposed workﬂow is intended to allow AV professionals to pre-visualize 
locations and prepare for production. Consequently, access to high-ﬁdelity 
representations is not a priority, as the pre-visualization output is not the ﬁnal output 
from the project.  
 
The potential to collaborate remotely, seamlessly, and in real time within a digital 
representation of the location was also considered useful by participants. To better 
explain this feature, they referred to Google Docs (Google, 2021), a web application 
which allows diﬀerent people to work in and edit the same document in real time. 
This further suggests the importance of potential security and privacy issues for a 
future platform implementing the proposed workﬂow and the need to establish a 
permissions system for edits and revision history. 
 
The Importance of Ease of Use 
An important aspect that was emphasised by the majority of participants was the 
ease of use of such a workﬂow. As they expressed, poor usability can be a 
dealbreaker for the proposed conceptual workflow. Learning a new workﬂow and 
related software is a tedious and time-consuming process with which potential users 
are not necessarily willing to engage. 
 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
79 
‘I foresee there might be a gap between an independent ﬁlmmaker wanting to use 
this technology and himself actually being able to manage it…Many independent 
ﬁlmmakers are in a way…they simplify greatly, they greatly simplify things and the 
workﬂow because of the condition of the productions or budget or maybe even 
people. Moreover, they are okay to do so to get the movie done’  PI03, 
cinematographer. 
 
‘How long would it take? How complicated is it? What the learning process would 
be for someone who isn’t necessarily experienced in visual eﬀects or 3D 
modelling?’ PI08, director. 
 
Therefore, participants suggested that they should be actively involved in designing 
intuitive UIs when the workﬂow is implemented to reduce the slope of the learning 
curve and facilitate rapid progress for all users. 
 
The Importance of Pre-Existing Tools 
An aspect that surprised participants was the current availability of key components 
of the proposed conceptual workflow through existing competitive hardware and 
software that is affordably priced for SMPs with limited resources. Making 
participants aware of such tools increased their interest, and they were involved as 
beta testers of the ﬁrst version of the prototype. 
 
The Importance of Uniqueness 
Another aspect highlighted by PI03 (cinematographer) is that the most thrilling and 
exciting part of filmmaking is often the unexpected. PI03 explained that observational 
documentaries are rich in unique and fortuitous moments, such as the genuine 
reaction of the people interviewed or spontaneous events happening in the area 
while shooting. However, he also stated how: ‘even if it’s a documentary, there could 
be sequences that are more constructed and even slightly rehearsed. Furthermore, 
this tool can help that too. So it can be used on documentaries as well. I wouldn’t 
rule it out’ PI03, cinematographer. 
 
4. Exploratory Study (DS-I, PS-I) 
 
 
 
80 
The Difference Between Location Scouting and Location Recce 
Participants mentioned the confusion among professionals about the terminology 
used to describe pre-production phases, including location scouting, which refers to 
that phase where potential locations are considered and proposed; this initial phase 
is oriented towards meeting the director's creative vision. Location recce (derived 
from the military term reconnaissance), which is sometimes used interchangeably 
with tech scout (abbreviation of technical scouting), consists of visiting the chosen 
location in person. This phase allows personnel to collect important information that 
cannot be determined in the previous phase, such as logistics, natural lighting, 
power sources, hazards, space for make-up or wardrobe rooms, and noise that may 
affect the audio recording quality, among others.   
 
4.8 Chapter Summary 
This chapter described the exploratory study (DS-I) required to identify the key daily 
challenges faced by directors, cinematographers, and producers during pre-
production by qualitatively analysing remote in-depth interviews with AV 
professionals (PS-I). 
Potential uses and benefits of using immersive technologies in the current pre-
production workflow were discussed by participants and based on that a conceptual 
workflow was co-designed and represented visually  in the form of a diagram. 
The following chapter describes a new study (DS-II) that confirms the conclusions 
that emerged from the analysis described in DS-I and PS-I and presents initial co-
design ideas regarding integrating immersive technologies into the participants’ 
current workflow. 
 
 
 
 
 
81 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Chapter 5  
 
IDEA CO-GENERATION  
(DS-II, PS-IIA, PS-IIB, PS-III) 
 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
82 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
5.1 Introduction 
The exploratory study paved the way for structuring a more interactive and 
productive phase: co-design workshops.  
Two workshops were conducted remotely, thereby providing an example of 
successful strategies for online implementation of co-design workshops during the 
COVID-19 pandemic. The workshops united a diverse group of AV professionals 
who work on small and medium-budget projects not involved in the previous study, 
except for one participant that helped recruit additional participants. 
 
In this second study it was decided to re-open the conversation on how VP could 
impact not only the pre-production phase but also production and post-production. 
Despite the literature indicated how pre-production is the phase benefitting the most 
from novel VP processes, because of the co-design workshop are still a conceptual 
phase of the research process, it was considered as appropriate to do not limit 
participants imagination and creativity.  
 
The first workshop led to identifying pain points in existing filmmaking workflows (DS-
II), and the second generated several innovative concepts (PS-IIA and PS-IIB) with a 
potential for further development and testing in operational settings (PS-III).  
 
5.2 Aim 
The study prompted participants to generate collaborative ideas that build on 
immersive technologies and offer the potential to improve existing AV production 
workflows. Identifying an effective research approach and design method was 
central to fostering this creative process. 
Co-design was deemed appropriate to facilitate the generation of innovative and 
useful designs that respond to stakeholders' needs (Steen, Manschot, & De Koning, 
2011) and to instil a sense of ownership and empowerment in the participants (van 
Rijn & Stappers, 2008). Concurrently, the role of the facilitator is not to be 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
83 
underestimated. The facilitator is responsible for providing the correct tools and 
methods to enable non-designers involved in the design thinking process to generate 
and express their ideas (Sanders & Stappers, 2008). In relation to this study, the 
facilitator organized a series of design thinking workshops to motivate participants to 
explore innovative uses of immersive technologies in VP processes.  
Design workshops are well suited for idea generation (Broadley, Cara, & Smith, 
2018; Avital, 2011) in that they allow the participants to more effectively express the 
often tacit and implicit aspects of their working habits (Sleeswijk-Visser, 2009) and to 
share anecdotal experiences with others. The co-design workshops were carefully 
designed and operated via online collaborative software boards (Mural.com). The 
boards were implemented to encourage participants to freely yet consistently 
express their opinions and ideas through a predetermined sequence that maintained 
focus in the discussions. In particular, a set of sequential activities was designed and 
implemented to guide participants in transitioning from one activity to the next 
(Figure 5.1). According to Sanders, Brandt, and Binder (2010), this sequential aspect 
is critical to the successful execution of co-design workshops.  
 
 
 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
84 
 
 
 
Figure 5.1 Flowchart of the Co-Design Remote Workshops 
 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
85 
5.3 Participants 
To co-design effective and innovative concepts, the involvement of professionals 
working in the AV industry, including directors, cinematographers, producers, and 
editors, was essential (Table 4). The participants were based in the US (2), UK (3), 
and Italy (10). 
Table 4 Summary of the Participant Pool (Workshops) 
PARTICIPANT 
GROUP 
ROLE 
DESCRIPTION 
PW01 
GROUP 1 
Cinematograp
her 
Operating cameras and lighting on set, 
working closely with directors 
PW02 
Cinematograp
her 
Operating cameras and lighting on set, 
working closely with directors 
PW03 
Editor 
Working mainly on documentaries 
PW04 
Producer 
Overseeing the entire production process 
of fiction and documentaries 
PW05 
Sound 
designer 
Working closely with directors in 
producing the audio component for 
documentaries 
PW06 
GROUP 2 
Producer 
Overseeing the entire production process 
of fashion commercials 
PW07 
Producer 
Overseeing the entire production process 
of fashion commercials 
PW08 
Producer 
Overseeing the entire production process 
of fashion commercials 
PW09 
Director 
Directing commercials, music videos, and 
fiction 
PW10 
Editor 
Working mainly on commercials and TV 
series 
PW11 
GROUP 3 
Archive 
producer 
Overseeing the production and post-
production of documentaries 
PW12 
Producer 
Involved during the development phase of 
a project and actively seeking funding 
PW13 
Animator 
Working as animator on fiction and 
independent games 
PW14 
Director 
Directing short-ﬁlms and art installations 
and actively seeking funding 
PW15 
Producer 
Working on the business side of film or TV 
projects 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
86 
 
Through the involvement of a range of professionals across AV roles, diverse 
knowledge, perspectives, and skills were combined, which created favourable 
conditions for identifying solutions to complex problems (Meroni, Selloni, & Rossi 
2018). 
 
Three groups, each composed of five participants, were recruited for the workshops. 
This choice of group size is in line with recommendations in the literature concerning 
remote collaborative workshops and reduces the risk of technical issues interfering 
with the creative processes (Flynn, Albrecht, & Scott, 2018; Daniels et al., 2019).  
 
Two groups included participants who had already collaborated with each other on 
previous projects. This strategy was meant to facilitate more effective and honest 
communication compared to groups whose participants were unfamiliar with each 
other, as this reduced the risk of individuals feeling embarrassed or judged by others 
during the activities. There was also an expectation that the group dynamic could be 
favourably impacted by participants' ability to recall common experiences on 
previous projects, which could encourage them to share different viewpoints. This is 
in line with observations during the implementation of the workshops. As 
documented in Muller and Druin (2003), stories can be effective in opening 
conversations, as they often encode details about user habits, needs, pain points, 
expectations, desires, and additional contextual information that can be particularly 
meaningful when addressing a design problem. 
 
5.4 Procedure 
Conducting in-person (as opposed to remote and online) co-design workshops has 
advantages in the depth of the input generally received from participants through the 
enhanced sense of cohesion within each participant group and through the 
availability of a richer set of communication channels, including non-verbal cues. In-
person workshop discussions often result in more spontaneous reactions and more 
genuine answers to questions (Brüggen & Willems, 2009). 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
87 
However, the COVID-19 pandemic placed unprecedented constraints on fieldwork 
activities, which prompted researchers to identify new ways of collecting data from 
participants (Slingerland et al., 2022; Bakırlıoğlu et al., 2020; Ali et al., 2021). A 
useful online document, which was crowdsourced and manually curated, details 
remote fieldwork methods employed by social researchers worldwide during the 
COVID-19 pandemic (Lupton, 2020). The document covers a range of 
communication channels, including online discussion platforms, and has proven 
useful during the design of this study. 
 
Similar to other researchers' findings, this thesis argue that the execution of remote 
online co-design workshops can increase participant access to in-person activities by 
lowering potential barriers associated with travel time and cost (Zhang et al., 2022) 
and therefore may allow researchers to engage with participants around the world 
(Bertran et al., 2022) or with hard-to-reach populations (Blomkamp, 2018). Such a 
degree of accessibility was particularly relevant to professionals who were willing to 
engage in this study in the absence of financial compensation. 
 
The implementation of remote online co-design workshops in this research 
presented challenges that, if not uniquely associated with reliance on an online 
medium, were compounded by it. In particular, keeping participants continuously 
engaged online despite potential distractions in their domestic settings was a priority 
for the facilitator that proved critical to the successful implementation of the co-
design activities. Attention was paid to whether prior professional relationships were 
in place among participants to achieve a balance between groups in which 
participants were not familiar with each other and those consisting of participants 
with prior shared professional experience. Two of the three groups consisted of 
participants who had previously worked together. 
 
As part of this effort, digital tools, platforms, and services suitable for the 
implementation of online workshops were identified. 
 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
88 
The Zoom platform proved useful for video-based participant activities because of its 
intuitive interface and the availability of recording functionalities. Importantly, 
participants were already familiar with Zoom, which reduced friction and enabled a 
smooth execution of the online activities. Audio recordings were processed using the 
Trint software, and transcriptions were proofread and edited. 
 
In addition to the Zoom video-call service, other collaborative online platforms 
(Miro,Mural, & Klaxoon) were tested by the researcher in preparation for the 
workshops to identify the most suitable program for replicating the whiteboards that 
are commonly used for in-person activities. All three platforms enabled effective 
interaction among participants during the online workshops by replicating common 
actions, such as placement of post-it notes, writing, and drawing. The browser 
version of Mural was selected for its ease of use. 
 
5.4.1 First Workshop: Board Framework 
 
Figure 5.2 Mural Board Designed for the First Workshop 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
89 
The first workshop, for which the Mural board displayed in Figure 5.2 was adopted, 
was implemented to achieve the following objectives: (a) introduce participants to 
each other, thereby facilitating the creation of an open and friendly environment; (b) 
discuss pain points across their AV productions; and (c) introduce participants to 
emerging technologies (VR, AR, AI, DTs), using existing case studies to illustrate the 
potential of these technologies for augmenting AV production workflows. 
The first objective – creating an environment where every participant could be 
empowered to express themselves without feeling judged – an icebreaker activity 
was introduced (Figure 5.3). Icebreaker activities are commonly used for overcoming 
initial participant reticence and insecurity. Participants were asked to consider a 
science fiction object emblematic of a movie or TV series and sketch it in the box 
assigned on the Mural board (Tactivos Inc., 2022). In addition to building a feeling of 
mutual empathy, this activity familiarised participants with the functionalities provided 
by the platform, including navigation, selection, and drawing tools. Asking 
participants to focus on an emblematic science fiction object further required them to 
enter a futuristic mindset, distance themselves from limitations associated with 
existing technologies, and consider innovative ideas. The positive impact of playful 
tasks on creative workshop activities has been documented in Ehn (1993) and Muller 
(1993). 
 
 
Figure 5.3 Board Used for the Icebreaker Activity 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
90 
Following the icebreaker, participants were asked to express their opinions regarding 
the next section of the Mural board by focussing on the existing linear AV production 
process, which is common in the AV industry and consists of sequential stages 
including development, pre-production, production, post-production, and finalization 
(Figure 5.4). Participants were shown the results of a study on immersive 
technologies for VP based on one-to-one exploratory interviews with AV 
professionals (Bodini et al., 2023), which allowed them to evaluate the outcomes 
from the study and allowed the researcher to gather additional opinions and thoughts 
in relation to potential applications of immersive technologies for AV production.  
 
 
Figure 5.4 Stages of the AV Filmmaking Process Identified in DS-I 
 
Afterwards, participants were asked to reflect on the obstacles they encounter 
throughout the AV production process (Figure 5.5). This resulted in an open 
discussion where participants elaborated on their current pain points and shared 
relevant anecdotes from previous projects. 
 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
91 
 
Figure 5.5 Boxes to Record Challenges Faced in Existing AV Production Workflows 
 
The final activity of the first workshop focussed on presentation and discussion of 
case studies in relation to high-end VPs, such as The Lion King (Giardina, 2019) and 
The Mandalorian (2019; Seymour, 2020). The emphasis was on the role played by 
immersive technologies (VR, AR, XR), real-time game engines, and a broader range 
of emerging technologies, such as those enabling automated image generation 
based on descriptive text. Artificial intelligence (AI) algorithms such as DALL-E 
(Ramesh et al., 2021), its iteration DALL-E 2 (Ramesh et al., 2022), and Imagen 
(Saharia et al., 2022) are considered potentially disruptive to the media industry and 
have attracted attention in recent years (Newton, 2022). 
 
To further inspire participants, recent developments in DTs applied to humans were 
mentioned and explored with the participants. This included a discussion of 
MetaHuman (Epic Games, 2022), a freely available cloud-based application from 
Unreal Engine that facilitates the creation of realistic virtual human agents for use in 
media productions. This phase of the workshop prompted participants and allowed 
them to envision design fiction scenarios (Figure 5.6).   
 
Figure 5.6 Pictures and Videos Shown to Prompt Participants 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
92 
Keeping participants focussed throughout the workshops was not straightforward. 
Unveiling parts of the Mural board in a stepwise fashion instead of presenting the 
board in its entirety required participants to focus on one aspect at a time, which 
proved to be particularly useful. In a follow-up discussion after the workshops, one 
participant noted that the stepwise unveiling of the Mural board was beneficial 
because it allowed participants to better understand the board and reduced the risk 
of cognitive overload. 
 
5.4.2 Self-Reflection Task Between the Two Workshops 
A break of few days was introduced between the first and second workshops, 
following the recommendation from Di Stefano, Pisano, and Staats (2015), who 
demonstrate that self-reflection following a learning activity can improve learning 
outcomes. Participants were invited to reflect on previous discussions, further 
explore the materials that were made available to them (videos and articles on the 
emerging technologies that were presented during the first workshop), and return to 
the Mural board for refinement in their own time over the following days. 
 
 
 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
93 
5.4.3 Second Workshop: Board Framework 
 
Figure 5.7 Mural Board Designed for the Second Workshop 
 
The objective of the second workshop was to generate innovative ideas that rely on 
emerging technologies discussed during the first workshop. A range of activities was 
implemented: (a) recapitulation, (b) visual prompting, (c) independent brainstorming, 
(d) building on others’ ideas, (e) group discussion, and (f) filtering and evaluation. 
 
i) 
First, the output from the first workshop was summarized to refresh the 
participants’ memories about the pain points previously identified (right-
hand side of Figure 5.8: ‘What you wrote’ and ‘What you said’). 
Additionally, the main phases of the filmmaking process were reported in 
the ‘Areas of interest’ box (left-hand side of Figure 5.8) to prompt 
participants to consider relevant works from which they could take 
inspiration during the following brainstorming activity. 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
94 
 
 
Figure 5.8 Recapitulation of the Topics Discussed During the First Workshop 
ii) 
Visual Recapitulation 
Similarly, a set of images providing examples of emerging technologies 
were displayed in this initial phase of the workshop to further stimulate 
participants’ imaginations and inspire them during the execution of the 
core activity of the workshop (Figure 5.9). During this phase, participants 
were also encouraged to ask for any clarifications and enquire about the 
technologies considered during the self-reflection task.  
 
Figure 5.9 Visual Recapitulation of the Technologies Introduced During the First Workshop 
iii) 
Solo Brainstorming 
After the facilitator introduced the workshop, participants were given 10 
minutes to independently brainstorm ideas (Figure 5.10). The Zoom 
breakout room feature was used to isolate individual participants for the 
duration of the activity. The facilitator was able to join each participant’s 
breakout room to ensure correct understanding of the task. Additionally, 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
95 
the facilitator was provided with a real-time view of the ideas generated by 
the participants on the Mural board, and he monitored the time by using 
the stopwatch feature. 
 
Figure 5.10 Boxes to Record Ideas During the Solo Brainstorming Activity  
iv) 
Idea Iteration 
At the end of the activity, all participants rejoined the Zoom group call and 
received instructions about the follow-up activity. They were asked to 
consider others’ ideas and add any thoughts, comments, and critiques to 
others’ notes on the board to expand the concepts (Figure 5.11). Each 
participant was allocated up to 3 minutes for the execution of this activity, 
which comprised a total of 12 minutes. 
 
 
Figure 5.11 Boxes to Record Ideas During the Idea Iteration activity 
v) 
Group Discussion 
Following a short break, a group discussion occupied the remainder of the 
workshop. Each participant was asked to elaborate verbally on the most 
relevant ideas they produced. 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
96 
 
Figure 5.12 Bullseye Framework (left) and Participants’ Input Summaries (right) 
 
vi) 
Filtering and Evaluation (DS-IIB) 
Finally, participants were asked to position individual ideas within a 
bullseye framework, which comprised three concentric circles labelled 
‘most important’, ‘important’, and ‘least important’ on the Mural board 
(Figure 5.12). The more central the positioning, the higher the perceived 
relevance and value of the idea. Previous researchers have documented 
the usefulness of the bullseye framework for organising and prioritizing 
ideas (Weinberg & Mares 2015; Rayo et al., 2018). The bullseye 
framework was originally introduced by Mares and Weinberg (2014) to 
support commercial organizations in identifying the most promising 
marketing channels for business development. In this study, the 
framework was a visual representation reflecting an underlying scoring 
system, as detailed in the following sections. 
 
 
 
 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
97 
5.5 Findings 
After completing the workshops, the data generated (audio recordings and Mural 
boards) were analysed.  
 
5.5.1 First Workshop (DS-IIA)  
During the icebreaker activity, participants had a chance to understand the nature of 
the study and familiarize themselves with the workshop agenda. The icebreaker 
activity also provided time for participants to become comfortable with the Mural 
tools and allowed the Group 3 members to introduce themselves to the facilitator and 
to each other. 
 
During the first workshop, participants were receptive to concepts presented by the 
facilitator and contributed little content to the Mural board while the focus was on the 
established AV production process. Participants added the following to the board:  
 
• A note about legal paperwork (e.g., permission to shoot in a specific location 
and film individuals); 
 
• Clarifications about the difference between offline editing (transcoding the 
original high-quality footage to lower resolutions to reduce the computational 
resources required for editing) and online editing (the concluding stage where 
low-resolution files are re-linked to the original high-quality footage and the 
final edit is made available for exporting);  
 
• Clarifications about the so-called treatment, that is, a document used by 
directors to express their ideas about the visual style they want to achieve and 
how they intend to make the project happen from a production standpoint. If 
an AV product is requested by a client, which is often the case in the 
advertising sector, then directors are asked to compete with each other by 
proposing and presenting a prospective treatment. 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
98 
• 
If directors are developing a project independently, then they normally 
rely on their treatment to sell their project and secure funding. This is 
often the case for feature films, shorts films, and documentaries. 
 
Participants noted that different sectors of the industry may adopt workflows 
consisting of slightly different stages that may be arranged in a different order but 
agreed that the established AV production workflow illustrated was an accurate 
description of their professional experience. Therefore, the findings from this study 
are consistent with the outcomes from a previous investigation by Bodini et al. 
(2023). 
Regarding pain points, a range of opinions was expressed. One participant (PW04, 
producer) highlighted a need to ‘fulfil and combine all the requests coming from 
different departments’, which can be complicated by unforeseen problems during 
production, thereby resulting in a need to ‘micro reschedule based on daily micro 
issues’. 
A theme that emerged in relation to pain points with established AV production 
workflows is the need for effective communication across departments when 
addressing unexpected issues, both before and during the production stage. Those 
participants working in post-production roles, such as editors (PW03 and PW10) and 
archive producers (PW11) mentioned the challenges arising from processing and 
managing large volumes of data. 
Participants also noted challenges associated with shooting in real-world locations. 
Examples were provided regarding the important role of accurate weather forecasts, 
which can make the difference between progressing, postponing, or even wasting an 
entire shooting day. In particular, the ability to gain prior understanding of how 
different weather conditions can influence the shooting outcome was considered 
critical for the decision-making process. 
Part of the first workshop was devoted to presenting relevant VP case studies to the 
participants. Consequently, the facilitator was the only speaker, which left little space 
for participants to intervene except to ask questions or provide clarifications.  
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
99 
As anticipated, groups in which participants already knew each other featured more 
open discussion that often built on shared anecdotes from previous projects to 
highlight pain points and issues encountered. 
 
Figure 5.13 Mural Board After the First Workshop With Group 2 
 
 
5.5.2 Second Workshop (PS-II, DS-IIB) 
The second workshop started with a recapitulation activity to refresh the participants’ 
memory and prompt their imagination. The facilitator reviewed participant notes that 
were previously placed on the Mural board (‘What you wrote’ section) and outlined 
the key points that emerged from the first workshop after the researcher listened to 
and transcribed the conversation (‘What you said’ section). 
 
As expected, prompting participants with the recapitulation activity led to the 
generation of a richer dataset during the second workshop compared to the first.  
The independent brainstorming exercise (PS-II) was appropriately executed by all 
participants. 
 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
100 
Interaction with the Mural board was frictionless, which may have been facilitated by 
participants' prior familiarization with the online tools during the first workshop. 
Moreover, the ability for the facilitator to enter and exit individual Zoom breakout 
rooms to check whether participants needed assistance to execute the task proved 
particularly useful. Similarly, monitoring time using the Mural stopwatch function was 
useful throughout all activities.  
At the end of the 10-minute solo brainstorming activity, the number of ideas 
generated by individual participants ranged from three (PW05, sound designer) to 
nine (PW14, director). 
The follow-up activity in which each participant was asked to expand on others’ ideas 
was particularly useful for strengthening and extending the concepts initially 
proposed. Inviting participants to read about ideas proposed by others, which were 
either new or similar to theirs but expressed with different words and reflecting a 
different perspective, provided participants with additional sources of inspiration and 
enhanced the creative process. This ultimately resulted in fresh input to the original 
ideas generated during the workshops. 
In fact, after this activity, the majority of ideas attracted additional notes from others. 
This included expressions of appreciation (‘Agree!’, ‘Cool’, ‘Very useful!’), questions 
(‘Does it exist already?’, ‘What do you mean?’), and in most cases, additional input 
to the initial ideas (‘Not only from the point of view of a creative such as the director 
but also for those involved in the production department’). In some instances, 
comments were meant to initiate a more structured debate (‘Some of these aspects 
of production need real-life evaluation…Don't you think some parts of the process 
will always need non-virtual dynamics?’). 
During the group discussion, participants often joined the conversation and provided 
additional constructive input to the concept being discussed, thereby promoting the 
expression of different viewpoints. This dynamic facilitated the exchange of ideas, 
enhanced the collective thinking process, and led to a richer understanding of the 
anticipated benefit of future adoption of the design for the VP process. If few 
participants were involved in a conversation, then the facilitator invited others to join 
to broaden the scope of the discussion. Some concepts were presented and 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
101 
received few comments, while others were reviewed by several participants and 
underwent a more intense exchange. 
 
Finally, participants were asked to identify a subset of ideas worthy of further 
development by positioning iterated ideas within the bullseye framework (DS-IIB). 
 
 
Figure 5.14 Overview of the Mural Board After the Second Workshop With Group 1 
 
 
Figure 5.15 Ideas Placed Within the Bullseye Framework by Participants 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
102 
 
A few concepts were merged or excluded from this list because they were deemed 
irrelevant to the aim of the study. 
 
Each idea was assigned a score reflecting its potential usefulness as perceived by 
the participants. Ideas placed within the ‘Most Important’ circle of the bullseye 
framework were assigned a score of 3, those within the ‘Important’ circle, a score of 
2, and those in the ‘Least Important’ circle, a score of 1. If an idea was generated by 
more than one participant within a group, then the corresponding scores were 
averaged (AVG_Group). If multiple groups generated the same idea, then the 
corresponding group-level averages were averaged to produce a total score 
(AVG_Tot). A final metric reflecting the perceived usefulness of each idea was 
obtained by multiplying the total score (AVG_Tot) by the number of participant 
groups in which each idea was generated (number of occurrences). 
The results of the analysis of the board from the second workshop are summarized 
in Table 5 and illustrated visually in Figure 5.16. 
 
 
Figure 5.16 Visual Representation of the Idea Scoring System 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
103 
Table 5 Concepts Generated, Filtered, and Prioritized During the Second Workshop 
 
 
# 
Concept 
Brief description 
Bullseye’s 
priority 
(avg.) 
Number of 
occurrences 
among 
groups 
Idea 
Total 
Score 
#1 
Virtual pre-
production 
meeting 
Exchange thoughts 
with other crew 
members before the 
start of the production. 
2.33 
3 of 3 
6.99 
#2 
Virtual location 
scouting and 
location recce 
Be immersed in a 
digital re-creation of the 
location and freely 
explore it without time 
or accessibility 
limitations, either 
independently or with 
other collaborators. 
2.33 
3 of 3 
6.99 
#3 
Virtual set 
design 
Experiment quickly with 
different set design 
layouts and facilitate 
decision-making. 
1.5 
3 of 3 
4.5 
#4 
Virtual drone 
flight path 
simulation 
Pre-plan and simulate 
the flight path of a flying 
drone. 
2 
1 of 3 
2 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
104 
#5 
Virtual 
cinematography 
Experiment with 
different camera 
angles, positions, 
optics, and movements. 
2 
3 of 3 
6 
#6 
Actor blocking 
and rehearsing 
 
Place and animate 
virtual actors and 
actresses to rehearse 
the scene. 
 
1.25 
2 of 3 
2.5 
#7 
Virtual pitching 
 
Simulate a scene 
virtually and pitch ideas 
to investors. 
2 
1 of 3 
2 
#8 
Immersive 
remote casting 
 
Immersive stereoscopic 
videos run casting 
remotely. 
1 
1 of 3 
1 
#9 
New 
interactions with 
post-production 
software 
 
Interact with the 
software used in post-
production in an 
immersive way. 
1 
1 of 3 
1 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
105 
#10 
AI to generate 
rough 3D assets 
and AR 
integration 
when shooting 
Implement in real time, 
while on set, a low poly 
version of the objects 
that will be added in 
post-production. 
3 
1 of 3 
3 
#11 
Immersive 
editing 
Use gestures and 
visualize footage clips 
in an immersive 
environment. 
2 
1 of 3 
2 
#12 
Re-experiencing 
the production 
process 
 
Re-experience the 
filming set through a 
pre-recorded 360° 
video. 
1 
1 of 3 
1 
#13 
AR for set 
design 
Visualize beforehand 
how a specific object 
would look in the scene 
through AR. 
2 
1 of 3 
2 
#14 
Generative AI 
scenarios 
Use AI to predict the 
economic performance 
at the box office when 
casting specific actors 
and actresses. 
3 
1 of 3 
3 
 
 
 
 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
106 
5.6 Discussion 
Conducting fieldwork research despite practical constraints arising from the COVID-
19 pandemic was a complex endeavour, and identifying effective strategies to work 
around such limitations was a worthwhile effort that holds significant potential for 
future design research.  
A useful review of the strengths and limitations of videoconferencing tools to facilitate 
qualitative research is documented in Boland et al. (2021). This study confirms some 
of their findings. Specifically, remote online workshops are a cost-effective method of 
collecting data if additional hardware and software equipment requirements are 
lacking. Moreover, the implementation of remote workshops using existing digital 
tools and services as opposed to in-person events in physical venues has the 
advantage of potentially lowering barriers to participation associated with travel time 
and cost (Forrestal, D’Angelo, & Vogel, 2017).  
 
The adoption of a remote online approach also holds the potential to increase the 
speed of data collection (Kite & Phongsavan, 2017), with the only obstacle being 
participants’ availability. A significant challenge in this study was selecting a date and 
time suitable for everyone, as all participants were AV professionals who opted to 
join this research without financial compensation and despite concurrent demands 
arising from their professional duties. This proved particularly difficult, as the AV 
industry was returning to operational levels that were closer to a pre-pandemic 
regime. To address this issue, workshops were sometimes rescheduled. Other 
researchers wishing to engage professionals in similar future research should 
identify suitable incentives to increase participation and facilitate workshop planning. 
One participant, approached again following the workshops, commented favourably 
on the idea of organizing future in-person workshops on this theme and stated that 
the opportunity to experience immersive technologies firsthand was a beneficial 
investment of their time. 
The remote workshops conducted as part of this study were valuable in generating 
initial design concepts with the potential to enhance future filmmaking workflows and 
address some of the pain points currently faced by professionals. The adoption of a 
co-design approach empowered participants and generated a sense of ownership 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
107 
within the design process; without this approach, it would not have been possible to 
decode and take advantage of AV professionals’ tacit knowledge to produce, iterate, 
and evaluate ideas as effectively as in this study.  
The collaborative nature of the activities and the broad range of AV skill sets 
involved proved to be key enablers of a shared process of ideation and critical 
assessment of innovative ideas regarding the potential of immersive VP 
technologies. 
Reliance on data collection methods that are potentially less participatory, such as 
focus groups, would most likely have resulted in the facilitator having to play a more 
prominent role in the activities, thereby potentially reducing the scope of the group 
discussions and limiting the creative output from the workshops. Instead, through the 
co-design process implemented, the discussions were primarily participant led, 
which created ideal conditions for generating a range of innovative design concepts. 
In the first workshop, additional time could have been allocated by the facilitator to 
illustrate how immersive technologies can augment existing AV production workflows 
for smaller-scale organizations. This could have increased participant understanding 
and positively impacted the follow-up discussions; this will be considered for further 
research. Accordingly, including additional in-person activities between the first and 
second workshops could have been beneficial. As mentioned by Ssozi-Mugarura, 
Blake, and Rivett (2017), co-design ‘is challenging when users have little 
understanding of technology’. Therefore the main drawback of running remote (as 
opposed to in-person) co-design workshops is the lack of a familiarization phase 
during which participants – guided by a facilitator – can gain a hands-on appreciation 
of the potential of emerging technologies. 
In the absence of restrictions to in-person interaction, studies with in-person co-
design workshops would enable participants to gain hands-on experience with 
immersive technologies, thereby enriching exchanges of opinions and discussions. 
Additionally, the combination of remote online and in-person co-design activities has 
the potential to result in better participant understanding of immersive technologies, 
which can in turn facilitate the generation of innovative ideas while concurrently 
improving access to the co-design activities. 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
108 
The next stage of the research (DS-III) focusses on assessment of the design 
concepts generated as part of this study with a different group of AV professionals. 
 
5.7 Diegetic Prototypes (PS-III) 
The initial concepts generated by participants during the co-design workshops, as 
shown in Table 5, were filtered and coded by the researcher according to the results 
from the bullseye framework, which was used during the workshops to evaluate and 
prioritize these initial concepts (PS-IIB). Furthermore, each relevant idea was 
assigned a score, which is also shown in Table 5. Finally, the researcher merged 
some of these ideas to create broader and more structured scenarios (Figures 5.17 
and 5.18). 
 
This process led the researcher to create three design fiction scenarios in the form of 
written stories; each one focusses on a different phase of the AV workflow:  
 
• Scenario 1 – Pre-production 
• Scenario 2 – Production 
• Scenario 3 – Post-Production 
 
As explained at the beginning of this chapter, it was considered useful to explore 
conceptually how VP can be employed to other phases such as production and post-
production. Due to limited resources, the researcher made a decision to develop a 
practical prototype based on the outcomes presented in Chapter 6. In this chapter, 
participants were engaged through an online questionnaire to collect their 
preferences towards the scenario perceived as the most advantageous for 
filmmakers and to further develop into a practical prototype. 
 
 
 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
109 
 
 
 
Figure 5.17 Visual Representation of the PS-III Phase (part one) 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
110 
Figure 5.18 Visual Representation of the PS-III Phase (part two) 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
111 
 
 
 
 
Design Fiction Scenario 1: Immersive Pre-Production Collaborative Platform 
 
This scenario is the result of several specific ideas that were merged and included in 
a broader concept. The role of a digital replica of the filming location was seen as 
central because it enables several pre-production tasks. 
Participants ideated a scenario where VR allows them to pre-visualize the scene 
they are planning to shoot in the production phase. They envisioned the filming 
location being accessible remotely and all crew members being outfitted with the 
required equipment (VR headset). In this scenario, it is possible to perform several 
activities in a group or independently in a synchronous or asynchronous way. 
The potentialities of this scenario include the following: 
• 
The possibility to exchange thoughts with other members of the crew before 
the start of the production 
• 
The possibility to be immersed in a digital recreation of the location and freely 
explore it without time or accessibility limitations, independently or with other 
collaborators 
• 
The possibility to make decisions and adjustments on the set design (props, 
furniture, scenography, etc.) 
• 
The possibility to experiment with different camera angles and positions as 
well as different optics and movements to find the one most appropriate for 
the scene 
• 
The possibility to plan the flight path of a drone and simulate other camera 
movements using specific gear, such as dollies, cranes, and jibs, among 
others 
• 
The possibility to place actors and actresses, models, or dummies (blocking) 
or animate them to rehearse the scene 
• 
The possibility to place and simulate natural and artificial lights 
• 
The possibility to better pitch ideas to investors 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
112 
This scenario is aligned with the findings reported in PS-I, in which interest was 
expressed from a different sample of participants about a similar concept.  
 
Design Fiction Scenario 2: Real-Time Implementation of Augmented Reality on 
Set Through AI 
 
This scenario was envisioned with the specific goal of enabling those involved in the 
production phase to visualise VFX elements that are planned for addition in post-
production. 
The opportunity participants perceived in this scenario is having a faithful 
representation of VFX when shooting, thus providing them with a better idea of the 
final output through in-camera AR. The VFX, which can be 2D or 3D, are generated 
by an AI algorithm that is capable of synthesizing images and animations according 
to verbal instruction from the director or other crew members. 
Participants believed that this technological aid could reduce the risks of capturing 
footage that is not usable in post-production due to false assumptions about the VFX 
that were intended for implementation. 
 
Design Fiction Scenario 3: Immersive Editing 
 
Post-production activities are executed by a crew member sitting in front of a monitor 
and using a mouse and keyboard for inputs. Sometimes this approach is considered 
monotonous and not fertile for creativity as well as deleterious for one’s physical 
health.  
Compared to Scenario 2, where a post-production activity such as VFX integration is 
included in the production phase, for Scenario 3, participants re-imagined a post-
production activity not related to VFX. They conceptualized a scenario in which the 
editing phase is performed in an immersive environment. This extends beyond a 
simple integration of floating 2D tabs, windows, and screens in VR. Such a scenario 
offers different UXs and UIs by taking advantage of the physical movements and 
gestures of the user in a virtual space. This new way of approaching the editing 
phase could unlock new creative possibilities; one participant noted that ‘editing, 
5. Idea Co-Generation (DS-II, PS-IIA, PS-IIB, PS-III) 
 
 
 
113 
sometimes, is like dancing, and so it would be interesting to give it a try. It might let 
you see new solutions, new combinations’ (PW03, editor). Additionally, these 
interactions require editors to be more involved physically.  
Many participants recognised how working many hours a day in such a way can be 
physically exhausting. It could be beneficial to mix and alternate both the established 
and proposed way of editing. 
 
5.8 Chapter Summary 
This chapter described the structure of the remote co-design workshops through 
which the researcher aimed to confirm the pain points and challenges faced by AV 
professionals who operated in SMPs; these pain points and challenges were 
identified in PS-I with a different sample of participants. Through a design fiction 
approach, participants were later introduced to the notable uses of immersive and 
emerging technologies, which inspired the innovative ideation applied to their 
production process. Concepts ideated by participants within a group were iterated 
and evaluated by other members of the same group. Finally, during PS-III, three 
design fiction scenarios were created based on the findings of the remote co-design 
workshop. 
 
 
 
 
 
114 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Chapter 6 
 
IDEA FILTERING AND ITERATION 
(DS-III) 
 
 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
115 
6. Idea Filtering and Iteration (DS-III) 
 
6.1 Introduction 
This chapter describes the process of identifying the most preferred design fiction 
scenario among those generated in PS-II by participants. This research activity is 
part of identifying the answer for RQ1.3, and it describes the employment of an 
online questionnaire as a design method. 
Initially, the rationale behind the questionnaire’s structure is explained. 
Subsequently, the results obtained from respondents are presented and discussed. 
Finally, this chapter explains how this study (DS-III) is directly related to the next 
through the design and development of the preferred scenario into a concrete 
prototype (PS-III). 
 
6.2 Aim 
Overall, the aim that underscored the questionnaire was to identify which of the three 
design fiction scenarios was considered most valuable by stakeholders. 
However, the goal was broader than simply collecting responses by asking closed-
ended questions. The more ambitious intent behind the questionnaire was to receive 
more detailed feedback on the three scenarios by asking open-ended questions to 
capture further input. Collecting opinions on why participants preferred one scenario 
over another, the eventual pain points, and additional useful features to integrate into 
the scenarios were precious information to obtain in preparation for the next phase of 
the research. The scenario that received the most consensus indicated to the 
researcher which prototype to develop in the next phase of the research (PS-III). 
 
 
 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
116 
6.3 Participants 
When recruiting, the researcher contacted AV professionals who participated in 
previous phases of the research. These people were asked to circulate the 
questionnaire among their collaborators according to the snowball sampling method 
(Parker, Scott, & Geddes, 2019).  
Additionally, AV professionals were scouted using Vimeo, a video hosting and 
sharing platform that independent filmmakers employ to disseminate their works. 
Those whose profiles were relevant to the study were contacted via email or private 
message on Vimeo and invited to complete the questionnaire. 
The total number of responses the researcher aimed to receive was 30, which was 
thought to be appropriate due to (a) the challenges of engaging with AV 
professionals, (b) the effort required by participants to complete the survey, and (c) 
the vast amount of quantitative and qualitative data generated by the questionnaire. 
Moreover, Rowley (2014) expresses that certain circumstances, such as the difficulty 
in reaching specific populations, means that 20-30 is a realistic number of responses 
to expect. 
 
This design method was employed because it could be performed independently and 
remotely by participants. With a specific limit of 3 weeks to submit their responses, 
AV professionals could participate in the study whenever they had time to spare 
according to their work commitments. Respondents were based in Italy (22), UK (3), 
US (2), Ireland (1), Mexico (1), and Malaysia (1). 
 
 
6.4 Structure of the Questionnaire 
A crucial aspect of designing the questionnaire was deciding what questions to ask 
and which number of questions was appropriate. This determined the length of the 
questionnaire as well as the time required by participants to complete the survey. 
Macer and Wilson (2014) posit that approximately 15 minutes is an acceptable limit. 
This aligns with Cape's (2015, as cited in Brace, 2018) suggestion: the attention 
span of online survey participants is 20 minutes, on average. 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
117 
Other researchers, such as Rowley (2014), recognize the difficulty of defining the 
correct length of a questionnaire or the number of responses to collect, explaining 
that there are many factors researchers have to consider to better define these two 
aspects.  
 
One of the factors for the questionnaire was the presence of the three embedded 
stories that required time for reading. The researcher thought answers may be better 
if respondents first read Story 1 and completed all the related questions. After that, 
they could proceed to read Story 2 and so on. 
 
The overall structure of the questionnaire is divided into eight sections: 
 
• Section 1 – Consent  
• 
Inform participants about the research and receive their ethical 
approval 
 
• Section 2 – Introduction 
• 
Thank participants in advance and inform them of what they will be 
asked 
 
• Section 3 – Generalities  
• 
Collect information about participants’ age, roles, years of experience, 
AV sector, average team size, and average project budget 
 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
118 
 
• Section 4 – Story 1 
Describe this design fiction scenario and collect feedback  
 
• Section 5 – Story 2 
Describe this design fiction scenario and collect feedback  
 
• Section 6 – Story 3 
Describe this design fiction scenario and collect feedback  
 
• Section 7 – Final overall questions  
Ask participants to express preference towards one of the scenarios 
 
• Section 8 – Conclusion  
Thank participants again and ask whether they are interested in being 
contacted for future studies 
 
 
The integral Microsoft Forms version of the questionnaire used in this research to 
collect data can be found in Appendix II. 
 
 
6.4.1 Diegetic Prototypes 
The three diegetic prototypes ideated in PS-II were presented at the beginning of the 
dedicated session and were supported by visual suggestions (mood boards), 
including three abstract logos and fictional names. 
 
- 
DEPERO: A tribute to a famous futurist designer of the early XX century. 
 
- 
ALNINE: A tribute to HAL9000, the fictional AI presented in Stanley Kubrick’s 
2001: A Space Odyssey (Kubrick, 1968) 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
119 
- 
OSMOS 3: A tribute to designer Alex McDowell, who is responsible for the 
production design of the feature film Minority Report (Spielberg, 2002) 
 
 
Figure 6.1 Fictional Logos 
The length of each story was approximately 600 words, which required 
approximately 2-3 minutes for reading.  
Each story was told from the perspective of the main character, an AV professional 
who performs a specific role (Story 1 – set designer, Story 2 – director, Story 3 – 
editor).  
The underlying structure of the stories was composed of different elements with 
different objectives. 
 
I. 
Persona bio: Describes the main characters of the story 
 
II. 
Tech description: Describes the features and functionalities of fictional 
technologies 
 
III. 
Fictional workflow: Describes how fictional technologies are employed by AV 
professionals in their roles and production processes 
 
IV. 
Storytelling: Uses sentences and words to glue together all the elements and 
to facilitate the readers' immersion in the stories 
 
 
The full stories and complete mood boards are reported in Appendix I. 
 
 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
120 
6.4.2 Adapting the Technology Acceptance Model to This Study 
The TAM is a framework introduced by Davis (1989) to predict people's behaviour 
towards new technology. In DS-III, it was necessary to identify which of the three 
diegetic prototypes AV professionals perceived as most valuable to develop into a 
practical prototype in PS-IV. 
Davis argues that users' perception of a new technology's usefulness and ease of 
use affects the actual use of the technology system (Figure 6.2). 
 
 
Figure 6.2 Davis' (1989) Technology Acceptance Model 
 
 
Throughout the years, the framework has evolved and has become increasingly 
structured and complex (Venkatesh & Davis, 2000; Venkatesh & Bala, 2008). 
Furthermore, many researchers have adapted the framework to their needs, as 
reported by Marangunić and Granić (2015), who provide a comprehensive literature 
review about the topic. According to Al-Emran and Granić (2021), the TAM is a solid 
framework for conducting empirical research in various applications and fields.  
Bertrand and Bouchard (2008) adapted the TAM framework specifically for VR. 
However, they kept the framework relatively simple and considered the original 
variables of perceived usefulness and perceived ease of use. 
They conclude that ‘the TAM can predict well the intention of a favourable population 
to use virtual reality as a tool for treating mental health problems’ (Bertrand & 
Bouchard, 2008). 
Considering their conclusion, the researcher believed it to be opportune to adapt the 
TAM framework for this study. Similar to Bertrand and Bouchard (2008), the 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
121 
researcher in this phase of the study proposed to participants the employment of 
new technologies as tools via three design fiction scenarios ideated in PS-II. The 
difference is using the TAM framework in the AV field, as opposed to the medical 
one. 
 
The questionnaire structure includes some queries (Q12, Q13, Q17, Q18, Q22, Q23) 
adapted for the AV field and based on the TAM framework, as listed in Table 6. The 
questions were designed following findings from DS-I and DS-II and, more 
specifically, around the key points of AV professionals’ workflow (communication, 
creativity, pitching, logistic, and well-being). An additional adaptation is the 
measurement scale. Instead of using a 7-point Likert scale as proposed in the TAM 
framework, the researcher chose, after the pilot, to use a 5-point scale. This is 
further explained in the next chapter. What is reported in Table 6 is related to Story 
1 – DEPERO, but the same list of questions was asked for Story 2 – ALNINE (Q17, 
Q18) and Story 3 – OSMOS (Q22, Q23). Further details are provided in Appendix II. 
 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
122 
 
Table 6 Questions Adapted From the Technology Acceptance Framework  
Compared with the current pre-production workflow in the AV sector in which you 
most frequently work... 
Q12: Perceived usefulness 
5-point Likert scale 
...Using DEPERO may facilitate communication 
with other collaborators. 
Strongly Disagree = 1 
Disagree = 2 
Neutral = 3 
Agree = 4 
Strongly Agree = 5 
 
...Using DEPERO may lead to exploring more 
creative opportunities. 
...Using DEPERO may be more helpful in the 
decision-making process. 
...Using DEPERO may be more helpful when 
pitching ideas and asking for funding. 
...Using DEPERO may reduce filmmakers' 
ecological footprint (travelling, energy 
consumption, etc.). 
...Using DEPERO may improve filmmakers' 
well-being (mental health, safety, inclusivity, 
equity, etc.). 
Q13: Perceived ease of use 
Learning to use DEPERO may be easy for me. 
 
6.4.3 Open-Ended Questions  
In addition to closed-ended questions adapted from the TAM model, the researcher 
considered it opportune to collect more qualitative data by asking participants open-
ended questions. This strategy, especially with Q27, provided a deeper 
understanding of the previous and crucial Q26, which allowed the researcher to 
discern which practical prototype to develop.  
 
Answers collected from responses to Q14, Q19, and Q24 informed the researcher of 
potential pain points and criticalities in the scenarios presented. Additionally, Q15, 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
123 
Q20, and Q25 were introduced as feature requests for participants to offer direction 
on how these scenarios can be further developed.  
 
These open-ended questions were designed to collect precious insights that would 
contribute to iterating the same scenarios before starting prototype development. 
 
6.4.4 Self-Evaluation Questions 
In Q7 and Q8, respondents were asked to provide more information regarding the 
usual team size and the average budget of the projects in which they are usually 
involved. These questions were inserted to verify that professionals responding to 
the questionnaire were working in small and medium AV productions with limited 
resources and to allow the researcher to identify eventual sampling biases. 
 
Similarly, considering findings from Macer and Wilson (2014), Cape (2015), and 
Rowley (2014), the researcher wanted to recognize possible procedural bias; 
therefore, the final questions (Q28, Q29, Q30) were included to investigate whether 
participants encountered some difficulty while completing the questionnaire due to its 
length. Through self-evaluation, they could express whether they maintained a 
consistent focus and whether the materials provided (written and visual) were 
sufficient to answer the previous questions with confidence. 
 
6.4.5 Online Platform 
Microsoft Forms was chosen as an online tool because it was considered to be 
opportune for determining the structure of the questionnaire as intended by the 
researcher, allowing the inclusion of both closed- and open-ended questions and the 
clear, immediate visualization of the data collected. 
Additionally, the program offered the possibility to split the questionnaire into 
different sections, a helpful feature that is similar to turning the page of a book. This 
strategy was thought to provide some breaks to the respondents and enable them to 
better distinguish the various sections of the questionnaire (consent, introduction, 
generalities, Story 1, Story 2, Story 3, final questions, and conclusion). 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
124 
6.4.5.1 Pilot 
As Brace suggests (2018), ‘It is always advisable to pilot the questionnaire before 
the survey goes live’. Consequently, seven people (master design students, PhD 
design students, and lecturers) were asked to participate in the pilot and review the 
structure of the online questionnaire. The length of the questionnaire and clarity of 
the design fiction scenarios were most in need of testing.  
This activity further strengthened the questionnaire's structure and required slight 
adjustments. For instance, after the pilot, the researcher adopted a 5-point Likert 
scale instead of a 7-point scale because the 5-point scale was considered more 
straightforward, which would better allow participants to correctly interpret the scale. 
 
6.5 Results 
Initially, the researcher planned to employ the statistical software SPSS (IBM, 2022) 
to analyze the results, but Microsoft Forms' data visualization and analysis was 
already considered satisfying and valuable. 
Quantitative data from the closed-ended questions Q12, Q13, Q17, Q18, Q22, and 
Q23 were evaluated according to the TAM framework and the 5-point Likert scale. 
Qualitative data collected in the open-ended questions were classified following 
thematic analysis. 
 
6.5.1 Profiling 
The first 10 questions collected the generalities of the respondents and are reported 
in Figures 6.3 and 6.4. 
To preserve the initial goal of the research, it was essential to ensure that 
respondents were representative of and understood the participants at the centre of 
this exploratory research. Hence, they were asked Q7, ‘What is the average team 
size of the projects you are involved in?’ and Q8, ‘What is the average budget of 
those projects you are involved in?’ 
In Q7, most respondents worked in teams of 21-50 (11) or 6-10 (8). Only two 
respondents were involved in AV productions of 50+ people, a team size that does 
not fall within this study's definition of SMPs. Nevertheless, their responses were 
considered. 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
125 
    
 
Figure 6.3 Q7 Results: Average Team Size 
 
 
Figure 6.4 Q8 Results: Average Budget Size 
 
6.5.2 Main Outcomes 
Q12, Q17, and Q22 asked participants how a specific scenario, in terms of 
usefulness, compared to the current AV production process they employed. 
Analyzing the data collected revealed that all three design fiction scenarios were 
valued as preferable compared to their current workflow. According to Davis (1989), 
the results, derived from the average score received by each question, must be 
interpreted as follows:  
 
• Strongly Disagree = 1.00-1.89 
• Disagree = 1.90-2.69 
• Neutral = 2.70-3.49 
• Agree = 3.50-4.49 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
126 
• Strongly Agree = 4.50-5.00 
 
Furthermore, by analyzing and comparing the data generated by Q12, Q17, and 
Q22, it is possible to observe that Story 1 and Story 2 obtained similar scores in 
most sub-questions. However, the feedback received for Story 3 is positive but 
notably less positive than Story 1 and Story 2. 
 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
127 
 
Table 7 Perceived Usefulness 
Q12 
Q17 
Q22 
Compared with the 
current pre-production, 
production, and post-
production workflow in 
the AV sector in which 
you most frequently 
work... 
Scenario 1: 
DEPERO 
Scenario 2: 
ALNINE 
Scenario 3: 
OSMOS 
 
 
Average score Average score Average score 
Q##.1 ...may facilitate 
communication with 
other collaborators. 
4.16 
4.06 
3.26 
Q##.2 ...may lead to 
exploration of more 
creative opportunities. 
4 
4.46 
3.7 
Q##.3 ...may be more helpful 
in the decision-making 
process. 
4.13 
4.26 
3.56 
Q##.4 ...may be more helpful 
when pitching ideas and 
asking for funding. 
3.93 
4.1 
3.2 
Q##.5 ...may reduce 
filmmakers' ecological 
footprint (travelling, 
energy consumption, 
etc.). 
4.33 
4.03 
3.6 
Q##.6 ...may improve 
filmmakers' well-being 
(mental health, safety, 
inclusivity, equity, etc.). 
3.36 
3.86 
3.46 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
128 
 
Figure 6.5 Visual Representation of Data Related to Perceived Usefulness 
Therefore, to better understand what design fiction scenario was judged most 
promising between Story 1 and Story 2, it was crucial to examine the data from Q26.  
 
Figure 6.6 shows that of the 30 responses received, most respondents preferred 
Story 1 (n = 22). This result means that respondents agreed that the design fiction 
scenario described could potentially bring the most benefits to the AV production 
process compared to the other two design fiction scenarios. 
 
 
Figure 6.6 Q26: Most Valuable Scenario 
 
 
Those who answered Story 1 and also better explained their reasoning for Q27 
recognized the following potential benefits: 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
129 
a) Cost and Time Savings 
Most of the participants explained that this scenario could save time and money, 
thus reinforcing the opinion that also emerged from the one-on-one exploratory 
interviews. 
 
‘More opportunities for a director, time savings, lower costs, greater creativity 
during the shooting’  PQ13, directing department. 
 
‘Making a good pre-production reduces the costs and optimizes the budget (or 
reduces it)’  PQ15, directing department. 
 
‘It is more practical and the most effective in reducing production costs’  PQ17, art 
department. 
 
‘Is the most useful, as the tools described cut considerable time and expenses for 
pre-production’ PQ18, production department. 
 
I believe it would be incredibly helpful to speed up a lot of pre-production processes, 
and it would save a lot of money for location scouting, pre-lighting, set design 
prepping, etc. It would save an incredible amount of time and make pre-production 
more efficient. The team would arrive to principal photography much more prepared’ 
PQ23, production department. 
 
 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
130 
b) Extended Workflow Impact  
Some participants justified their response by expressing that it would impact many 
more figures and phases of the workflow compared to the other two design fiction 
scenarios. 
 
‘The first one is the most complete. It can help everybody on the crew and level 
up the pre-production work’ PQ06, art department. 
 
‘It has to do with the whole workflow for creating a movie – [whereas] the other 
two refer only to one step of the process. So the first scenario could potentially 
benefit a bigger slice of indie filmmakers’ PQ11, camera department. 
 
c) Better Output Quality and Quality of Life 
Some believed that such a scenario would improve their current quality of life and 
output. 
 
‘It will be the better way to work’ PQ09, directing department. 
 
‘It can help to increase the quality of the pre-production’  PQ12, directing 
department. 
 
d) Carbon Footprint 
A different perspective was offered by PQ25: 
 
‘Lowering the carbon footprint of your pre-production, especially in our current 
times where we are almost at the point of no return as it relates to our 
environment’ PQ25, development department. 
 
e) Technical Feasibility 
Some expressed a preference towards Story 1 because they considered such a 
design fiction scenario to be feasible in the near future. 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
131 
‘I think it is concretely the one closest to the reality of use. Story 2 and Story 3 are 
still very theoretical’ PQ16, camera department. 
 
‘I think it is the easiest to make. All the technology around it is almost already 
here. I also think it is something we do not have now. While we can create VFX 
and edit videos, there is nothing to pre-visualize a scene with photogenic 
precision. It is the easiest to introduce, make, and use but still the most useful. 
This technology could really change the behaviour of the pre-production crew’ 
PQ28, art department. 
 
Additional Comments on Story 1 
PQ02 (directing department) recognized the value brought by such a design fiction 
scenario but was hesitant in deciding whether it could replace in-person scouting: 
 
‘I think it could be a useful tool to add to a normal in-person location scouting. You 
usually have a few hours for doing the scouting, and this is a tool that allows you 
to work and rework on it. However, I am not sure if it could replace in-person 
scouting. Scouting is a time to meet heads of department in person, have a 
human connection, and share an idea together’ PQ02, directing department. 
 
PQ30 expressed a less exclusive opinion about this matter: 
 
‘It’s not trying to replace or compete with existing infrastructure but bringing 
something new that could be added to upcoming productions’ PQ30, camera 
department. 
 
 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
132 
Interest in More Than One Scenario 
Additionally, some participants wanted to express their interest in those design fiction 
scenarios for which they did not vote. 
 
‘I think both Stories 1 and 3 represent very useful scenarios for the industry. […] 
Story 3 describes tools that seem [like they] would make [the] life of editors much 
easier and probably healthier’  PQ18, production department. 
 
‘I think the first and the third are really useful. I prefer the third one just because 
it's for my role’  PQ01, post-production department. 
 
‘If I could choose two, also the first one could be really interesting, for the chance 
to have more tools to see alternative scenarios. But I think the second one, it is 
really a game changer in the industry. Also, as a director, sometimes [it] is hard to 
communicate with the post-production or understand how the output would be’ 
PQ02, directing department. 
 
What PQ02 expressed may be due to the quality of the output from the co-design 
workshop and the balanced presentation of the stories in clarity and detail. 
 
In this regard, Q30 was designed to investigate other potential procedural biases in 
narrating the stories. However, the results were precise and showed that none of the 
participants had issues understanding the design fiction scenarios. 
 
Despite the unusual length of the questionnaire and the effort required to complete it, 
the outcome from Q28 was satisfying. Only five of 30 respondents answered No, and 
in Q29, one (PQ25) of these five explained that, despite their length, reading the 
stories was enjoyable; another (PQ11) remarked that he felt the urge to explore 
more aspects of what was narrated by searching online.  
 
 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
133 
6.5.3 DEPERO Pain Points 
After they listed the potential benefits introduced by Story 1, respondents were asked 
in Q14 to indicate the most significant pain point that may stop them from adopting 
the presented workflow; this allowed them to further assess and evaluate the design 
fiction scenario and increase comprehensive understanding. 
 
‘As a set designer, I think it can be hard to create the structures or the details that 
you want to design in the set's space. It can be easy to import furniture from 
libraries, but less easy and less fast to create brand new 3D objects or textures. 
You should be quite specialized in this to do it’ PQ06, art department. 
 
One of the reasons some people pursued such professional career paths is because 
they enjoy spending time in close contact with other people and physically travelling 
to the chosen filming location. Consequently, some of them were concerned about 
missing the in-person visit and human exchange with other people. 
 
‘I think it could be a useful tool to add to a normal in-person location scouting. You 
usually have a few hours for doing the scouting, and this is a tool that allows you 
to work and rework on it. However, I am not sure if it could replace in-person 
scouting. Scouting is a time to meet heads of department in person, have a 
human connection and share ideas together. The digital filter keeps being quite a 
different feeling. Also, if you do narrative with dialogue, you also need to check 
the sound of the ambience, and in general, exploring in person a location, it is 
really important to me’  PQ02, directing department. 
 
‘A 3D set may look better than reality. Unexpected changes – such as weather – 
are not easy to be calculated. Even depth of field will not be considered in lenses, 
and location scouting is also useful to know the surrounding area. By the way, to 
have a better ecological footprint, do not choose crew from abroad’  PQ07, 
directing department. 
 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
134 
a) Budget 
A significant number of respondents indicated that the affordability of such a design 
fiction scenario could stop them from using DEPERO. Of 30 respondents for Q14, 10 
mentioned that the cost of the software and related expenses, such as the hardware 
and internet connection, might represent the primary dealbreaker for adopting 
DEPERO. 
This result was expected and showed the importance given by these stakeholders to 
their productions' budget. When they were presented with alternative and potentially 
more affordable scenarios such as DEPERO, before even thinking about learning 
how to introduce it in their workflow, they felt the urge to first investigate more about 
its affordability. 
Therefore, these data strongly support what was discovered during the literature 
review and first exploratory study. VP processes employed by other industry players 
such as ILM, Netflix, or WETA Digital were seen as expensive and out of reach by 
these stakeholders.  
 
b) Perceived Ease of Use 
The average score from the 5-point Likert scale for Q13.1, ‘Learning to use DEPERO 
may be easy for me’, was 3.56, meaning that overall, participants agreed with such a 
statement. As shown in Figure 6.7, 16 of 30 participants agreed or strongly agreed 
that it would be easy for them to learn how to use DEPERO, while 12 of 30 preferred 
to remain neutral.  
 
 
Figure 6.7 Q13 Results – Perceived Ease of Use of DEPERO 
 
Seven of these 12 expressed in Q14 how poor usability may stop them from 
employing DEPERO. 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
135 
 
‘The difficulty in learning to use it’  PQ13, directing department. 
 
‘Having already many online platforms/software/systems that sometimes are not 
as easy to use. Learning how to use the software properly can take time and, for 
some people, might not be very easy (for example, older generations still in the 
industry)’ PQ23, production department. 
 
‘The challenge of getting less tech-savvy crew, directors, or producers to use VR 
tech, particularly older ones’ PQ30, camera department. 
 
Introducing a new tool in the workflow of professionals remains a delicate matter, 
and it is one of the reasons why Davis’ TAM (1989) asks several questions to 
investigate the perceived usability of proposed innovations.  
Because AV productions are generally composed of heterogeneous age groups, 
PQ23 and PQ30 further mentioned that older collaborators might encounter 
additional friction in learning how to use new tools.  
 
c) Network Effect, Accessibility, and Proficiency  
Other participants underscored that such a collaborative scenario depends on the 
number of collaborators having access to DEPERO (software, hardware, and reliable 
internet connection) and their ability to use it. 
 
‘People I work with not having access’  PQ24, directing department. 
 
‘If the people I collaborate with on the project didn't use or didn't know how to use 
DEPERO’ PQ26, production department. 
 
‘Having an international team used to having DEPERO’ PQ28, art department. 
 
This important aspect on which participants remarked can be traced to the so-called 
network effect first investigated in the field of telecommunications and economics 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
136 
(Rohlfs, 1974) that has since been extended to software services (Gallaugher & 
Wang, 2002). This phenomenon describes how the benefit or value a user receives 
from a product or service depends on the number of customers who use similar 
goods. As new customers adopt the product or service, its value and utility increase.  
 
d) AV Sector Dependent 
Some participants believed that it was logical to employ DEPERO only in specific AV 
sectors. 
 
‘A software like this would not be a fit depending on the genre of film I am making. 
Genres like documentaries would not benefit from this workflow’ PQ11, camera 
department. 
 
PQ11's perspective may have been motivated by the discussion in Section 4.7.5 in 
which a participant who worked on documentaries explained the value behind 
unforeseen events and aspects of a documentary. PQ18 offered a similar opinion 
regarding the unsuitability: 
 
‘The size and scope of the projects I work on, as they are particularly low-
key…with a lot of the scouting to be done directly on location after arrival’ PQ18, 
production department. 
 
e) Visual Fidelity 
Some participants were critical of the image quality represented in the immersive 
environment. They noted that a mismatch between the simulation and the actual 
location could lead to false expectations and bring more disadvantages than 
advantages.    
 
‘A 3D set may look better than reality. [A] casual change – such as weather – is 
not easy to be calculated. Even depth of field will not be considered in lenses, and 
location scouting is useful also to assess the surrounding area’ PQ07, directing 
department. 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
137 
 
‘Not giving a real and authentic [imaging] of the elements [such as locations or 
lights] can lead to creative errors or misunderstandings that can damage the 
production’ PQ19, production department. 
 
‘I would stop using DEPERO if the graphic rendering and image quality were poor’ 
PQ26, production department. 
 
6.5.4 Additional Features to Implement Within DEPERO 
Q15 asked what additional features participants would desire to be implemented in 
DEPERO. Some of these features were initially included in the first draft of the 
design fiction scenario described in Story 1. For instance, the ability to take 
screenshots of the virtual scene or the need to be aware of the area's facilities, 
roads, and shops emerged since the first exploratory in-depth interviews. 
Nevertheless, it was crucial to reduce the length of the stories as much as possible; 
hence, the scenario presented was not comprehensive of all the features planned to 
integrate into the final prototype.  
 
Features 
request 
# 
Name 
Brief description 
Suggested 
by 
01 
Virtual actors and 
actresses 
Being able to place, in scene, 
mannequins or real actors and 
actresses who have been scanned. 
Being able to animate them. 
PQ2, PQ28 
02 
Sun keeper 
Sunlight simulation based on 
location and date of shooting 
(similar to existing application 
Helios Pro). 
PQ7, 
PQ18, 
PQ28 
03 
Budget control 
An automatic feature that would 
inform users of the estimated cost 
of the scene they are planning 
PQ9, 
PQ10, 
PQ19 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
138 
based on the virtual objects or 
equipment added. 
04 
Photo and video 
export 
Being able to take screenshots of 
planned references or storyboards 
or even record videos of the scene. 
PQ12, 
PQ15 
05 
Surrounding 
location 
Being able to assess the 
surrounding of the location for car 
parking, power sources, load-in, 
actors’ and actresses' wardrobe, 
etc.). 
PQ25; 
PQ28 
06 
Lighting 
Being able to add artificial lights 
and simulate their effect on the 
location, objects, and actors and 
actresses. 
PQ16 
07 
Day and night 
Being able to simulate how the 
location will look like during daytime 
and nighttime. 
PQ28 
08 
Digest summary 
A way to keep track of the 
decisions made after the 
collaborative session. 
PQ11 
09 
Interoperability with 
different media 
formats and 
telecommunications 
means 
Being able to import, export, and 
share other media, such as photos, 
videos, or documents. Being able 
to start and receive phone and 
video calls. 
PQ16, 
PQ30 
10 
Write script 
Being able to write a script. 
PQ17 
11 
Basic editing 
Being able to edit different 
screenshots or videos. 
PQ1 
12 
Space 
measurement 
Being able to take the 
measurements between two points. 
PQ18 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
139 
13 
Import props from 
library 
Being able to access a library to 
obtain props to add to the scene. 
PQ20 
14 
Tutorial 
An introduction to the software and 
how to use it. 
PQ21 
Table 8 Features Suggested by Participants in Q15 
 
It was deliberately decided to report the outcomes, pain points, and requested 
features of only the most preferred scenario (Story 1).  
Further presentation and analysis of the results derived from the other stories would 
lengthen this chapter unnecessarily, as the overall plan of this work is to further 
develop into a prototype only one scenario due to time and resource constraints. 
 
However, the results of the questionnaire and comprehensive responses to Stories 2 
and 3 are reported in Appendix II. The data collected for these scenarios can provide 
valuable insights to those researchers seeking inspiration and interested in exploring 
these scenarios. 
 
6.6 Discussion 
This study not only highlighted the direction for the progression of the overall 
research but also offered the researcher useful feedback on the strengths and 
weaknesses of the prototype to be developed. 
Overall the engagement in the open-ended questions was high. Many of the answers 
provided clear reasoning and were rich in detail. 
According to participants responding to this questionnaire, the design fiction scenario 
presented in Story 1 was considered the most promising to develop further in a 
practical prototype. 
This may be because, in such a scenario, more roles are involved compared to 
Stories 2 and 3, which present a workflow that is more role-specific. 
 
The results also revealed that, when expressing feedback on Story 1, a significant 
portion of participants stated that the cost of the equipment required to adopt the 
workflow presented can be an obstacle to its actual use. This confirms the critical 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
140 
concern among SMPs around the economic implications of each choice they made: 
from casting specific actors and actresses to purchasing the rights for a specific 
soundtrack or even, as in this case, introducing new tools and technologies, every 
cost must be considered.  
 
It is essential to acknowledge the potential bias in favour of Scenario 1, considering 
that a majority of respondents to the questionnaire were involved in pre-production 
and production roles. The only preference expressed for Scenario 3, related to post-
production, came from an individual working as an editor. Therefore, it is reasonable 
to question how the results might have differed if more responses had been collected 
from AV professionals specializing in post-production, such as VFX Artists, Motion 
Graphic Designers, and 3D Artists. 
 
In retrospect, it could be more appropriate to add a variable in Q8 that includes a 
budget range of $100,000-$250,000. Such a range could have provided better data 
granularity. Overall, the fact that 25 of 30 respondents worked on projects with 
budgets below $100,000 confirms that the stakeholders recruited were those 
intended.  
 
Additionally, the usability of the future practical prototype intended for development 
was considered a potential dealbreaker, especially for less technologically skilled 
collaborators. Therefore, key aspects such as affordability and usability were 
considered when designing the prototype in PS-III. These considerations can be 
attributed to AV professionals' practical nature. 
 
 
 
 
6. Ideas Filtering and Iteration (DS-III) 
 
 
 
141 
6.7 Chapter Summary 
This chapter described the design of three diegetic prototypes in the form of written 
stories based on the three design fiction scenarios identified in PS-III. It also 
explained the goal of this stage, which was to identify, via an online questionnaire, 
the scenario considered most valuable by AV professionals. The questionnaire 
included closed-ended questions, many of which were adapted from the TAM 
framework, and open-ended queries that collected qualitative data. 
After analyzing the results, the researcher concluded that the most valued scenario 
related to an immersive and remote pre-production workflow. This chapter’s 
discussion of these key findings provided comprehensive insights that enabled the 
development of a practical prototype that was tested and evaluated in DS-IV. 
 
 
 
 
 
 
 
 
 
 
142 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Chapter 7 
 
PROTOTYPE DESIGN (PS-IV)  
AND TESTING (DS-IV) 
 
 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
143 
7. Prototype Design (PS-IV) and Testing (DS-IV) 
 
7.1 Introduction 
This chapter is divided into two main parts. The first explains the rationale behind the 
prototype designed and developed based on the findings from DS-III. Next, it 
describes the outcome of the prototype evaluation as expressed by participants 
during 11 user testing sessions. 
 
In the second part, Section 7.6, the researcher further explores the technical 
feasibility of a specific feature of the practical prototype designed in PS-IV. 
Consequently, the researcher explains the process of designing and testing the 
immersive planning and automation of a drone shot, which is referred to as a sub-
prototype.  
 
7.2 Aim 
In this phase, the researcher collected feedback on the prototype's usefulness and 
ease of use to address RQ1.3: What alternative VP process can be co-designed and 
developed to enable SMPs’ adoption of VP? The outcome of this study led to the 
definition of design recommendations for applying VP to SMPs, which is explained in 
detail in Chapter 8.  
 
7.3 Participants 
COVID-19 restrictions gradually eased, which allowed this study to be the first in this 
research to be conducted in person, enabling participants to interact physically with 
the prototype and experience immersive technologies in practice.  
 
The prototype's development was characterized by a collaborative element, so the 
researcher thought that testing participants should come from AV companies to 
enable the involvement of multiple participants accustomed to working together who 
could form groups.  
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
144 
Because of the limited time at the disposal of AV professionals, the researcher 
thought it worthwhile to conduct the user testing sessions at their workplace. The 
geographic locations where the researcher could physically travel were the London 
area (United Kingdom) and the Milan area (Italy). Considering this, an online search 
was performed to identify the most suitable AV companies in these areas.  
 
The researcher also decided to recruit some of the participants involved in previous 
phases of the research. Once again, snowball sampling was employed, and previous 
participants were asked to involve other participants corresponding to the criteria 
provided by the researcher. 
 
Since it was decided to contact production companies, most professional figures 
involved in this study were producers. This outcome was expected since SMP 
companies can be seen as empty boxes that usually fully employ only those in 
production roles. Once a project is confirmed and the budget defined, producers start 
involving the other professionals needed (camera operators, set designers, 
cinematographers, directors, etc.) who usually work as freelancers.  
 
As explained in the previous chapters, producers participate in AV productions from 
inception to final delivery. They oversee the whole project and are aware of the 
different needs and working habits of all involved personnel. This scholar aimed to 
test and evaluate an alternative workflow; therefore, producers' presence in this 
research phase was considered precious.  
 
Participants were based in Italy (23) and UK (six) for a total of 29 professionals who 
formed 11 groups of two or three participants each, depending on participants' 
availability and last-minute defections, plus the facilitator. Creating groups of three or 
four people was considered optimal for performing collaborative tasks and 
incentivizing participants to communicate with each other. It was also the maximum 
number the facilitator could concurrently manage. Before the beginning of the 
session, VR and AR devices as well as recording devices needed to be set up. 
During the session, the facilitator quickly fixed eventual technical issues encountered 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
145 
by participants and guided them through the procedure. Furthermore, four people in 
the same virtual space was the maximum allowed by Gravity Sketch, the VR 
software used for operating part of the user testing activities; this is better explained 
later. 
 
PARTICIPANT 
GROUP 
ROLE 
DESCRIPTION 
PT01 
GROUP 1 
Video consultant 
Involved by clients to design video 
strategies and oversee production 
PT02 
Motion graphic 
designer 
Working mainly on commercials 
PT03 
Camera operator 
Working mainly on commercials 
PT04 
GROUP 2 
Producer 
Overseeing the entire production process 
of commercials and documentaries 
PT05 
2D animator 
Working as 2D animator and motion 
graphic artist for commercials and 
documentaries 
PT06 
GROUP 3 
Producer 
Planning and organizing the production of 
commercials 
PT07 
Producer 
Planning and organizing the production of 
commercials 
PT08 
GROUP 4 
Executive 
producer 
Overseeing the entire production process 
of commercials, documentaries, and 
fictional projects 
PT09 
Post-production 
supervisor 
Overseeing the post-production process 
of commercials 
PT10 
GROUP 5 
Executive 
producer 
Overseeing the entire production process 
of commercials, documentaries, and 
fictional projects 
PT11 
Executive 
producer 
Overseeing the entire production process 
of commercials, documentaries, and 
fictional projects 
PT12 
Director 
Directing commercials and other fictional 
AV genres 
PT13 
GROUP 6 
Executive 
producer 
Working on the business side of 
commercials, film, and TV projects 
PT14 
Post-production 
supervisor 
Directing short ﬁlms and art installations 
and actively seeking funding 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
146 
PT15 
Producer 
Working on the business side of film or 
TV projects 
PT16 
GROUP 7 
Producer 
Planning and organizing the production of 
commercials  
PT17 
Producer 
Planning and organizing the production of 
commercials 
PT18 
GROUP 8 
Producer 
Overseeing the entire production process 
of fashion commercials 
PT19 
Producer 
Overseeing the entire production process 
of fashion commercials 
PT20 
Editor 
Editing of fashion commercials and 
fictional TV series 
PT21 
GROUP 9 
Producer 
Overseeing the entire production process 
of commercials, documentaries, and 
fictional projects 
PT22 
Assistant 
producer 
Assisting producers in planning and 
organizing productions 
PT23 
Assistant 
producer 
Assisting producers in planning and 
organizing productions 
PT24 
GROUP 10 
Producer 
Overseeing the entire production process 
of commercials, documentaries, and 
fictional projects 
PT25 
Producer 
Working on the business side of 
commercials, film, and TV projects 
PT26 
Post-production 
supervisor 
Overseeing the entire post-production 
process of commercials, documentaries, 
and fictional projects 
PT27 
GROUP 11 
Cinematographer 
Working mainly on commercials 
PT28 
Cinematographer 
Working mainly on commercials 
PT29 
Editor 
Editing commercials  
 
Table 9 Summary of the Total Participant Pool (User Testing) 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
147 
7.4 Prototype Design (PS-IV) 
This section describes the rationale employed while designing the practical prototype 
and its functionality. 
 
7.4.1 Convenience of Pre-Existing Technologies 
Developing immersive hardware devices and software applications from scratch is 
out of the scope of this exploratory study and exceeds the researcher's resources in 
time and expertise.  
Addressing RQ1.3 required the identification of accessible and affordable immersive 
hardware and software products that were available on the market before the 
storyline of Story 1 could be realized. This approach was also supported by the 
findings in the previous phases of the research (DS-I and DS-II), which revealed that 
easy access to affordable hardware products and software services was considered 
crucial for participants. 
 
7.4.1.1 Overview of VR Headsets  
The current landscape of suitable VR headsets does not present as much variety as 
other consumer electronic devices, such as smartphones or laptops. This fact 
significantly reduced the possible choices of VR headsets that might meet the need 
for this phase of the research.  
The Meta Quest 2, the headset employed for this study, is a wireless, all-in-one VR 
device, meaning that both the head-mounted display and computing power (CPU) 
are integrated in the device and do not require any external equipment, such as a 
desktop computer. Meta designed this headset to be plug and play and aimed to 
reduce user friction. According to data provided by Steam (Steam, 2022), the Oculus 
Quest 2 has the highest market share in headsets (49.25%) at the time of writing. 
Other headsets, such as Valve Index, HTC Vive Pro, and Windows Mixed Reality, 
were initially considered. However, these are designed to be connected via cable to 
a personal computer to use the computational power to operate VR software. Having 
three or four headsets wired to their corresponding PC would limit participants' 
movements within the physical space. 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
148 
7.4.1.2 Overview of Mobile Capturing Software 
SiteScape (2022) was initially thought to be valid for capturing spatial data of the 
real-world location where an AV product may be set. The documentation made 
available by its creators was informative to move the first steps and generate high-
quality scans. However, the only file formats SiteScape uses for export are .ply, .rcp, 
and .e57, which all represent point cloud data (a collection of individual points 
captured by the LiDAR scanner through a set of XYZ coordinates). Such formats 
would have required some additional and burdensome steps to convert files to a 
format representing 3D geometry, such as .obj. 
Therefore, the researcher preferred to use a software capable of capturing these 
individual points and processing them to a 3D mesh that would allow a direct import 
into the VR software for the next phase of the workflow (Gravity Sketch, 2022). 
Additional research and testing indicated that Polycam (2022) was better than 
SiteScape because of the smoother workflow in processing and exporting the data 
captured. Polycam generates a similar visual result and allows export of the capture 
in more than 10 formats, including .obj, which is compatible with Gravity Sketch. In 
contrast to SiteScape, which supports only iOs, Polycam has also been developed 
for Android and offers a web application, thus allowing more users to employ 
Polycam. 
  
7.4.1.3 Overview of Immersive Sketching Software 
Regarding VR software that specialises in sketching, many applications have already 
been developed and receive continual updates to implement more features and 
compatibility.  
 
Oculus Medium is a VR application focussed on creating 3D objects and characters 
that are compatible with Oculus Rift, Oculus Rift S, and Oculus Quest. The 
application was initially released in 2016 by Facebook (Meta), acquired by Adobe in 
2019, and rebranded as Medium by Adobe. It has some advanced features specific 
to 3D sculpting and is well integrated with other texturing and rendering software in 
the Adobe ecosystem. It is a free, single-user application. 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
149 
Tilt Brush is another VR painting cross-platform application released by Google in 
2016. Its source code was made available in 2021. It is designed to be artistically 
oriented, offering a wide variety of brushes to be used freehand. Computer-aided 
geometric features for drawing and its compatibility with different formats and media 
are limited. Furthermore, Tilt Brush was originally a single-user application, but after 
the source code became available, Rendever developed a multi-user paid version 
called MultiBrush (2022). 
 
Gravity Sketch is a free cross-platform VR application released in 2017 that enables 
sketching freehand or using a tool set to recreate symmetry, manipulate surfaces, 
and collaborate from anywhere through their cloud-based solution, Landing Pad. 
What differentiates Gravity Sketch from the previously mentioned applications is the 
wide variety of tools that can be employed for different purposes. It is used by 
designers to quickly sketch, iterate, and evaluate ideas, independently or with other 
collaborators. Up to four people can be present in the same virtual environment and 
exchange thoughts through the microphones integrated with most of today’s 
consumer VR headsets. Additionally, different users can work on different layers, 
which can be locked by the owner of the room. This basic permissions system for 
edits is aligned with the user requirements that emerged during PS-I. 
Equally important is Gravity Sketch’s compatibility with widely used geometry 
definition file formats, such as .obj and .usdz, or graphic formats, such as .png and 
.jpeg, thus allowing users to smoothly import and export files. 
Gravity Sketch was considered the most suitable to recreate Scenario 1 among the 
three programs because of the sketching tools provided, the multi-user support, and 
its economical accessibility, an aspect that was often mentioned by participants 
throughout the phases of the research. 
 
To better understand ideal practices to acquire optimal performances from these 
programs, the researcher directly contacted these programs' online customer service 
and asked specific questions to obtain further insights and guidance. 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
150 
7.4.2 Prototype Description 
Prototypes are commonly associated with initial models of physical objects to test a 
design. However, the term prototype can also be extended to the design of 
workflows or processes. The scenario portrayed in Story 1 describes an alternative 
process related to the pre-production phase; therefore, the prototype designed in 
PS-III and tested in DS-IV was a workflow composed of different stages that 
employed various technologies. 
 
This alternative pre-production process can be divided into two stages:  
 
1) Capturing and retrieving a digital replica of the filming location 
2) Immersive pre-production in the digital replica of the filming location 
 
7.4.2.1 Capturing and Retrieving a Digital Replica of the Filming Location 
Findings from previous studies (DS-I and DS-II) indicated that location is crucial in 
defining an AV production. The location dictates several creative and technical 
decisions that professionals must make in the pre-production phase. 
Consequently, accessing the digital replica of the location was identified as the 
starting point for the proposed alternative pre-production workflow. 
 
To do so, the prototype workflow was integrated into two possible options:  
 
i) 
Generate a digital replica of the intended location using capturing 
technologies, such as photogrammetry or the LiDAR sensor, integrated 
into the iPadPro in combination with the Polycam application, 
 
or 
 
ii) 
Retrieve pre-existing 3D models or scans of the locations sought on 
platforms and marketplaces, such as Sketchfab, Thingiverse, TurboSquid, 
and CGTrader. 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
151 
 
In the prototype testing phase (DS-IV), participants tested both options to collect 
different feedback, as explained in Section 7.4.3. 
 
 
7.4.2.2 Immersive Pre-Production in the Digital Replica of the Filming Location 
Once the 3D model of the location was generated or retrieved, it was imported into 
the VR application Gravity Sketch. Although Gravity Sketch is meant to be used by 
product designers as the end users, with some imagination, it is possible to re-
interpret some of its features and functionalities to align with AV professionals' 
needs.  
Importing into Gravity Sketch the 3D model of the location enabled AV professionals 
to virtually execute some of the tasks commonly performed during the pre-production 
phase, such as location scouting, location recce, rehearsing, compiling a shot list, 
and designing the set. Some of these activities are represented in Appendix V in 
Figure V.1.7. 
 
It is also important to mention that the significant amount of qualitative data collected 
in DS-III contributed to iterations of the prototype design before its development in 
PS-IV. 
Participants were asked in Q15 which additional features should be integrated into 
DEPERO, and they listed several functionalities that are not present in Gravity 
Sketch. 
To overcome this limitation, some of the desired additional features were integrated 
by adapting the Wizard of Oz technique, which was first proposed by Kelley (1983) 
and then widely adopted in the Human Computer Interaction (HCI) research 
community (Weiss et al., 2009). The concept behind the Wizard of Oz technique is 
having a human (the wizard) simulate the missing functionalities of a system. This 
allows users to have the perception of a flawless experience and enables 
researchers to collect their feedback and opinions as they experience the final 
system.  
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
152 
In this study, the facilitator was the wizard during the user testing sessions and 
demonstrated some of the functionalities requested by participants but not integrated 
into Gravity Sketch. Users were informed about the adoption of the Wizard of Oz 
technique. 
 
Creative use of tools provided by Gravity Sketch combined with the facilitator’s 
storytelling (Wizard of Oz technique) offered users the impression that the following 
functionalities were integrated into Gravity Sketch: 
• A day and night mode to simulate these lighting looks (PQ28) 
• A budgeting chart updated in real time depending on what object or filming 
gear (lights, cameras, dollies, etc.) is added to the scene (PQ9, PQ10, PQ19) 
Some of the functionalities derived from the responses to Q15 could be integrated 
into the prototype since they were already present in Gravity Sketch. 
• Import props for set design (PQ20) 
• Import 3D scans of people (PQ2, PQ28) 
• Export photo and video (PQ12, PQ15) 
• Take measurements through the tape tool (PQ18) 
The complete list of activities and tasks executed in this immersive pre-production 
phase is reported in Appendix III. 
 
7.4.3 Virtual Locations 
Filming locations are at the centre of many creative and technical decisions. Three 
virtual locations with different characteristics, aesthetics, and purposes, were 
retrieved from 3D asset libraries (Location 01 and Location 03) or captured manually 
by the researcher (Location 02). 
 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
153 
7.4.3.1 Location 01: La Casa Gassia (Demonstration) 
 
 
Figure 7.1 3D Capture of La Casa Gassia 
 
The first location presented to participants was a historical and remote house named 
La Casa Gassia, a domestic location in the Pyrenees that is not convenient in the 
preliminary phase as a location recce. 
Participants were also offered some context and reasoning regarding why they 
would shoot here: they were involved in a short film set in the 19th century, and their 
director considered this location to be a suitable place to shoot the project. 
One participant responding to the questionnaire (PQ06, set designer) expressed 
interest in importing a 3D asset in the scene from pre-existing 3D libraries. 
Therefore, while designing the practical prototype, the 3D model of La Casa Gassia 
was retrieved from Sketchfab (Giravolt, 2021). On this platform, creators share their 
3D creations under different licences (Creative Commons included).  
 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
154 
7.4.3.2 Location 02: Tower D (Practice) 
 
 
Figure 7.2 3D Capture of Tower D Entrance at Brunel University 
The second location, Tower D, presents a peculiar backstory that is worth explaining. 
While designing this user testing study, the researcher discovered that Brunel 
University was one of the main filming locations for Kubrick’s famous feature film, A 
Clockwork Orange (Kubrick, 1971). The university was designed by Richard 
Sheppard, who opted for brutalist architecture, a style that since the ’50s has 
become increasingly popular in the UK. The use of bare materials, such as concrete, 
and angular, minimalistic geometric shapes characterize brutalist architecture. 
Kubrick thought that establishing the fictional Ludovico Medical Facility in such a 
context was appropriate to convey the sense of oppression and domination that the 
main character, Alex, would face in that part of the story. 
Some other interiors of the university, such as the entrance of Tower D, were used 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
155 
for other scenes of the movie, including where Alex encounters his gang waiting for 
him (Figure 7.3). 
This scene was a source of inspiration while designing the study, as it allowed the 
researcher to experiment with and practice the first part of the proposed process. 
The entrance of Tower D was captured using Polycam and the LiDAR scanner, 
which were integrated into the iPadPro 2020. Once the capture was elaborated by 
the Polycam cloud, the resulting .obj file was imported into Gravity Sketch and ready 
to be experienced by participants in the collaborative room of Landing Pad (Figure 
7.2). 
 
Figure 7.3 Scene From A Clockwork Orange Set at the Entrance of Tower D 
When participants reached this point in the user testing sessions, they were 
instructed to recreate a scene without being informed that it was based on the 
screenplay of A Clockwork Orange. When the allotted time ended or when they 
completed the tasks, they were asked to remove the headset and take a break. 
During this pause, they were shown the original scene shot by Kubrick more than 50 
years before in the location they had just virtually experienced. This surprised them 
and created a link between the proposed prototype and a real-world scenario.  
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
156 
In conclusion, choosing Tower D as the backdrop of the second location was useful 
for the scope of the study and represented an unexpected tribute to Kubrick. 
7.4.3.3 Location 03: Mont-Saint-Michel (Practice) 
 
 
Figure 7.4 3D Capture of Mont-Saint-Michel 
 
Many filming locations are set in interiors, but many other AV productions are set in 
exteriors. Consequently, the third location was a capture of Mont-Saint-Michel, the 
famous tidal island in Normandy, France. The 3D model was retrieved from 
Sketchfab (3dcreation_lyon, 2021). 
The first two locations were shown at a 1:1 scale to participants; however, this 3D 
location was presented on a smaller scale, as if it were a physical 3D model used by 
architects when presenting a project. 
The scale and perspective from above provided participants with a more 
comprehensive understanding of the entire location and its surroundings.  
A quick overview of the 3D model was considered optimal for the fictional script 
ideated by the researcher to prompt participants in executing some tasks. 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
157 
In this phase, participants were informed that the client, Normandy's ministry of 
tourism, wanted them to recreate a complex camera shot using a drone flying around 
Mont-Saint-Michel. Once again, this idea was inspired by one of the participants 
during the co-design workshops (PW02, cinematographer), who imagined a workflow 
where one could use the controllers to draw the drone's flight path in the 3D space to 
simulate in an immersive environment.  
In this phase of the user testing session, participants were also presented with a 
different experience of visualizing the virtual elements through the Passthrough 
experimental feature offered by Gravity Sketch (Figure 7.5).  
Passthrough allows one to see the real surroundings (e.g., the room where the user 
testing session is occurring) through the front cameras that are integrated into a VR 
headset, such as the Meta Quest 2. Using this hybrid view mode, it is possible to 
view in the real space virtual objects that are tracked in real time. There is no 
common agreement on the terminology to use to define this viewing mode. 
Pioneering researchers Milgram and Kishino (1994) developed a taxonomy 
encompassing the various forms of immersive technologies, the so-called Virtuality 
Continuum, which ‘connects completely real environments to completely virtual 
ones’. Industry players such as Meta (Oculus VR, 2021) refer to this as MR, and 
others, such as Varjo, as XR (Konttori, 2020). In this research, the umbrella term MR 
was adopted. The reason for switching from VR to MR was purely exploratory and 
aimed at collecting participants' opinions and feedback. 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
158 
 
Figure 7.5 VR Viewing Mode (left) and Mixed Reality Viewing Mode (right) 
 
7.5 Prototype Testing (PS-IV) 
 
Pilot 
To test the overall procedure, a pilot study session was held involving doctoral 
design researchers and film production students at Brunel University London. 
After the pilot, it emerged that preparing the equipment and the virtual environment 
was crucial to avoid delays during the testing session. Additionally, it was important 
to prevent participants from taking extra steps that were not relevant to the scope of 
the study.  
 
Once in Gravity Sketch and assessing the location's digital capture, participants 
taking part in the pilot study, were confused by the incorrect scale of the location 
showed while immersed in VR. To overcome this issue, while preparing the virtual 
environment, the researcher ensured that the location was scaled correctly and then 
locked it using the permission system already present in Gravity Sketch, as shown in 
Figure 7.6.  
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
159 
 
Figure 7.6 Layers' Functionality Inside Gravity Sketch 
 
Locking some elements, such as the location's 3D capture, prevented participants 
from accidentally moving or deleting elements with which they were not supposed to 
interact. 
Additionally, the researcher desired to reduce the time spent explaining how to use 
all the functionalities of the controllers, which could result in information overload. 
For the scope of the study, it was more important to push participants’ attention to 
the verbal assessment and discussion of pre-production tasks needed in a specific 
location. 
Accordingly, the initial number of tasks to be executed by participants was reduced 
in favour of providing the facilitator with more time to demonstrate the different 
features of the potential prototype workflow. 
Finally, during the several planned breaks, participants exchanged thoughts on what 
they had just experienced, so it was important to consider these breaks as an 
important time frame to collect participants' spontaneous feedback. 
 
7.5.1 Procedure 
The following sections describe the procedure designed by the researcher according 
to the scope of the specific study. 
 
7.5.1.1 Preparation 
After agreeing to join the user testing session, participants were informed via email 
or phone about the requirements needed to successfully operate the designed 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
160 
procedure. More specifically, they needed to have an empty, walkable 12 foot by 12 
foot room and a Wi-Fi connection.  
The researcher created four Gravity Sketch accounts, one for each VR headset. This 
allowed four people to access the same virtual space, which Gravity Sketch calls a 
Landing Pad Collab room. Moreover, to quickly identify each headset, each was 
assigned a code name inspired by the famous movie Reservoir Dogs (1992), where 
the main characters were named after colours, such as Mr Orange, Mr White, and 
Mr Pink. As with the tribute to Kubrick, this choice of referencing a famous movie 
was both functional and helpful to engage with participants in a playful way. 
 
 
Figure 7.7 Naming and Setup of VR Headsets 
All the 2D (photos, screenshots, textures) and 3D assets (set design props, 
characters, 3D scanned locations) had previously been organized in a cloud folder 
on Landing Pad. An internet connection made it possible to retrieve the assets 
needed anytime and anywhere and place them in the virtual environment.  
Additionally, for highly detailed assets, such as the 3D location and character scans, 
the open-source 3D modelling software Blender was used to reduce the polygons of 
these assets. As reported in the documentation provided by Gravity Sketch (Kujovic, 
2022), when using the Oculus Quest 2 wirelessly, participants should not introduce a 
scene with more than 500,000 polygons (or faces). Exceeding this would negatively 
impact the performance of Gravity Sketch. 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
161 
Data were collected using an omnidirectional microphone to capture what was 
expressed by participants regardless of their position in the room and a video 
camera to capture participants’ behaviours as well as interactions and to have an 
additional audio backup. 
Furthermore, the VR collaborative sessions on Gravity Sketch and their sketches 
were saved. The same was done for the 3D captures created using Polycam. This 
decision allowed the researcher to retrieve what was generated by participants and 
extract visual materials to include in this writing for illustrative purposes. Testing 
session participants were rewarded with a £50 voucher. 
 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
162 
7.5.1.2 Execution 
 
 
Figure 7.8 Collage of the 11 Sessions With a Total of 29 Participants 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
163 
Before starting, participants provided their informed consent, and a brief introduction 
to the study was offered. Using the Polycam application installed on the iPad Pro, 
the facilitator demonstrated how to capture the surrounding space digitally. 
Participants tried to replicate the process, and they were asked to think aloud while 
performing the task to provide direct data on their ongoing thinking processes (Van 
Someren, Barnard, & Sandberg, 1994).  
After the end of this phase, they were shown how to wear the Oculus Quest 2 
devices, and then the facilitator provided a VR headset to each participant. When 
wearing the headset, each participant was already in Gravity Sketch and logged in to 
the collaborative room. 
They could see each other as minimalistic avatars where only their head and hands 
were represented in the virtual world (Figure 7.9). 
 
 
Figure 7.9 Gravity Sketch Avatars 
 
The facilitator then briefly explained the controllers' main buttons with an illustration 
prepared beforehand and already present inside the virtual environment (Figure 
7.10). 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
164 
 
Figure 7.10 Controllers' Instructions for Participants 
 
The considerable amount of effort required of the facilitator to oversee multiple 
aspects for the correct execution of the testing session prompted him to create and 
import part of the procedure into the virtual environment. This eased the process for 
the facilitator and allowed him to remember the planned activities (Figure 7.11). 
 
 
Figure 7.11 User Testing Procedure Document Imported Within Gravity Sketch 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
165 
After assessing, discussing, and collaborating in the three locations (01: La Casa 
Gassia; 02: Tower D; 03: Mont-Saint-Michel), participants were informed that this 
activity in Gravity Sketch was over and a semi-structured group discussion would 
ensue.  
 
To collect qualitative data from the group discussion, the questions asked of 
participants required them to assess the main aspects and functionalities of the 
prototype they had experienced. 
The group discussion questions were designed to acquire additional feedback on the 
following: 
 
a) The virtual location scouting and recce activity (navigation) 
b) The overall visual representation of the location and other objects 
(representation) 
c) Communication and collaboration with other people (collaboration) 
d) Interface and interactions (manipulation, edit, creation, output) 
e) Intention to use the proposed workflow in a real-world scenario 
f) Economical aspects 
 
The questions presented some similarities to Horvat et al.’s (2022) classification 
scheme. In their work, the authors identify eight classes to analyze when exploring 
the potential of immersive VR. applications developed for Design Reviews: input, 
representation, navigation, manipulation, collaboration, edit, creation, and output. 
 
Table 10 Class Category Description According to Horvat et al. (2022) 
Class category 
Description 
Input 
Importing the content and information to be reviewed 
Representation 
Designing content that is available to users within the virtual 
environment 
Navigation 
Changing the viewpoint within the virtual environment 
Manipulation 
Temporary editing of the environment for better view or 
analysis purposes 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
166 
Collaboration 
Conducting Design Reviews collaboratively, either 
synchronously or asynchronously 
Edit 
Creating or changing the digital content under review 
Creation 
Creating a review content 
Output 
Exporting the review content and reviewed design 
 
Horvat et al. (2022) propose a systematic and rigid classification to code categories 
(a total of eight), class subcategories (a total of 22), and classes (a total of 55); 
however, the set of questions designed for this study were more general and flexible. 
The questions prompted participants to begin an open discussion. Nevertheless, the 
questions asked during the post-study group were aligned to those eight main 
categories from Horvat et al. (2022) and are crucial when evaluating immersive VR 
Design Reviews software, such as Gravity Sketch. 
 
Table 11 Questionnaire Questions in relation to Horvat et al. 
# 
Question 
(Post-study group discussion) 
Category 
(according to Horvat et al., 
2022) 
1 
How was your overall experience of the 
workflow? 
/ 
2 
How was the experience of being immersed in 
the location where you are going to shoot? 
Navigation, representation 
3 
How did you find communicating your ideas 
with the other participants in the virtual 
environment? 
Collaboration 
4 
How did you find collaborating at the same 
time with other participants in the same virtual 
environment? 
Collaboration 
5 
How did you find interacting with the interface 
proposed? 
Input, manipulation, edit, 
creation, output 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
167 
6 
What did you find most difficult when 
interacting with the interface? 
Input, manipulation, edit, 
creation, output 
7 
Would you use this exact workflow presented 
in a real-world scenario? Why or why not? 
/ 
8 
What would stop you from using this 
workflow? 
/ 
9 
Do you think this workflow may be helpful in 
saving time and therefore money? How? 
/ 
10 
Was there anything you wanted to do while 
planning your production that you were unable 
to do? 
Input, manipulation, edit, 
creation, output 
11 
How did the proposed virtual pre-production 
workflow compare to traditional pre-
production? 
/ 
 
In addition to the questions in Table 11, participants expressed their thoughts and 
feedback on relevant aspects. 
 
At the end of the group discussion, participants were provided with a brief 
questionnaire; this reviewed Q12 and Q13 of DS-III's online questionnaire and asked 
whether the results obtained from judging the design fiction scenario were different 
from those obtained after testing a real prototype such as the one proposed in this 
DS-IV phase. Finally, participants were thanked for their contribution.  
 
Table 12 Questionnaire From the End of the User Testing Session 
Perceived Usefulness 
Compared with the current pre-production workflow you are experiencing in the AV 
industry, the proposed pre-production workflow... 
 
Strongly 
Disagree 
Disagree Neutral Agree 
Strongly 
Agree 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
168 
...may facilitate communication 
with other collaborators. 
 
 
 
 
 
...may lead to explore more 
creative opportunities. 
 
 
 
 
 
...may be more helpful in the 
decision-making process. 
 
 
 
 
 
...may be more helpful when 
pitching ideas and seeking 
funding. 
 
 
 
 
 
...may reduce filmmakers' 
ecological footprint (travelling, 
energy consumption, etc.). 
 
 
 
 
 
...may improve filmmakers' well-
being (mental health, safety, 
inclusivity, equity, etc.). 
 
 
 
 
 
Perceived Ease of Use 
…may be easy for me to learn. 
 
 
 
 
 
…would be easy for me to 
become skilful at adopting. 
 
 
 
 
 
would be clear and 
understandable for me to use. 
 
 
 
 
 
 
 
The complete study procedure can be viewed in Appendix III. 
 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
169 
7.5.2 Results and Discussion (DS-IV) 
Only two of the 29 participants felt discomfort while experiencing VR. Nevertheless, 
they were able to complete the whole procedure. 
None of the participants expressed a total lack of knowledge towards VR and AR, 
and their degree of familiarity with these technologies varied. 
Audio files recorded were transcribed using Trint, and video files were watched to 
observe participants’ behaviours. Quantitative data were evaluated by adopting the 
adaptation of the TAM framework previously used in DS-III.  Qualitative data were 
evaluated using an adaptation of the evaluation framework proposed by Horvat et al. 
(2022). 
 
7.5.2.1 Questionnaire Results 
Q12.2, Q12.3, and Q12.4 all received positive feedback, meaning that participants 
agreed with the proposed statements after experiencing the real prototype. 
 
 
Q12 
Compared with the current pre-
production workflow in the AV 
sector in which you most frequently 
work... 
Design fiction 
scenario – 
DEPERO 
(questionnaire) 
Real prototype 
Polycam + Gravity 
Sketch 
(user testing) 
 
 
Average score 
Average score 
Q12.1 ...may facilitate communication with 
other collaborators. 
4.16 
3.38 
Q12.2 ...may lead to explore more 
creative opportunities. 
4 
3.93 
Q12.3 ...may be more helpful in the 
decision-making process. 
4.13 
3.93 
Q12.4 ...may be more helpful when 
pitching ideas and seeking funding. 
3.93 
3.76 
Q12.5 ...may reduce filmmakers' 
ecological footprint (travelling, 
energy consumption, etc.). 
4.33 
3.9 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
170 
Q12.6 ...may improve filmmakers' well-
being (mental health, safety, 
inclusivity, equity, etc.). 
3.36 
2.85 
Table 13 Results Comparison: Usefulness 
The scores are not as positive as those obtained in the online questionnaire and 
when judging the design fiction scenario. However, the degree of consistency seen 
in the results of these three questions indicates that the responses still show 
agreement.  
The outcome of Q12.6 was the lowest score (2.85 = neutral) among all the 
questions. This result may have two explanations. First, filmmakers fear the 
replacement of phases where people meet and interact in person, and location 
scouting or recce is one of those moments. As PT10 stated: 
‘It would be opportune that the workflow proposed would be an addition and not a 
total replacement of the current one we have today…even if I think that in the 
future this totally virtual workflow will be the new norm’ PT10, executive producer.   
The second reason could be that participants were returning to former work patterns 
after 2 years of confinement, where they had been forced to interact virtually with 
others both personally and professionally. This feeling was expressed by PW09 
when noting how, when possible, scouting locations physicallyis preferred ‘especially 
after this period [COVID-19 pandemic]’. 
The score obtained for Q12.6 may therefore represent participants' caution towards 
spending additional and extensive time in VR in this historic period. 
 
 
Q13 
Compared with the current pre-
production workflow in the AV 
sector in which you most frequently 
work... 
Design fiction 
scenario – 
DEPERO 
(questionnaire) 
Real prototype 
Polycam + Gravity 
Sketch 
(user testing) 
 
 
Average score 
Average score 
Q13.1 …learning to use DEPERO may be 
easy for me. 
3.56 
3.58 
Q13.2 …I may be interested in testing 
DEPERO firsthand. 
4.26 
/ 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
171 
Q13.4 …it would be easy for me to 
become skilful at adopting the 
proposed workflow. 
/ 
3.83 
Q13.5 …my interaction with the proposed 
workflow would be clear and 
understandable. 
/ 
3.58 
Table 14 Results Comparison: Ease of Use 
For perceived ease of use (Q13), it is possible to observe that the results obtained 
after the user testing session are slightly more positive than those obtained in the 
online questionnaire. When participants were asked to judge the perceived ease of 
use of the description of the diegetic prototype, they answered with prudence, not 
knowing how that workflow would actually be experienced in practice (‘I’d have to try 
before expressing myself’ PQ10, post-production department). However, when 
participants completed the user testing session, they may have felt more secure 
about expressing positive feedback. Overall, they seemed confident about ultimately 
improving their skill and proficiency in using the proposed workflow. 
This consideration is further supported by the facilitator’s observations during the 
user testing session. Several participants initially encountered trouble in interacting 
with the design support. However, most eventually understood the functionalities and 
features when they were explained; a few achieved this independently. 
 
7.5.2.2 Think-Aloud and Group Discussions 
As expected, the strategy of involving professionals accustomed to working together 
and designing a procedure where multiple participants were asked to simultaneously 
experience and evaluate the prototype called for an open and transparent discussion 
without embarrassment or shyness. The activities designed for the procedure and 
the questions asked by the facilitator prompted participants to start discussions with 
one another, exchanging ideas and perspectives. Sometimes they agreed on a 
specific matter. Other times their opinions diverged, but in doing so, the study was 
enriched with valuable data that lent the researcher a more comprehensive and in-
depth understanding of the subject. 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
172 
Usefulness 
After receiving this brief training, some participants recognised that this process 
would allow them to send other collaborators on location (‘A very simple process, 
very doable that allows me to say to my assistant producer, I cannot go on location 
[to perform the capturing], you go’ PT18, producer). They also believed that taking a 
digital capture of the location would be useful to ‘show other heads of departments’ 
who could not attend the recce, especially in international productions, as stated by 
PT24 and PT25 (producers). They further described that their trusted 
cinematographer occasionally was not able to visit and assess the location in 
advance, forcing them to ‘always rent and employ the same lighting equipment’, 
therefore limiting their creativity in illuminating the scene. 
During the demonstration phase of Location 01, participants were presented with the 
outdoor area near La Casa Gassia through a capture extracted from Google Maps 
(2022) and imported into Gravity Sketch (Figure 7.12). On that occasion, PT10 
reiterated the importance of the space surrounding the filming location (adjacent 
rooms and spaces, both interiors and exteriors). This opinion was further supported 
by PT16, PT17, and PT18, who stated that ‘if we think that this is our filming location, 
I would definitely go and capture every space that is accessible to get a 
comprehensive idea’. 
 
 
Figure 7.12 Capture Extracted From Google Maps 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
173 
PT24 and PT25 explained that set designers usually work and plan the scenography 
on rough sketches of the space. They believed that ‘having the actual spaces, 
having this [digital replica of the space] and sending it to set designers would show 
them very easily [the space, thus] facilitating working on the scenography, [as] 
sometimes there are spaces that are quite specific’. PT04 (producer) and PT12 
(director) also recognized the benefits for a set designer. 
 
Figure 7.13 Set Design Notes Drawn by Sketching Red Circles Around Props 
PT04, PT10, and PT24 claimed that capturing existing locations (both interiors and 
exteriors) should be a natural step for any location agency (that may be called 
different names, such as regional film office, film commission, or film institution) that 
assists AV production companies in seeking appropriate locations for their projects. 
The researcher explained to Group 8 that Polycam was also capable of capturing 
objects and creating a 3D digital asset, which caused them to recall a past client’s 
request to transport heavy and bulky furniture to a remote location. They wondered if 
this technology and process could have solved that problem and so secured that 
project and budget. 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
174 
 
Figure 7.14 User-Generated Capture of a Sofa using Polycam 
 
 
Ease of Use 
While using Polycam, most participants found the room scanning process to be 
simple and intuitive; they also liked the opportunity to learn the dimensions of that 
space. The speed at which they could generate a 3D image was unexpected and 
received positive feedback, and some claimed that this factor contributed to 
accepting some trade-offs in visual output. Participants were told that Polycam 
provides best practices (Polycam Learn, 2022) for scanning the space, and they 
recognized that dedicating time and effort to learning these best practices could 
improve the quality of their captures.  
 
Similarly, at the end of the VR activities with Gravity Sketch, there was a consensus 
that participants could become more proficient after spending time in the application.  
Finally, it is important to mention that participants were informed that the researcher 
imported the 3D assets they experienced in Gravity Sketch before the user testing 
session because of the researcher’s limited time and because the researcher 
thought the procedure was overly complicated. However, participants’ feedback on 
the prototype’s ease of use could have been different if they had personally executed 
the necessary steps to set up the virtual environment. Facilitation by the researcher 
represent a limitation of the study and in future iterations of the prototype, it is 
imperative to assess its ease of use more objectively. 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
175 
Representation 
While assessing the 3D capture that they generated, PT04, PT05, and PT08 agreed 
that the visual output was sufficient if the purpose was to have an overall 
understanding of the location. In few cases, the captures that users generated were 
not aligned with their expectations of visual output.  
PT10 expressed that to better assess the location scanned, it would have been 
necessary to examine 2D pictures of the location. This feedback was expected, and 
in the following VR activity, participants were also provided with some real photos of 
the location, as shown in Figure 7.15.  
 
Figure 7.15 Real Photos of Location 02 Imported Into the Virtual Scene 
A concern was expressed about the file size of captures generated using Polycam. 
The facilitator informed the participant that the average size of the .obj file was a few 
megabytes, and he felt reassured. 
When assessing the result of the capture, PT01 and PT20 expressed that it could be 
useful if Polycam would also provide some information on the degree of accuracy of 
specific areas while capturing (such as, ‘Wait! You didn’t accurately scan this area’). 
These users ideated that after processing, a heat map could highlight parts of the 
scanned object or environment that had some imprecisions. 
During the session, Group 5 shared an anecdote regarding how they had already 
employed Polycam in a previous project. They used Polycam to generate a 3D 
capture of a location that was later inserted in a 2D scene, creating contents that 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
176 
were functional for their 2D production rather than using the tool to facilitate their 
production process. 
Gravity Sketch allows users to experience a 3D replica of a scaled model (e.g., 
1:50), which is similar to architects’ physical architectural models that are made of 
cardboard. Experiencing a scaled model in VR or MR may cause artefacts and 
imperfections in the captures to be less evident, although users can easily perceive 
the overall location as more credible and accurate in its representation. As PT12 
(director) stated, ‘It seems [to be] a super accurate mode’. 
 
 
Figure 7.16 Location 01: La Casa Gassia at 1:1 (left) and 1:50 (right) Scales 
Navigation 
When participants wanted to explore remote areas of the virtual environment, they 
could not physically reach the spot because the real environment in which the user 
testing session was held was smaller than the virtual environment. This constraint is 
common for most VR applications. To overcome such limitations, VR designers 
usually propose alternative ways to enable this navigation, such as teleportation, 
joystick-based navigation, or redirected walking (Langbehn, Lubos, & Steinicke, 
2018). Participants were instructed on using the teleportation tool in Gravity Sketch. 
Some participants could not easily teleport themselves around the virtual 
environment but managed to move within the virtual space after trial and error. The 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
177 
common tendency was to walk physically within the spatial limits of the room where 
the user testing session was occurring.  
When experiencing Location 03 and activating the Passthrough feature, participants 
were surprised, and those who felt some degree of motion sickness now felt more 
comfortable than when they experienced VR. Since they could see each other’s 
bodies and their respective avatar simultaneously, they noticed a discrepancy in their 
positions. To improve this viewing mode, defined by PT10 as ‘familiar’, the virtual 
avatar visualization should be removed when MR mode is activated. Moreover, 
some participants noticed that the Passthrough visualization was black and white 
and expressed that a fully coloured viewing was preferred. A few months after this 
user testing study occurred, Meta released a new headset named Meta Quest Pro, 
which provides a full-colour Passthrough function.   
 
Collaboration 
Many times participants put themselves in the shoes of other professional figures, 
expressing their opinions on how other personnel would feel when using such tools. 
It seemed to be a natural behaviour that may be due to the profound 
interconnections between these professionals. In some cases, the facilitator had to 
repeat questions and specify that the study purpose was to collect participants’ 
feedback on what they experienced.  
As a result of this strict collaboration among AV professionals, some participants, 
such as PT11 (executive producer), were hesitant to complete the questionnaire 
because of a conflict between their intention to use the proposed workflow and their 
expectation that collaborators may experience difficulty in using it. PT22 also made 
this remark, which can be traced to the DS-III findings, where the usefulness of the 
proposed workflow depends on the number of collaborators adopting the same 
workflow (‘network effect’). PT07 (producer) noted that if the proposed workflow were 
to be adopted and bring value to the AV production, then: 
‘it has to be used by as many collaborators as possible…and to facilitate other 
people in using it, it has to be simple, very intuitive. The moment I open it [Gravity 
Sketch], I should know how to use it. When this will happen, [it] will be a game 
changer’ PT07, producer. 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
178 
 
Figure 7.17 Three Participants in the Virtual Environment Simultaneously 
PT10 explained that it would be useful to see other collaborators' perspectives when 
they are trying to communicate. This feature was not available at the time of testing. 
However, after further research into this matter, it was discovered that Gravity 
Sketch later implemented this function as a beta feature, calling it VR perspective: 
‘You can follow any VR users in the room by clicking the Pin icon under the people 
menu; this will pin their view to your screen and you will see exactly what they are 
seeing’ (Humphreys, 2022). 
 
Interface and Interactions 
After wearing the VR headset and holding the controllers, participants – perhaps 
prompted by curiosity – tended to freely explore the different interactions possible 
within Gravity Sketch, although they were not instructed to do so. Sometimes it was 
necessary to redirect participants’ attention. In a few cases, the facilitator needed to 
correct participants' mistakes, such as recovering objects they accidentally deleted 
or settings they unintentionally changed.  
Unexpectedly, some participants preferred a scenario in which they could work on 
the same production in an immersive and 2D manner. PT01 suggested that because 
filmmakers may find it more intuitive to work on 2D screens, they might also prefer to 
edit the scene and manipulate objects within the virtual environment using 
established inputs, such as a mouse and keyboard. 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
179 
Similarly, other groups suggested that one of their collaborators who was proficient 
with such a workflow could mirror the reviewing process on a 2D screen. 
Therefore, it is important to clarify that some participants preferred a 2D viewing and 
experience of the virtual environment but wanted to take advantage of the 
possibilities in the real-time rendering aspect of the workflow.  
 
Economical Aspect 
PT05 was surprised that such hardware and software technologies are already on 
the market and ready to be used. PT16 was surprised by the current price of a VR 
headset such as Meta Quest 2, which was perceived as much more expensive. 
While evaluating the capture output of the room generated using the iPadPro and 
Polycam, PT26 (post-production supervisor) said, ‘I think you would end up with 
something that you could definitely use, especially for free’ (PT26, VFX artist). 
Overall, the price required to adopt the proposed workflow, which can increase 
depending on the number of collaborators whom a production team wants to enable 
(equipping more people would require more VR headsets), was considered 
affordable and did not represent a ‘dealbreaker’ for its adoption. Participants agreed 
that deciding to spend money on the equipment needed to enable such a VP 
process would require further discussion within the team.  
 
Intention to Use 
When discussing the intention to use the proposed alternative workflow, it was clear 
that those in different roles may be more interested than others in integrating the 
workflow. Many participants believed that creative figures, such as set designers, 
directors, and cinematographers, would benefit from spending time learning how to 
use this immersive VP process, which would therefore enhance their work. Others, 
such as producers, were uncertain whether introducing this workflow would simplify 
their daily tasks and bring some benefits or whether it would complicate the whole 
process. Nevertheless, other figures involved in the post-production phase, such as 
editors or VFX supervisors, expressed a neutral opinion since they are usually not 
involved in the pre-production process. 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
180 
AV professionals working in the advertising sector agreed that the workflow should 
be used internally by the team and not extended to their clients while presenting their 
creative ideas or plans on the production's organization. This consideration was 
made because of the constraints and limitations regarding representation and ease 
of use. The risk foreseen by participants was that it could create more 
misunderstandings than explanations in the eyes of their clients, who, in their 
opinion, already struggle to comprehend even the basic principles of the established 
AV process.  
Overall, participants expressed interest in experimenting with the alternative 
workflow in a real-world scenario to enable a more thorough evaluation.   
 
 
7.6 Sub-Prototype: Drone Digital Twin 
During the remote co-design workshops, PW02 (cinematographer) first conceived 
the idea of planning the drone's flight path. This concept could support directors, 
cinematographers, and drone operators involved in capturing complex drone 
movements. Since the rest of the group positively evaluated such an idea, it was 
considered worthy of further exploration of its technical feasibility. 
 
Recently, drone cinematography has become increasingly affordable for AV 
productions (Mademlis et al., 2018), and some researchers have explored how 
drone cinematography can be pre-planned (Angelopoulos et. al., 2022) and 
automated (Liu & Shen, 2020) using immersive technologies. 
Zhang et al. (2020) previously investigated drone cinematography in a virtual 
environment. To do so, they captured the area where they wanted to simulate the 
drone's flight path, or they used pre-existing 3D environments (similar to the 
description in Section 7.4.2.3) based on Google Earth's source data. They imported 
such 3D environments in Unreal Engine 4 and then virtually simulated the drone's 
flight path. They conclude that future work should be focussed on experimenting with 
(a) how the workflow can integrate and employ VR devices and (b) how the data 
generated in the simulation can be added to autopilot software for autonomous 
drone operation. If data generated in the immersive environment could be 
transferred successfully into autopiloting software, then this workflow could generate 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
181 
a DT of the drone's flight path, thus opening new possibilities for cinematographers, 
as suggested by PW02. 
 
7.6.1 Definition of Digital Twins 
DTs were first formally introduced by Michael Grieves in 2003 at the University of 
Michigan (Grieves, 2014) and, more specifically, for the manufacturing process. 
However, the concept of DTs had been familiar to NASA since the 1970s (Barricelli, 
Casiraghi, & Fogli, 2019). At its Space Center in Houston, Texas, NASA had 
‘mirrored systems’ of spacecraft that had been sent to space. The most famous 
example is Apollo 13: through this mirrored system, engineers on earth instructed 
astronauts on board the spacecraft to solve a critical issue they encountered. 
The scientific definition of DTs has not yet been determined (Negri, Fumagalli, & 
Macchi, 2017); therefore, it is still a topic of debate. In this regard, Barricelli, 
Casiraghi, and Fogli's (2019) survey is helpful in outlining the current definition, 
characteristics, and applications of DTs. After analyzing 75 papers, they state, ‘DTs 
can be defined as (physical and/or virtual) machines or computer-based models that 
are simulating, emulating, mirroring, or ‘twinning’ the life of a physical entity, which 
may be an object, a process, a human, or a human-related feature’. This 
comprehensive definition encompasses the various definitions from the current 
literature. Notably, they mention the word process, which is the same term used in 
Section 2.1.1 to describe VP. Therefore, it is necessary to further investigate the 
relationship between the two. 
Based on their review, a crucial requirement for all DTs is having a seamless 
connection and continuous data exchange between the physical and virtual twins. 
Through this exchange, the virtual twin is constantly aware of what is occurring in the 
actual world to its physical counterpart. This awareness is possible through sensors, 
which can be many and specific, installed on the physical object, system, or human 
and are capable of collecting data. Therefore, DTs are related to another emerging 
technology: the Internet of Things (IoT). DTs can also be combined with AI to predict 
future failures of the physical twin, leading to so-called ‘predictive maintenance’. 
According to Barricelli, Casiraghi, and Fogli (2019), DTs have been employed mainly 
in manufacturing, medicine, aviation, and hospital management. However, in the last 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
182 
chapter of their study, they explain that many other applications of DTs may be 
viable in other sectors. Hence, the reason and opportunity for applying the DT 
concept to the AV field with this additional experiment is to expand the current 
literature on this emerging field. 
 
Considering the user testing session, specifically Location 03 (planning a drone shot 
of Mont-Saint-Michel), the first direction from Zhang et al. (2020) was completed 
successfully. Zhang et al.'s (2020) next step is testing the feasibility of translating the 
data generated in VR (the hand-drawn drone flight path) to instructions that would be 
entered into drone autopilot software. Figure 7.18 compares the contribution that the 
researcher aimed to generate as the output of this work to Zhang et al.'s goal. 
 
Figure 7.18 Relationship Between Zhang et al. (2020) and This Work 
 
It was necessary to clearly understand which file formats could be exported from 
Gravity Sketch and would be compatible with autopilot software. 
 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
183 
7.6.2 Experiment Design 
Landing Pad (2022), the cloud-based solution to access, upload, and download 
Gravity Sketch projects (version 5.5.55) allows users to export the following formats: 
.fbx, .iges, .obj, .gltf, .usdz, and .mp4. 
Among these, the .obj format is thought to be the most promising when opening the 
file with a generic text editor. Reading how the data were stored and organized, the 
researcher noticed that this format preserved the absolute values of the vertexes of 
the flight path drawn in VR, as shown in Figure 7.19. 
 
Figure 7.19 Gravity Sketch .obj File, Opened With a Text Editor 
It became conceptually clear that the absolute values of the XY axis needed to be 
converted into GPS coordinates (latitude, longitude), and the absolute values of the 
Z axis needed to be converted to altitude.  
Even if the conversion can be done automatically, it is still necessary to manually set 
a reference point or value that could be interpreted identically in both the starting 
format (.obj) and ending format (.klm). 
The .klm format (keyhole markup language) was chosen as the ending format 
because it is supported by Litchi (2022), the autopilot software that was employed in 
the study. Additionally, this software is compatible with the DJI Mini 2 drone that was 
used for the test and is widely used by filmmakers when trying to accomplish drone 
shots.  
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
184 
 
Figure 7.20 File in .kml Format to Import in Litchi, Opened With a Text Editor 
The researcher initially planned to employ a DJI Mavic 3 (DJI, 2022a) from the start 
to the end of the process, but while testing, it was discovered that compatibility 
between this drone and Litchi was not possible. Therefore, the new strategy 
consisted of using the DJI Mavic 3 to capture the initial dataset of images because it 
was capable of capturing higher quality images than the DJI Mini 2 (DJI, 2022b). 
Then, the DJI Mini 2 was employed during the shooting phase because of its 
compatibility with Litchi.  
 
7.6.3 Results 
The drone was flown around the Brunel University campus, and its subject was the 
iconic lecture centre, a location chosen by Kubrick more than 50 years ago for A 
Clockwork Orange (Kubrick, 1971). 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
185 
 
Figure 7.21 Scene From A Clockwork Orange (1971) Set Outside the Lecture Centre 
It took approximately 10 minutes to fly around the chosen building and 15 minutes to 
upload and process the images on Polycam (89 images in the .jpg format taken from 
different perspectives). 
 
 
Figure 7.22 Images From the Dataset Collected Using the DJI Mavic 3 
Polycam allows users to process the dataset on a different level of detail (LOD), 
which is a common term in CGs, especially video games, to describe the different 
levels of complexity attributed to 3D geometric figures. Setting the output detail to 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
186 
‘raw’ created a 3D mesh of 921,599 polygons (or faces), which needed to be 
reduced to be experienced smoothly in Gravity Sketch.  
 
The same was valid for the two textures generated (8192 x 8192 pixels) each, which 
were merged into one with image manipulation software, such as Adobe Photoshop 
(2022). Setting the output detail to ‘full’ on Polycam created a 3D mesh of 184,450 
polygons and one texture of 8192 x 8192 pixels. This export setting from Polycam 
was considered the best option since it did not require extra time for post-processing 
and could be directly imported into Gravity Sketch.  
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
187 
 
Figure 7.23 Movie Scene (top) and 3D Model Generated (bottom) 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
188 
 
Figure 7.24 Different Levels of Detail Using Polycam and Blender 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
189 
Once the .obj file that was exported from Polycam was imported in Gravity Sketch, it 
was possible to plan the drone's flight path and draw the preferred itinerary.  
First, a reference object was created to place inside the scene. The shape of a cube 
was considered the most appropriate since it could be framed in front of the lecture 
centre, which presents a 90° angle. 
Next, a freehand red stroke representing the drone's flight path was drawn. 
Figure 7.25 portrays how the level related to the 3D model of the lecture centre is 
made invisible so that only the cube and the red stroke are exported. 
 
 
Figure 7.25 Steps Performed Using Gravity Sketch 
 
After saving the sketch on the cloud (Landing Pad), the same sketch that was 
exported as a .obj file was converted into a .3ds format using a free online format 
converter platform, such as ASPOSE, so that it could be imported into SketchUp. 
From here, the 3D mesh of the stroke and cube were assigned geospatial metadata 
information through one of SketchUp's features, Add Location. 
Then the cube was appropriately scaled and positioned to frame in front of the 
building once again, as shown in Figure 7.26. This step introduced approximation 
due to the manual intervention of positioning the cube in the reference position. 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
190 
 
Figure 7.26 Steps Performed in SketchUp 
A .kmz file was exported from SketchUp and imported into Google Earth. 
Because of the metadata associated with the 3D model while using SketchUp, the 
model, once imported into Google Earth, was placed directly in the correct position, 
as shown in Figure 7.27. 
From here, it was possible to use the Add Path feature in Google Earth to manually 
draw key point after key point over the stroke that was initially made in Gravity 
Sketch. This process of manually replicating the stroke introduced a degree of 
approximation, which made it impossible to set the elevation (Z axis) of the single 
key point, so this 3D aspect of the flight was lost.  
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
191 
 
Figure 7.27 Steps Performed in Google Earth 
 
After that, it was possible to export the flight path as a .kml file, which can be 
imported into the Litchi cloud platform.  
Using the Litchi application on the iPad (Figure 7.28), it was possible to synchronize 
the cloud with the application and set additional commands, such as drone altitude 
(Z axis) for each key point and camera orientation. Once the preferred settings were 
chosen, it was possible to let the drone fly autonomously through the flight path that 
was initially planned in VR. 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
192 
 
 
 
Figure 7.28 Steps Performed in Litchi (Cloud and Mobile Application) 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
193 
 
7.6.4 Discussion 
Overall, the initial process of capturing the exterior location (photogrammetry) and 
planning the flight path using an immersive device (Meta Quest 2) and software 
(Gravity Sketch) was smooth and feasible. 
 
The location capture generated a highly detailed and overall satisfactory 3D asset of 
the location. Nevertheless, some areas of the building presented some artefacts and 
inaccuracies. Thin objects were not correctly captured, as can be seen in Figure 
7.29, where the handrail of the external stairs is poorly represented. In this regard, it 
is crucial to note the risk of flying a route where there are light poles or other thin 
objects that were not previously detected by the capture. 
Similarly, if the intended flight path is in a building or area that is subject to changes 
over time (e.g., tree branches, new structures and buildings, etc.), it is recommended 
to pre-plan the flight from a recent capture. An additional risk may occur if the drone 
is flying autonomously through the pre-planned route and encounters wild animals 
(birds) flying in the same area. If the drone is not instructed by proximity sensors to 
avoid crashing into unexpected obstacles, then this could represent a danger.  
 
 
Figure 7.29 Capture Artefacts: Tree Branches and Leaves (left), Handrails (right) 
Testing also proved that weather conditions might affect the quality of the capture. It 
is not recommended to capture when sunlight is casting a strong shadow on the 
ground since it creates an abrupt transition between highlights and shadows in the 
picture (known in photography as hard light). These sudden lighting changes 
between different faces of the building were not well elaborated by Polycam when 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
194 
processing the uploaded pictures. Consequently, it is advised to capture data during 
overcast weather when sunlight is filtered and softened by clouds (known in 
photography as soft light). 
 
The immersive planning of the drone's flight path was technically feasible; however, 
translating data that originated in Gravity Sketch was not. As shown in Figure 7.30, 
two steps of the proposed workflow required manual intervention: altering original 
data due to approximation while (a) repositioning the reference object in SketchUp 
and (b) redrawing the flight path in Google Earth.  
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
195 
 
Figure 7.30 Proposed Workflow for Immersive Planning and Drone Automation 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
196 
A limitation of Google Earth’s Path feature is that it only allows users to set points 
that are linked, thus creating a polygonal chain that cannot be curvy. Recreating the 
curved trajectory drawn in Gravity Sketch is not possible inside Google Earth, but it 
can be redrawn manually inside the Litchi application. Similarly, to set the altitude of 
each point, it is necessary to insert values inside the .klm file or from within the Litchi 
application. 
 
Manually repositioning the reference cube in SketchUp and redrawing the flight path 
in Google Earth introduced a degree of inaccuracy. A conservative estimation of this 
error in the 3D space is between 50 and 150 centimetres on all axes. This 
inaccuracy is directly related to the time and effort spent by the user while executing 
these manual tasks. 
 
These discoveries reinforce Zhang et al.'s (2020) conclusions: finding a way to 
convert formats generated in immersive environments that are compatible with 
autonomous drone piloting software is still needed. Nonetheless, the proposed 
workflow may be an alternative aid to cinematographers and drone operators when 
planning a drone's flight path. While experiencing Location 03 during the user testing 
sessions in DS-IV, participants expressed positive feedback about the usefulness of 
such an approach when planning a drone shot.  
What has yet to be investigated by future scholars is the proposed alternative 
workflow that is summarized in Figure 7.30, as evaluated in practice by drone 
operators and cinematographers.  
 
In this work, the researcher attempted to accurately convert a .obj file to a .kml file. 
However, it is essential to be aware of how the starting and ending formats can be 
replaced. The steps explained herein might be subject to change if software is 
discontinued or updates no longer support specific formats. What is most important 
in the context of this study – the core goal – is discovering how to link geometrical 
information located in the Euclidean space to GPS.  
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
197 
Nevertheless, describing and visually illustrating the workflow ideated and followed 
to achieve the result shown was considered helpful for a better understanding of the 
original concept. 
 
 
 
7. PROTOTYPE DESIGN  (PS-IV) AND TESTING (DS-IV) 
 
 
 
198 
7.7 Chapter Summary 
This chapter described the outcome of collaborative in-person testing and evaluation 
of the practical prototype, which was developed in PS-IV, by 11 groups with a total of 
29 AV professionals. The prototype consists in a workflow made possible by the 
combination of already existing hardware and software solutions (Meta Quest 2, 
iPad, Polycam, Gravity Sketch).  The main benefit brought by this workflow is to 
immerse  filmmakers into a virtual replica of the shooting location and facilitate 
several pre-production activities. Details on the prototype and its functionalities are 
reported in Appendix III. The rich amount of qualitative data collected during the 
testing session, and later analyzed, contributed to the answer for RQ1.3 and to 
recommendations for implementing the prototype within SMPs and, ergo, its 
evaluation in real-world scenarios. These recommendations are described in 
Chapter 8. 
Furthermore, the specific concept ideated by one of the PS-II participants regarding 
the immersive pre-planning of a drone's flight path was empirically tested and further 
extended the work of previous researchers on the topic. In this regard, an alternative 
workflow is proposed when planning a drone camera shot. 
 
 
 
 
 
 
 
 
 
 
 
 
199 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Chapter 8 
 
DISCUSSION
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
200 
8. Discussion and Recommendations 
 
This chapter presents the outcome of the research process and the output generated 
from each study. Additionally, recommendations are provided for investigating 
emerging areas and designing other VP processes that can be applied to SMPs. 
 
 
8.1 Research Output 
 
8.1.1 General Discussion 
The Importance of Virtual Production Among Small and Medium Productions 
Many VP processes have been developed by industry players and described in 
detail in the literature. However, few were developed while considering the significant 
number of SMPs that are also part of the AV industry. However, the designs 
described in these studies were ideated autonomously by the same researchers 
without systematically involving the AV professionals from the beginning of the 
design process.  
The in-depth interviews conducted during the exploratory study (Chapter 4) provided 
additional supporting evidence that an alternative VP process was desired by SMP 
practitioners while also revealing initial user requirements. The curiosity and interest 
in alternative, affordable, and easy-to-adopt VP processes were present among 
participants. The possibility of experiencing the VP process, similar to their 
counterparts working in high-end productions, was welcomed with enthusiasm.  
 
 
Filling the Gap 
The alternative VP process with its emphasis on pre-production was presented in 
PS-IV (Section 7.4) and tested by professionals in DS-IV (Section 7.5); the design 
fiction scenarios were developed in PS-III (Section 5.7), and the initial concepts were 
collected from DS-IIB. Each represents practical contributions to the VP field, as 
shown in Figure 8.2 and briefly described in Figure 8.3. 
 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
201 
 
Figure 8.1 Illustration of the Practical Output Generated Throughout the Research 
Additionally, this chapter explains that the insights collected throughout the research 
contributed to generating a new conceptual framework for developing VP processes 
for AV professionals throughout SMPs, as explained in the next section. 
While filling the gap in the literature, the findings in this PhD work also led to further 
considerations of how the research output produced from this investigation may be 
adapted to other fields and uses.  
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
202 
 
Figure 8.2 Brief Description of Each Output Generated Throughout the Research 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
203 
8.1.2 Discussion on the Final Practical Output 
In DS-IV, a specific process was designed and tested by employing pre-existing 
hardware devices and software services. It should be noted that more advanced 
products may replace these proprietary products in the future because the rapid 
pace of technology, especially immersive technologies, is evolving. However, the 
core functionalities and uses are likely to remain the same for years. The capturing 
software Polycam may be replaced by other applications capable of generating a 
better output quality. More lightweight and ergonomic headsets will substitute VR 
headsets such as the Meta Quest 2.  
In this regard, Blessing and Chakrabarti (2009, p. 34) explain that PhD researchers 
often spend time defining the specific features of the design support developed. 
However, ‘the core research contribution often lies in this concept. The aim of a 
research project is rarely to develop a commercially viable support’. 
 
In agreement with Blessing and Chakrabarti, the findings generated from this 
research suggest recommendations for a real-world implementation of the design 
support that was co-created throughout the iterative phases of the research.  
 
Ease of Use Is Key 
The findings reveal how much attention was bestowed upon the ease of use of the 
final design support. Throughout the research, especially after the evaluation phase 
in DS-IV, participants shared excitement and surprise towards the technologies 
presented as well as caution when discussing the integration of the proposed 
alternative workflow in their workplace. Research participants wondered whether the 
trade-off in time and effort to learn how to operate with new tools would prove to be 
convenient or if it would unnecessarily complicate issues.  
 
Because of the intrinsically collaborative nature of filmmaking, many participants 
initially expressed that everyone should be proficient and skilled while operating the 
proposed VP process. However, after discussing this matter, participants agreed that 
some AV personnel might benefit from simply wearing a VR headset and being 
immersed in the virtual location without interacting with controllers or taking 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
204 
advantage of the virtual tool set (drawing tool, virtual camera, importing assets, 
lighting, etc.). Additionally, these lesser technologically proficient professionals can 
be guided by more skilled collaborators participating in virtual meetings, which is 
similar to the user testing session where the researcher or facilitator was sufficiently 
skilled to guide the group and respond to most of their requests (e.g., ‘Is it possible 
to resize this element? Is it possible to take notes? It is possible to create a copy of 
this element?’).  
Providing the necessary tools and instructions for users to autonomously adopt the 
VP process in a real-world scenario and later asking for feedback on their 
experience could cast further light on this matter. 
 
Role-Specific Interfaces and Tools 
Established editing software commonly used by AV professionals, such as Adobe 
Premiere (2022), offers the possibility to have pre-existing UIs, depending on the 
intended task (e.g., editing, colour corrections, effects, audio, review, etc.). Further, 
they also allow users to customize their unique interfaces according to their 
preferences and needs. 
It is therefore argued that designing different VR UIs specific to each role (director, 
cinematographer, producer, etc.), may contribute to a better UX overall. AV 
professionals, while accessing the VR pre-production application, could select their 
role-specific interface and visualize only those tools appropriate for accomplishing 
their role-specific tasks. Consequently, this would lead to a higher degree of usability 
for end users. Because of convenience, it was decided to rely on Gravity Sketch, 
whose UI and UX were designed with product designers in mind, not filmmakers.  
 
Consistency of Interactions Across Immersive Applications Is Yet to Be Defined 
Testing the alternative VP process in DS-IV and interacting with Gravity Sketch 
highlighted the different outcomes users expected from specific buttons, especially if 
they previously experienced other VR applications (e.g., games). For example, the 
Meta Quest 2 controller (Figure 7.10) has one trigger for the index finger and one for 
the middle finger. In Gravity Sketch, the index finger trigger is responsible for 
interacting with the UI elements, such as tabs. Conversely, the trigger pressed by the 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
205 
middle finger allows one to grab an object and reposition it in the virtual space. Some 
participants were confused about the different interactions because, in other VR 
applications, these functions worked in the opposite way. 
This specific example can be extended to non-immersive software, such as mobile 
applications, and even hardware devices, such as smartphones. Today, when 
unboxing a new smartphone, it is often only a matter of seconds before the user 
locates the side button and presses it to power the device. This immediacy in actions 
can be attributed to the fact that, over the years, product designers as well as UX 
and UI designers aligned their designs to be consistent across different hardware 
and software products. Consequently, this consistency – this common language – 
facilitated users' understanding of how to interact with machines. This consideration 
extends beyond the current research but is important for creating better and more 
intuitive immersive applications. 
 
Visual Representation Improvements 
 
‘What is the difference between the real world and the virtual one?’ 
Yuuki Asuna, Sword Art Online II, Episode 01 
 
Oculus VR founder Luckey (2016) answered this question without hesitation: ‘The 
quantity of data, that's all’. Putting aside the philosophical aspect of such a question, 
Luckey is correct regarding the amount of information a computer can process and 
the degree of visual fidelity available as the output of this computation. As explained 
at the beginning of this research, filmmakers have a keen eye for images. The 
research demonstrates that the visual fidelity of the virtual elements experienced in 
the VP process are an important factor. As explained by PW09, if the virtual 
environment is not represented faithfully, then potentially false assumptions can 
result when assessing the location. This may translate into serious troubles when 
arriving at the physical location during the shooting phase. To reduce 
misinterpretation of the space, participants noted during the testing and evaluation of 
the prototype that they could also study real photographs that faithfully represent the 
location while being immersed inside the virtual replica. Overall, the visual 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
206 
representation presented in DS-IV was considered acceptable if used as a tool for 
becoming familiarized with the real location before an in-person visit or shooting. On 
this matter, more technical effort should be made. Future work should focus on 
improving the visual representation of the virtual elements without exceeding the 
computational capabilities of immersive consumer devices and software. 
Alternatively, future research may experiment with techniques such as cloud 
computing, which require immersive devices to stream the video output from the 
computation performed by powerful centralized servers. The gaming industry has 
already been providing these services for playing video games (Nvidia, 2023) without 
requiring users to own powerful personal computers; only an internet connection with 
a large bandwidth is necessary. 
 
Relighting Environments, Objects, and People  
One of the limitations of scanning technologies, such as Polycam, is that the capture 
generated is relatively simple in 3D geometric and texture mapping. Many other 
factors are needed to recreate a realistic representation of real objects. One of the 
most crucial is lighting since each object and surface reflects light differently. Lighting 
proprieties in CG is a field of its own that has been investigated since the '70s 
(Gouraud, 1971). Relighting virtual environments when such information is missing is 
a challenging task. In recent years, some researchers have begun to explore this 
exciting field, taking advantage of the possibilities offered by machine learning and 
proving that it may be possible to relight objects (Sang & Chandraker, 2020) or 
people (Pandey et al., 2021). 
In the context of the proposed alternative VP for pre-production, future 
advancements may enable cinematographers to relight the location captured, 
experiment with diverse lighting setups, and pre-visualize the final output they want 
to achieve during the production phase.  
 
Semantic Segmentation of the Location Captured 
During DS-IV, some participants, especially PT18, expressed interest in 
repositioning or removing some set design elements of La Casa Gassia (Figure 7.1). 
However, the location captured and proposed was part of a single 3D geometric 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
207 
texture. It was not possible to interact with the single elements present in the scene. 
In the field of computer vision, researchers such as Yadav et al. (2022) suggest that 
machine learning advancements could allow the technology to automatically 
recognize and label different elements of a room, such as furniture, doors, or walls. 
Once again, such a technique combined with the practical prototype proposed would 
make it possible to separate each element of the scene and provide AV 
professionals, especially set designers, the freedom to interact with the location on a 
more granular level.  
 
Avatar Representation 
Participants noted that Gravity Sketch’s avatars were basic in visual representation. 
With such low-level realism, avatars could not convey facial expressions and other 
gestures, which are crucial, just as they are when people communicate in person. 
Maloney, Freeman, and Wohn (2020) have the same conclusion. To further improve 
the usability of the proposed VP process, it is suggested to explore how avatars of 
other collaborators can be represented in the VR or MR environment. 
 
Involvement of actors and actresses in the Co-Design Process 
Recreating more realistic avatars could also be beneficial when introducing the VP 
process to actors and actresses. Such figures were not involved in this research 
because of the limited resources at their disposal. However, future work should also 
engage with these fundamental stakeholders to collect insights and test different VP 
processes when these personnel are involved. 
In addition to familiarizing themselves with the location, they could rehearse in VR, 
which is an approach that is beneficial, according to Bouvilee, Gouranton, and 
Arnaldi (2016).  
 
‘If I had the time on set, I like to tell the actors to try anything, had the time to fail – 
just go ahead, try this, try that – You need that freedom’. Martin Scorsese 
(Masterclass, 2020) 
 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
208 
Of equal importance is the effort required in searching for technologies capable of 
optimally representing their performances in the virtual or mixed environment. Motion 
capture suits have been used for this purpose for decades, but they can be 
burdensome and difficult to set up (Meske et al., 2022). However, a promising 
technique is brought by the advancement of computer vision. Some researchers (Yu, 
Park, & Lee, 2021; Stenum, Rossi, & Roemmich, 2021) and existing commercial 
software (Move.ai, 2023; Plask, 2023) have demonstrated that it is feasible to extract 
people’s body movements from bi-dimensional videos. 
Furthermore, Bennett (2020) researched acting in virtual environments and outlines 
that investigating new technological systems is required to address some limitations, 
such as the occlusion of people's faces when they wear a VR headset. At the time of 
writing, Meta claims that through face-tracking sensors, their VR headset Meta 
Quest Pro (Meta, 2022) is capable of mimicking users’ facial expressions and 
overcoming Bennett's findings. 
 
From VR to Mixed Reality 
In DS-IV, specifically when assessing Location 03: Mont-Saint-Michel, participants 
experimented with the Passthrough feature offered by Gravity Sketch. This viewing 
mode received positive feedback since participants could see the real world (room 
and collaborators) and also the virtual elements (virtual location, objects, interfaces).  
It was considered less disconnected from reality than the VR viewing they 
experienced moments earlier. This finding suggests the need to further explore the 
integration of MR, perhaps by using more advanced headsets, such as the Meta 
Quest Pro or HoloLens 2 (Microsoft, 2023), in the VP process. 
 
Virtual Production as Support, Not as a Replacement 
Another important finding is that participants perceived that integrating their current 
production process with immersive and emerging technologies should occur with 
caution and vigilance. Participants believed that changing habits in the working 
environment is a sensitive matter. In many cases, when involving new participants in 
the study, their first concern was replacing their current in-person activities and 
tasks, which are often conducted in collaboration with other colleagues, with virtual 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
209 
and solitary ones. These initial instinctive answers may have been influenced by the 
physical confinement imposed by the pandemic, in which participants lived or were 
still living at the time of the data collection phase. After discussing the different 
aspects of immersive technologies, they opted for a more balanced view of such 
technologies. Most agreed that these processes should support their current process 
rather than replace them. The same is true when assessing other emerging 
technologies, such as AI, as discussed in Chapters 5 and 6. It is of primary 
importance for AV professionals to have the final word in creative or technical 
decisions. Introducing AI in their decision-making process raised scepticism since 
they would feel deprived of such decisions. 
The initial mistrust towards immersive and emerging technologies may be due in part 
to the scarcity or complete lack of personal experience in interacting with them. 
Therefore, the researcher wonders whether their prejudices and conjectures could 
be demystified if they were provided with these technologies for an extended time 
and allowed to experiment on their own. This could instil a more objective stance 
towards these technologies based on practical experience.  
 
 
 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
210 
8.1.3 Recommendations for Virtual Production Applied to Small and Medium 
Productions 
 
 
Figure 8.3 Representation of How the Research Contribution Was Generated 
 
Since the first data collection phase began, it was clear that the VP process required 
specific characteristics to be successfully adopted by SMPs. The initial insights 
contributed in answering to RQ 1.2 “What are the challenges that SMPs face due to 
limited resources?” and became increasingly evident after each iteration of 
evaluation, which started with initial ideas (DS-IIB) and was followed by diegetic 
prototypes (DS-III) and testing the practical prototype (DS-IV).  
 
This investigation revealed four main aspects considered crucial by AV professionals 
working within SMPs when adopting any VP process in a real-world scenario: 
usefulness, affordability, ease of use, and accessibility. 
A conceptual framework that summarizes these aspects and compares them with 
the current high-end VP processes is presented in Figure 8.5. 
 
 
 
 
 
 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
211 
 
 
Figure 8.4 Conceptual Framework Proposed for Virtual Production Processes Applied to Small and Medium 
Productions 
 
 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
212 
 
Table 15 Summary of Figure 8.5 
 
Current Challenges Common to all 
AV Roles 
 
Research Output 
Opportunities 
Usefulness 
Changing plans or exploring alternative 
creative ideas can be expensive or not 
possible 
Flexibility to experiment 
in real-time different 
creative or technical 
options and facilitate 
decision making 
 
Usefulness 
Communicating visual ideas can be 
challenging 
Take advantage of real-
time pre-visualisation 
and immersive 
technologies to quickly 
show others what 
envisioned 
 
Usefulness 
Collaboration across different 
departments can be challenging 
A collaborative 
environment where 
creative and technical 
inputs may converge. 
 
Affordability 
Current tools and technologies 
employed by high-end VP are highly 
expansive 
An alternative VP 
process proposed has 
low economic barriers to 
being employed 
 
Accessibility High-end VP process built upon custom 
and confidential hardware and software 
solutions 
An alternative VP 
process built upon "Off-
the shelves" hardware 
and software consumer 
products 
 
Ease of Use 
Learning to use tools and technologies 
employed by 
high-end VP is very demanding 
 
Friendly UX, intuitive 
interactions and steep 
learning curve. 
 
 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
213 
Usefulness. Any VP process applied to SMPs has to be evaluated as useful by the 
stakeholders. Some key factors identified throughout the research highlight how VP 
processes that offer opportunities to reduce costs and time while fostering creativity 
are considered valuable by AV professionals.  
Additionally, specific opportunities offered by VP could be common to all team 
members; for example, virtual meetings could ensure that everyone is on the same 
page.  
Alternatively, some opportunities may be role-specific within the same VP process 
through certain features or tool sets that aid specific professionals. 
Cinematographers, for instance, may experiment with different lighting or camera 
movements. More details on role-specific usefulness are provided in Figures 8.6, 
8.7, and 8.8. 
 
 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
214 
Usefulness to Directors 
 
Figure 8.5 Usefulness to Directors 
Table 16 Summary of Figure 8.6 
DIRECTOR 
Current Challenges 
Common to all AV Roles 
Research Output Opportunities 
Usefulness 
Communicating his/her own 
creative vision to the rest of 
the team 
Opportunity to bring collaborators in 
the virtual replica of the location 
and use interactive tools to 
communicate ideas (virtual 
cameras, drawings, notes...) 
Usefulness 
Experimenting with different 
creative ideas can be 
challenging due to the 
limited time at disposal 
during the location scouting 
and location recce 
Opportunity to spend as much time 
as desired in the virtual replica of 
the location and experiment 
 
Usefulness 
Scouting potential location 
relying on 2D images of the 
locations can be misleading 
Opportunity to access in an 
immersive way several potential 
locations where to set up the AV 
project and get a three-dimensional 
understanding of their 
characteristics 
 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
215 
 
Usefulness to Producers 
 
 
Figure 8.6 Usefulness to Producers 
Table 17 Summary of Figure 8.7 
PRODUCER 
Current Challenges 
Common to all AV Roles 
Research Output Opportunities 
Usefulness 
Identifying potential issues 
in advance without visiting 
the filming location 
Opportunity to experience an 
immersive visualisation of the 
location and its surrounding area to 
assess the location 
Usefulness 
Identifying potential issues 
in advance without 
dedicating enough time to 
location recce 
Opportunity to spend how much 
time desired in the virtual replica of 
the location 
Usefulness 
Being sure that every 
member of the AV 
production is aware of how 
the shooting day will be 
organised (schedule, 
shooting list, permits, 
surrounding facilities...) 
Opportunity to take part in remote 
immersive pre-production meetings 
in the virtual replica of the location 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
216 
Usefulness to Cinematographers 
 
 
Figure 8.7 Usefulness to Cinematographers 
 
CINEMATOGRAPHER 
Current Challenges 
Common to all AV Roles 
Research Output 
Opportunities 
Usefulness 
Limited freedom in 
experimenting with 
different creative ideas 
when lighting the scene 
and choosing the proper 
camera gear to employ 
(dolly, crane, jib....) 
Opportunity to experiment 
with virtual cameras, lights 
and gear to explore 
different creative options 
Usefulness 
Cinematographers often 
work on other projects 
while they are asked to 
start pre-production on the 
next one. In-person 
meeting with the director 
and other colleagues of the 
upcoming project is not 
always possible 
Opportunity to take part in 
remote immersive pre-
production meetings and to 
collaborate in the virtual 
replica of the location of 
upcoming AV projects 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
217 
Usefulness 
Limited time allowed for 
location recce and not 
always corresponding to 
the time of the day when 
the actual shooting will 
take place 
Opportunity to spend how 
much time to desired in the 
virtual replica of the location 
and to simulate sunlight at 
different times of the day 
 
 
The opportunities in terms of usefulness of the proposed VP process can also be 
extended to professionals in other departments (directing department, production 
department, and camera or lighting department). The same can be valid for other 
people involved in the pre-production phase, such as set designers while deciding 
how to act technically and creatively regarding which set design elements to 
integrate, replace, or reposition in the scene. 
 
Affordability. The cost of these VP processes was consistently at the centre of the 
conversation. The decision to spend any amount of money in SMPs is meticulously 
reviewed. The VP process that was designed during PS-IV requires fewer financial 
resources than those employed by high-end productions; however, participants 
recognized that any expense between several hundred and a couple of thousands of 
dollars (depending on how many people participate in the proposed VP process) is a 
decision to be weighed and discussed with the crew. 
 
Ease of Use. This factor was perceived as difficult to evaluate by reading the design 
fiction scenarios presented in DS-III. This led to development of a practical prototype 
(PS-IV) that was later tested and evaluated by participants (DS-IV). 
Findings revealed that the alternative VP process for immersive pre-production was 
straightforward. However, participants agreed that becoming skilful in actively 
operating the process would require some time. Alternatively, some participants, 
especially PT04 and PT05, suggested that only one person within the team needed 
to become proficient in the use of this VP process (in their words, ‘Master of VR’ or 
‘Master of Gravity Sketch’ PT25, producer) to guide the other members of the team. 
They likely came to this conclusion after participating in the user testing session 
where the researcher guided and facilitated the adoption of the proposed VP 
process.  
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
218 
 
Accessibility. AV professionals noted that they wanted to have at their disposal any 
gear and instruments needed to adopt any kind of VP. Using off-the-shelf products is 
therefore considered the ideal strategy since high-end VP processes in many cases 
are kept confidential for economic reasons. Additionally, it is important to consider 
that some products may be complex to import or export because of the policies 
present in some countries, which may exclude AV professionals working in those 
regions. 
 
8.2 Research Process 
 
8.2.1 Discussion of Essential Elements 
The Need for a Practical Output 
To assess the potential value brought by VP, participants working in SMPs needed 
to personally experiment with the practical prototype of such a VP process. 
Consequently, (Figure 8.1) the DRM framework was adopted since it is widely used 
when attempting to develop design support, according to Chakrabarti and Blessing 
(2009, p. 33), which is the ultimate goal of design research. 
 
Consequently, relying on existing off-the-shelf hardware and software products 
proved strategic and aligned with the researcher’s resources, as explained in Section 
7.4.1. Many previous researchers have supported this approach to developing 
practical prototypes. The literature review chapter explained how they adapted 
existing consumer devices and services to develop their VP processes. 
 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
219 
 
Figure 8.8 Alternative Representation of the Final Research Process  
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
220 
 
Co-Design Approach 
Deciding to involve participants according to co-design principles, from the beginning 
of the exploratory study through the end of the design research process, enabled the 
researcher to determine the broader context of VP's applications to SMPs. 
Conducting such work independently without considering multiple perspectives on 
the research subject could have generated a less complete output and caused the 
researcher to miss important aspects and insights. 
 
Design Fiction 
A technique such as design fiction prompted participants towards the generation of 
innovative ideas. Setting their thinking in the future enabled them to remove from 
their minds the technical constraints of current technologies. Limitations are often 
noted instinctively and promptly by this kind of participant. By nature, they are 
pragmatic, and their opinions are based on how they experience the world in the 
present. 
 
Evaluation Frameworks 
Actively interacting and prompting participants to contribute to the research proved 
crucial in collecting the initial user requirements, shaping initial ideas, extending 
these ideas into design fiction scenarios, and designing practical prototypes.  
The strategy to employ and adapt pre-established evaluation frameworks, such as 
the bullseye framework (Rayo et al., 2018) and TAM (Davis, 1986; Bertrand & 
Bouchard, 2008; Horvat et al., 2022), was crucial for rigorously categorizing and 
analyzing the information collected during each study. The findings from each 
evaluation phase contributed to identifying and improving the final design support 
and meeting the researcher's goal and scope.  
 
 
 
 
 
 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
221 
8.2.2  Methods Recommendations 
 
Recruiting AV Professionals 
One of the main challenges in this study was recruiting participants, which is a 
crucial component that enriched this work. Overall, having 74 unique professionals 
who worked in the AV industry be actively involved during the research process is 
substantial, considering the limited resources at the disposal of the researcher. 
Certainly, engaging with a larger sample would contribute to generating a more 
robust study. In this regard, it is suggested to build a strategic partnership with 
existing institutions, associations, organizations, and networks (e.g., Producers Guild 
of America, British Film Institute, AIR3, Asia-Pacific Broadcasting Union) by 
convincing them to believe in the value of the research project with which they are 
presented. This strategy should facilitate recruitment by future researchers who need 
these participants and allow them to engage with a larger sample. The network with 
which these players can engage, as a result of years of networking activities and 
initiatives, is far greater than what single researchers can achieve on their own. 
 
Primary Study Conducted in the Field 
While the restrictions imposed by the pandemic outbreak were a limitation to 
conducting in-person exploratory studies, future researchers should collect initial 
insights by joining an AV production that is about to start and asking to be an 
observer for the duration of the production process. 
 
Prototype Evaluation in a Real-World Scenario 
Similarly, for future scholars interested in testing the alternative VP workflow 
presented in this work or a different prototype, it is suggested to contact SMPs that 
are starting a new project and invite them to integrate the prototype designed herein 
into their process. Consequently, it would be possible to interview these 
professionals and ask how such integration impacted their work. 
 
 
 
8. DISCUSSION AND RECOMMENDATIONS 
 
 
 
222 
Research Assistant 
Collecting data using audio and video recorders and ensuring that the VR and AR 
devices and applications were working correctly while accurately executing the 
testing procedure proved challenging for a single researcher not only in DS-IV but 
also during all other data collection phases. Therefore, when approaching a similar 
study, recruiting one or more assistants who could fulfil some responsibilities and 
tasks while doing fieldwork is suggested. 
 
 
 
8.3 Chapter Summary 
This chapter provided suggestions for future researchers on the design strategy to 
use while investigating such an emerging field. 
Additionally, it presented recommendations based on the practical prototype that 
was co-designed, tested, and evaluated by participants. Key aspects to consider 
when applying VP to SMPs were identified and discussed.  
 
 
 
 
 
223 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Chapter 9 
 
CONCLUSIONS  
AND FUTURE WORK 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
224 
9. Conclusions and Future Work 
 
This chapter highlights the contributions arising from this work and outlines future 
research activities. 
 
9.1 Research Overview: Objectives and Outcomes  
This research was inspired by the scant research undertaken by previous 
researchers in an emerging field such as VP combined with the lack of design 
support that was actively co-designed with AV professionals operating in SMPs. To 
answer the main research question formulated in Chapter 1 (To what extent can VP 
combined with immersive technologies be employed by AV professionals in SMPs?), 
the researcher thought it appropriate to divide this enquiry into three sub-questions. 
Accordingly, Table 15 illustrates how the research objectives were achieved.  
 
 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
225 
 
Table 18 Illustration of the Research Questions and Defined Objectives 
Research question 
Objectives 
Chapter 
Research question 1.1  
What research already 
exists on this topic, and to 
what extent is VP already 
developed and employed 
by industry players in their  
making process? 
 
To REVIEW the academic literature 
and pre-existing processes employed 
by industry players regarding VP. 
Chapter 2 
Literature review 
Research question 1.2 
What are the challenges 
that SMPs face due to 
limited resources? 
To INVESTIGATE the challenges 
faced by AV professionals who work 
on SMPs. 
Chapter 4 
Exploratory Study 
Research question 1.3 
What alternative VP 
process can be co-
designed and developed to 
enable SMPs’ adoption of 
VP? 
 
To CO-DESIGN with participants 
alternative VP processes combined 
with immersive technologies. 
Chapter 5  
Idea co-generation 
Chapter 6 
Evaluation of the 
preferred design fiction 
scenario 
To TRANSLATE the outcomes of 
Studies 1-3 into a practical prototype to 
be tested and evaluated (study 4) by 
AV professionals. 
Chapter 7 
Practical development of 
a prototype and sub-
prototype 
To DISCUSS and self-reflect the 
implications of such prototype in Study 
5 and provide a set of 
recommendations upon which future 
work may advance research on the VP 
process applied to SMPs.  
Chapter 8  
Discussion of the 
research process and 
practical output leading to 
recommendations 
Chapter 9 
Summary and future 
research opportunities  
 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
226 
 
9.1.1 Meeting the Objectives Set to Answer Research Question 1.1 
The first part of this research was aimed to understand the latest advancements in 
VP by analyzing and reviewing relevant case studies. The same attention was also 
invested in searching the academic literature produced by previous researchers 
investigating this emerging field. 
 
RQ1.1: What research already exists on this topic, and to what extent is VP already 
developed and employed by industry players in their making process? 
 
Objective A: To review the academic literature and pre-existing processes 
employed by industry players regarding VP. 
 
The literature review (Chapter 2) highlighted that, in recent years, the private sector 
has invested in advancing VP since it could represent an economic advantage in 
creating AV products. High-end industry players developed a custom VP process for 
the needs of specific projects, but these do not extend to every AV production, which 
presents the lack of a VP process that considers the needs and distinctive traits of 
SMPs. Academic literature offers some exciting studies where SMPs were 
considered to be the end user of previous researchers' designs. However, the 
engagement with the end users occurred only at the end of the process while 
evaluating what was proposed by researchers. Additionally, these academic studies 
often presented alternative workflows centred around only one AV role or 
department. A more inclusive VP process that could better represent the ‘choral’ 
work of many different professional figures and departments while producing an AV 
product was missing. 
 
 
 
 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
227 
9.1.2 Meeting the Objectives Set to Answer Research Question 1.2 
Previous experience in the industry matured the researcher and played a vital role in 
extrapolating participants' tacit knowledge and enabling better empathizing with them 
when they discussed their working habits.  
RQ1.2: What are the challenges that SMPs face due to limited resources? 
 
Objective B: To investigate the challenges faced by AV professionals who work on 
SMPs. 
 
The second sub-question was designed to explore the daily and practical difficulties 
AV professionals who operate in SMPs encounter when working with limited 
economic and human resources. Consequently, through the preliminary study 
described in Chapter 4, it was possible to collect crucial insights and form multiple 
perspectives on the user requirements for a VP process that aligned with 
participants' needs.  
Further insights were also collected throughout the research. When speaking with 
participants, they mentioned anecdotes and stories about the difficulties and issues 
they encountered in past projects and how they related to the proposed alternative 
VP process. Therefore, through the end of the research, rich details about their 
challenges while working on AV productions were collected.  
 
9.1.3 Meeting the Objectives Set to Answer Research Question 1.3 
This third sub-question was aimed to co-design, develop, test, and evaluate with 
participants an alternative VP process combined with immersive technologies.  
 
RQ1.3: What alternative VP process can be co-designed and developed to enable 
SMPs’ adoption of VP? 
 
Objective C: To co-design with participants alternative VP processes combined with 
immersive technologies. 
 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
228 
As highlighted by the literature, no systematic researcher has yet co-designed VP 
processes with participants from the beginning of the design process. It was 
considered opportune to approach the research following co-design principles and 
actively engage with participants. The remote co-design workshop described in 
Chapter 5 contributed to achieving the goal of conceptualizing possible designs for 
alternative VP processes that were potentially beneficial for AV professionals 
working in SMPs. 
 
Objective D: To translate the outcomes of Studies 1-3 into a practical prototype to 
be tested and evaluated (study 4) by AV professionals. 
 
The outcomes that emerged from the co-design workshops, specifically PS-II, as 
well as the iteration and evaluation of the scenario perceived as most valuable in 
DS-III were used to develop an alternative VP process in PS-IV to support the pre-
production process of AV professionals working in SMPs. The different phases of 
such a proposed alternative VP process were described in detail in Chapter 7. 
 
Objective E: To discuss and self-reflect the implications of such a prototype in Study 
5 and provide a set of recommendations upon which future work may advance 
research on the VP process applied to SMPs.  
 
Through the in-person testing and evaluation phase described in Chapter 7, it was 
possible to draw conclusions about the proposed alternative VP process that led to 
further considerations and a presentation of a conceptual framework to aid future 
scholars interested in enriching knowledge on VP applied to SMPs. 
Suggestions on undertaking an investigation in this field and identifying an effective 
design research strategy are discussed in Section 9.4.1. Moreover, Section 9.4.2 
presents a list of recommendations for future researchers interested in employing the 
prototype developed in this work in a real-world scenario. 
 
 
 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
229 
9.2 Research Contributions 
Research Process 
As discussed in the literature review, little research has been conducted on VP 
because the recent development of immersive and emerging technologies. 
Additionally, the combination of the necessary multidisciplinary knowledge 
(immersive technologies, AV industry, design research), technical expertise 
(necessary to create a working prototype), and networking capability (necessary to 
involve hard-to-reach participants, such as AV professionals) to undertake such an 
investigation led to two contributions: 
 
I. 
An extensive review and organization of recent studies is present in the 
academic literature and in those innovative designs developed by industry 
players. These are the first step in decoding and organizing the work to date, 
both in academia and the industry as well as current needs. Although it 
cannot be classified as a systematic review, this thesis contributes to enabling 
future researchers to quickly navigate ever-evolving subjects, such as VP, and 
strengthening the bridge between academic knowledge and industry practice.  
 
II. 
The planning and execution of this research process occurred during an 
unprecedented event: the COVID-19 pandemic. In the first phases, this 
scenario required the research to be conducted through design methods that 
could be performed remotely. Hence, Chapters 5 and 6 presented and 
adapted some design methods to collect data using online services and tools. 
Both drawbacks and opportunities from this approach were discussed and 
may serve future researchers when operating in a similar scenario.  
 
 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
230 
Research Output 
This exploratory study contributes to a richer understanding of VP and its benefits for 
SMPs. The design research strategy adopted enabled the co-design of innovative 
ideas with AV participants, which were extended if participants perceived them to be 
valuable.  
Existing VP processes were discussed in Chapter 2, explaining that many AV 
professionals are not provided with affordable and easy-to-use technologies required 
to adopt VP. The findings in DS-I further confirm this consideration, and interviewed 
participants expressed their interest in employing VP tools and a workflow aligned to 
their needs and capabilities.  
The major practical contributions of this research are as follows: 
 
I. 
Design support was delivered via an alternative pre-production VP process 
that was tested and evaluated in a controlled environment (Chapter 7). 
 
II. 
Three highly detailed design fiction scenarios were co-designed with 
stakeholders and may benefit future researchers interested in further 
developing such scenarios into practical prototypes (Chapter 6). 
 
III. 
Stakeholders evaluated 14 initial ideas as potentially valuable and worthy of 
further extension and prototyping (Chapter 5). 
 
 
 
 
 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
231 
Contribution to Knowledge 
This research concludes with the development of design support that produced 
additional general conclusions on the topic under investigation. This contribution is 
represented by 
 
I. 
A list of recommendations upon which future developments in VP processes 
applied to SMPs can be based. 
 
The literature review process revealed that VP is a new field that has attracted 
attention among researchers. Some previous scholars (De Goussencourt, 2015; 
Zimmer et al., 2017; Muender, 2018; Spielmann, 2018; Ardal, 2019; Kuchelmeister, 
2020) have aimed to develop specific solutions that take advantage of immersive 
technologies to assist AV professionals operating in SMPs. However, in such 
studies, AV professionals were involved only at the end of the design process, when 
they were asked to test and evaluate researchers' independent ideations and 
developments.  
 
Involving AV professionals from the beginning of the design process, collecting and 
organizing their requirements, taking advantage of their tacit knowledge when 
prompting them to generate innovative concepts that align with their needs and, 
finally, asking them to test and evaluate a practical prototype as the output of the 
previous iterative phases is the main contribution of this research. A co-design-led 
investigation in the VP area is missing in the current literature. 
 
Adopting a co-design approach facilitated mutual learning derived by engaging with 
the end users of the design that the researcher intended to create. Participants were 
guided on the potential of immersive technologies through the provision of 
knowledge they did not have. Additionally, they shared with the researcher their 
challenges, habits, abilities, and operating context. This exchange of knowledge has 
been considered by other researchers (Robertson & Simonsen, 2012; Sanders & 
Stappers, 2008) as beneficial for generating context-specific and impactful new 
designs. Evidence of this belief is found in the outputs generated in PS-III and PS-IV 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
232 
that were positively evaluated in DS-III and PS-IV, respectively. All diegetic and 
practical prototypes earned an average score over > 3.50 (Agree) when asked if the 
co-designed alternative VP process could facilitate technical, productive, and 
creative aspects compared to their current production process. 
 
The reflection on the different outputs of PS-II (initial concepts), PS-III (diegetic 
prototypes), and PS-IV (practical prototype) in Section 8.2 allowed four necessary 
aspects of VP to be identified and described: usefulness, affordability, ease of use, 
and accessibility. These key elements emerged frequently throughout the research, 
thus confirming their crucial importance when designing a VP process whose end 
users were AV professionals working in SMPs.  
 
This researcher recognized a core component of all AV productions: the filming 
location. The importance of a scene's setting is considerable and influences 
technical, logistical, and creative choices, thus affecting almost all AV professionals 
involved in the production process. 
Practitioners in the AV industry recognized the potential of VP combined with LED 
volumes. Projecting the location on the LED walls in the background allows the 
whole crew to work in a controlled environment (the film studio) and provides the 
illusion of shooting in the real location while offering related benefits (pre-
visualization, collaboration, communication, and rapid iteration). With the same 
purpose, today and in the past, countless AV productions have relied on green 
screen studios (where actors’ and actresses composites are placed inside real or 
fictional locations) or have physically built a film set (a strategy used since the early 
20th century). 
 
The need and attempt to reconstruct locations has been a constant in the history of 
AV production, and consequently, it is not surprising that modern VP processes are 
centred mainly around LED volumes (Abramas et al., 2016; Favreau et al., 2019; 
Pohl, 2019; Netflix Studios, 2022) that are capable of partially immersing AV 
professionals in the digital replica of the location. 
 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
233 
However, the VP process can have many forms (Thacker, 2012) and therefore 
limiting research to LED volumes is a missed opportunity.  
Instead, this work contributes to knowledge by proving that alternative VP processes 
that employ more immersive technologies, such as VR and AR, are considered 
useful by stakeholders. Furthermore, the practical prototype developed as a result of 
the iterative co-design process has at its core the construction of a digital replica of 
the filming location, which favours creativity, decision-making, pitching, and reducing 
AV professionals' ecological footprints. This prototype, which is ready to be 
implemented in a real-world AV production, enriches the current literature by offering 
an alternative VP process that takes advantage of immersive technologies to answer 
stakeholders’ need to reconstruct the filming location, similar to what is attempted by 
adopting LED volumes, green screen studios, or physically building film sets. 
 
Finally, to further extend the boundaries on this emerging research area, this work 
contributes by defining several insights useful for future work (Section 8.2.1), which 
are summarized in the following paragraph. 
 
To be adopted, a VP process has to be easy to use by the stakeholders (ease of use 
is key), and developing custom interfaces for each role can be helpful (role-specific 
interfaces and tools). Ease of use is currently addressed by the discrepancy present 
among today’s immersive tools and interfaces, and although researchers have no 
control over this matter, they should be aware of its existence (consistency of 
interactions across immersive applications is yet to be defined). 
Because AV professionals have a keen eye for images, they expect a better visual 
representation in future VP processes (visual representation improvements), 
especially regarding correct lighting (relighting environments, objects, and people). 
On this aspect, groundbreaking researchers are obtaining promising results 
(semantic segmentation of the location captured). Because of the collaborative 
nature of AV productions, when those in different roles work together in a virtual 
environment, their avatars should better represent them (avatar representation). 
Another core component of AV production is provided by actors and actresses, and 
their perspective on VP should be included (involvement of actors and actresses in 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
234 
the co-design process). Additionally, stakeholders felt that working in a MR 
environment was more comfortable and reassuring; this should be further 
investigated (from VR to MR).  
Finally, AV professionals enjoy the collaborative component and human connection 
derived from their work environment. The total replacement of certain activities and 
current processes may be seen with fear and scepticism (VP as support, not as a 
replacement). 
 
9.3 Limitations  
This research presents some limitations on the topic under investigation and data 
collection.   
 
9.3.1 The Topic 
Because a strong technological component characterizes the nature of this topic, it is 
changing rapidly. Although this research provides several valuable findings and 
insights, immersive devices and software advance rapidly. 
As new technologies develop, this situation may change over the course of the next 
5 to 10 years. In the near future, other workflows and tools may be adopted and 
preferred by filmmakers when creating their AV products. Nevertheless, core aspects 
of every AV production, such as collaboration, communication, and quick iteration, 
will continue to be at the centre of the scope of the VP process. It is probable that the 
same will also be valid for the findings characterizing VP processes for SMPs: 
usability, affordability, ease of use, and accessibility. These critical factors presented 
in the conceptual framework in Chapter 8 will likely remain significant in the long 
term. 
 
 
 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
235 
9.3.2 COVID-19 Pandemic 
The COVID-19 outbreak significantly affected this project, as it disrupted traditional 
research workflows involving face-to-face involvement of participants. Such an event 
complicated the development of this study, requiring suspension of in-person data 
collection for a significant part of the research. In a scenario not affected by the 
pandemic, the researcher, for instance, may have been involved as an active 
observer during the creation of an AV production. This approach, especially during 
the exploratory phase, would have enabled the researcher to better understand 
professionals’ challenges and behaviours in their work environment. Furthermore, as 
restrictions were gradually lifted, AV professionals’ attention and endeavours were 
focussed on seeking paying jobs. Asking them to contribute time and effort to 
academic research was difficult and required flexibility on the researcher's side. 
 
However, these limitations in some cases became opportunities for exploration of 
remote online approaches with the potential to facilitate accessibility while reducing 
travel costs and carbon footprints. As discussed in Section 5.6, future adoption of 
hybrid approaches to data collection with participants could be advantageous if one 
combined advantages from traditional in-person and remote online techniques. One 
option is for online workshops to focus on those aspects of the research in which 
access to physical prototypes and in-person interaction is unnecessary. In contrast, 
face-to-face events can be restricted to those activities that most benefit from 
implementation in a physical venue. 
 
9.3.3 Data Collection 
This investigation had some limitations when data were collected during DS-IIA 
(induction to VP) and PS-II (co-design initial ideas and iteration) due to the design 
methods employed. 
 
9.3.3.1 Data Collection for DS-IIA and PS-II 
Part of the first workshop (DS-IIA) was dedicated to explaining the current state of 
the art of VP (induction) and describing the different technologies that can be 
integrated. Social distancing restrictions during the pandemic significantly limited 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
236 
options concerning data collection with participants and prevented the 
implementation of face-to-face co-designed activities in which participants could 
have benefited from hands-on experience with physical prototypes.  
The mere verbal and visual explanation (supported by videos) of experiential 
technologies, such as VR and AR, may have limited imagination and creativity when 
participants were asked to brainstorm ideas in the next PS-II phase.  
 
9.3.3.2 The Role of the Researcher 
The researcher was a facilitator when engaging with participants during the remote 
workshops (DS-IIA, PS-II, DS-IIB) and the user testing session (DS-IV). His role 
ensured that the procedure was correctly executed, and he provided explanations 
and guidance to the participants when needed. It is possible that his presence when 
participants were testing the practical prototype in DS-IV may have influenced the 
participants' perception of the prototype's ease of use. The facilitator aided 
participants when they encountered confusion on how to operate the prototype. 
When participants were asked to evaluate the prototype's ease of use, the facilitator 
reminded them to consider the help received during the user testing session. 
This limitation indicates that future scholars should design a testing procedure where 
the aid of the facilitator is not present. 
 
9.3.3.4 Geographic and Cultural Biases 
Research participants mainly worked in three countries: the United Kingdom, Italy, 
and the United States. An attempt was made to involve professionals working in 
other countries and regions, especially while spreading the online questionnaire. 
This intention resulted in collecting few responses from professionals in the Central 
American and South-East Asian region. Nevertheless, it is crucial to mention that 
current AV production processes are similar worldwide (Goldsmith, 2010; Lotz, 2021) 
when it is tried to reach a certain professional standard, as described in Section 
3.5.3. Additionally, the goal for the research output was to increase knowledge of a 
scarcely researched topic, which represents, therefore, a first step in this direction. 
The contribution represented by this research is open to further development for 
specific cultural and geographic contexts. Finally, focussing on contexts with limited 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
237 
resources is one of the main characteristics of this investigation. Therefore, the 
research output may be extended to various geographic and cultural contexts. In any 
case, for more robust validation of the findings, an effort is needed to further 
investigate VP applied to SMPs while considering the perspectives of AV 
professionals working in additional regions of the world. 
 
9.3  Suggestions for Future Work 
Overall, AV professionals are intrigued by the innovation brought by immersive 
technologies, and the direct experience allowed them to better understand the 
product's fundamentals, limitations, and possibilities. Their opinions on how the VP 
process can be used by SMPs and their evaluation of the tested prototype prompted 
directions for future works in the field. 
 
9.4.1 Adaptability  
Following the discussion on both the research process and the practical output 
described in Chapter 8, it is possible to speculate on how the VP processes applied 
to SMPs may be adopted and adapted in different fields and contexts. 
 
High-End Productions 
During the exploratory study, PI05, one of the two leading experts working on high-
end VP, stated that he also employed common consumer devices, such as an iPad, 
during the production of a blockbuster movie: ‘It’s not only about a democratization, 
[consumer] technology can benefit everyone, at any level [from high-end to SMPs]’. 
This statement is further demonstrated by the design process Jutan and Ellis (2017) 
established when integrating off-the-shelf hardware devices into their high-end VP 
process. Jonathan Bach (Bach, 2022) states on his Instagram page that, while 
working on Avatar: The Way of Water (Cameron, 2022), he used Gravity Sketch 
while initially designing one of the movie's scenes. Therefore, the output of this 
research can be extended beyond SMPs and towards high-end productions. 
 
 
 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
238 
Education 
The practical output of this work and the recommendations listed can also find a 
place within the education sector.  
The implementation lectures regarding real-time rendering applied to filmmaking 
have already been integrated in some film schools and digital media courses, 
according to PT22 and PT23, who recently graduated and approached Unreal 
Engine 4 in a bi-dimensional way (using mouse, keyboard, and 2D monitor).  
Considering the pace at which technology in the immersive and VP fields is 
advancing, it is possible to expect increasingly advanced visual representations of 
virtual environments. Thus, future work may build on the output of this research to 
create a ‘playground’ for aspiring AV professionals, such as an alternative immersive 
workflow for experimenting with different shooting techniques that may involve 
expensive or burdensome gears (camera optics, lights, dolly, set design, props, etc.) 
or difficult-to-access film studios or real locations. A potential drawback was raised 
by PT14 when explaining that an alternative immersive workflow that is drastically 
different from the dynamics of the real working environment may create a 
discrepancy in the learning process of young students: ‘[Film courses] should teach 
filmmaking processes according to the current market standards and trends’. 
Concurrently, incorporating awareness of the VP process in recent graduates' 
curriculum may increase their chances of being hired in the future, considering the 
lack of workers who have this skill set (Bennet et al., 2021). 
The findings from this research raise new and exciting areas for future researchers 
eager to investigate the role of immersive technologies and VP in media and film 
courses.  
 
 
 
 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
239 
9.4.2 Further Research Opportunities: Emerging Technologies 
The technological advancements humankind are producing and witnessing are 
unprecedented. Many are the new and emerging technologies that can shape the 
future of AV productions, and further research is needed. 
 
Real-World Digital Twins 
The attempt to encapsulate the real world in a digital likeness that is as faithful as 
possible is both a philosophical fascination and a technical effort claiming to bring 
many useful applications, as briefly presented in Section 7.6.1. 
 
Several companies (Bluesky, Maxar Technologies, Terra Metrics) provide 2D and 3D 
satellite images of extensive areas of the globe with increasing accuracy. In the 
future, the process described in Section 7.4.2 of manually capturing existing 
locations may be replaced by seeking the desired location within the vast libraries 
that such companies may make available.  
 
A different approach is needed when the aim is to create a digital replica of the 
interiors of such locations. The challenge is represented by the endless number of 
interiors that cannot be automatically scanned with satellites and by the legal permits 
to capture these often private locations. An attractive option could be relying on user-
generated captures that may be then made available for free or for purchase on pre-
existing 3D asset marketplaces. PT13 raised questions about the rights of digital 
captures, and PT14 answered that it would work similar to photography rights. In his 
opinion, the answer depends on the eventual constraints of the specific location. AV 
professional Alex Harvey depicts a possible future scenario in his post on LinkedIn:  
 
‘In the future, you might be limited to how many photos you are allowed to take 
inside a national heritage site or museum to stop people creating and selling 
unauthorized photogrammetry 3D models online’ (Harvey, 2022).  
 
For the practical prototype developed, both photogrammetry and LiDAR scanning 
technology combined with photogrammetry was used to capture existing spaces. An 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
240 
alternative technique that is gaining traction among researchers (Mildenhall et al., 
2021; Martin-Brualla et al., 2021) is neural radiance fields (NeRF), which is based on 
the opportunities offered by deep learning and should be further investigated in 
relation to VP.  
 
Generative AI 
Of no less importance and requiring researchers’ attention is the current and future 
potential of generative AI. A initial attempt to understand perceptions and potential 
uses of generative AI was made during the co-design workshops in Chapter 5. In 
that research phase, participants expressed a mix of scepticism and concern about 
the images produced by OpenAI’s Dall-E generative algorithm (Ramesh, 2021). 
They clearly expressed that its use should aid and not replace their creative 
freedom.  
 
The pace at which generative AI developed in recent years and the media attention 
on the subject is immense. The technology is capable of generating images as well 
as text, audio, and videos. ChatGPT3, a chatbot capable of formulating textual 
responses to users’ questions, is a rising concern among academic leaders because 
it can be used by students and researchers to automatically write their essays or, at 
least, provide them with a draft. To these critiques, OpenAI CEO Sam Altman 
replied, saying that education will adapt as it did in the past when calculators were 
introduced in schools (Mok, 2023). The doctoral researcher and author of this work 
finds it natural to wonder about the following provocative question: is this one of the 
last PhD theses not aided by ChatGPT3?   
 
Along similar lines, it is worth mentioning another project called Dramatron (Mirowski 
et al., 2022), a language model developed by Deepmind which received positive 
feedback from professional screenwriters while testing the usability and capabilities 
of this co-writing tool.  
 
When generating ideas during the second workshop, PW14 formulated the concept 
of having an AI ‘to predict the economic performance at the box office when casting 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
241 
certain actors’. AI algorithms do not yet seem to be capable of such economic 
valuations; however, it was notable to see a similar idea applied by developer and 
designer Dan Leveille while using the text-to-image generator mentioned previously 
to create counterfeit posters portraying the potential cast of Netflix’s live-action Zelda 
project (Leveille, 2022). Such cases may be useful to casting directors and executive 
producers when deciding whether a specific actors and actresses may be suitable 
for specific roles. 
 
However, a more important consideration exists than today’s output generated by AI 
algorithms: Plausible 2D images can now be generated by entering prompting text; 
in the future, it is likely that this trend will be transformed into text-to-video (Ho et al., 
2022; Villegas et al., 2022) or even text-to-3D. An early example is GET3D, which 
was developed by researchers at NVIDIA (Gao et al., 2022) and enables the creation 
of 3D textured geometries starting from the user's text prompt.  
 
Final Pixel in VR 
The advancements in capturing and generative technologies lead to further thinking 
when envisioning the future of AV production. If it is possible to acquire a realistic 
representation of all necessary assets, actors and actresses included, will that 
enable what can be called the final pixel in VR? This newly coined term takes 
inspiration from the current term final pixel on set, which refers to scenes shot inside 
a LED volume that do not require any post-production intervention (Pohl, 2019). 
In this regard, it is likely that the first AV genre to be produced entirely in a virtual 
environment may be animation, which is often characterized by a visual style that 
diverges from the faithful representation of reality. A wave of filmmaking in VR is 
already in action. Into the Metaverse (Metacosm Studios, 2021) is a 90-minute 
action-adventure film produced entirely using the social platform VR Chat, a social 
VR platform. Tales from Soda island is a short film created using the sketching and 
animating tool Quill (Hayden, 2022). 
 
The realm of emerging technologies is dense and constantly evolving, and the 
impact in transforming the current AV production process can be outstanding. 
9. CONCLUSIONS AND FUTURE WORK 
 
 
 
242 
However, even more disruptive changes that have not been seen before may derive 
from their ingenious and wise combination. 
 
9.4 Summary 
This chapter described the contribution represented by this research. A systematic 
approach enriched the current literature with new knowledge regarding VP applied to 
SMPs and offered both practical and conceptual outputs on which other researchers 
can base their future work. The challenges implied by investigating a topic such as 
VP were described, and recommendations on how to approach the subject were 
provided. Because of the exploratory nature of this PhD work, further and more 
specific studies are required and should employ additional and different design 
methods. 
The design research adopted led to several alternative VP processes for SMPs 
operating in the AV industry. This output was generated through a co-design 
approach that involved AV professionals from the first phase of the research. The 
researcher ascertained the current challenges among different personnel working in 
SMPs, which allowed the exploratory and iterative nature of the research to produce 
several innovative ideas. 
Such ideas were developed and evaluated in each subsequent phase. They were 
filtered based on the participants' perceptions of the different values attributed to 
each idea. At the end of the design process, one concept was developed into a 
prototype, which was tested and evaluated by participants. 
 
Finally, recommendations were provided for designing other VP processes and 
implementing them in a real-world scenario. Additionally, general guidelines were 
provided to advise future researchers interested in advancing knowledge on the VP 
field applied to SMPs. 
 
This work offers a conceptual and practical contribution to the current literature and 
the AV industry.
REFERENCES 
 
 
 
243 
 
References 
A 
● Abrams, J. J., Nolan, J., Joy, L., & Lewis, R. (2016, Present). Westworld 
[Television Series]. Warner Bros. Television Distribution. 
● Adobe Photoshop (2022). Adobe. Available at: 
www.adobe.com/products/photoshop 
● Adobe Premiere (2022). Adobe. Workspaces and header bar. Available at: 
https://helpx.adobe.com/premiere-pro/using/workspaces.html 
● Akenine-Moller, T., Haines, E. and Hoffman, N. (2019). Real-time rendering. 
AK Peters/crc Press. 
● Al-Emran, M., and Granić, A. (2021). Is it still valid or outdated? A bibliometric 
analysis of the technology acceptance model and its applications from 2010 to 
2020. In Recent advances in technology acceptance models and theories (pp. 
1-12). Springer, Cham. 
● Alban (2021, January 5). Day 5: 23rd street R W Subway stop. Retrieved 
from Sketchfab:  https://sketchfab.com/3d-models/day-5-23rd-street-r-w-
subway-stop-6eb9a6e3308948d793322670246ac2de.  
● Ali, A.X., Morris, M.R. and Wobbrock, J.O. (2021). Distributed interaction 
design: designing human-centered interactions in a time of social 
distancing. Interactions, 28(2), pp.82-87.  
● Alony, I., Whymark, G. and Jones, M.L. (2007). Sharing tacit knowledge: A 
case study in the Australian film industry 
● Anderson C. (2004, Oct). The long tail. Wired magazine, pp. 170-171 
● Angelopoulos, A., Hale, A., Shaik, H., Paruchuri, A., Liu, K., Tuggle, R. and 
Szafir, D. (2022). March. Drone Brush: Mixed Reality Drone Path Planning. 
In 2022 17th ACM/IEEE International Conference on Human-Robot 
Interaction (HRI) (pp. 678-682). IEEE 
● Ardal D., Alexandersson S., Lempert M., and Abelho Pereira A.T. (2019) A 
collaborative previsualization tool for filmmaking in virtual reality. CVMP 2019: 
REFERENCES 
 
 
 
244 
16th ACM SIGGRAPH European conference on visual media 
production. London, United Kingdom. 
● Auger, J. (2013). Speculative design: crafting the speculation. Digital 
Creativity, 24(1), pp.11-35 
● Avital, M. (2011). “The Generative Bedrock of Open Design.” In Open Design 
Now: Why Design cannot Remain Exclusive, edited by B. V. Abel, R. 
Klaassen, L. Evers, and P. Troxler, 48–58. Amsterdam: BIS Publishers. 
● Aylett, R., and Louchart, S. (2003). Towards a narrative theory of Virtual 
Reality. Virtual Reality (Waltham Cross), 7(2), 2–19. doi:10.1007/s10055-003-
0114-9 
● Aylett, R., Louchart, S., Dias, J., Paiva, A., & Vala, M. (2005). FearNot! – An 
Experiment in Emergent Narrative. Proceedings of the International Workshop 
on Intelligent Virtual Agents (pp. 305-316). 
 
B 
 
● Bach, J. (2022). Instagram [@jonathanbachdesign]. 19 December 2022. 
Available at: https://www.instagram.com/p/CmXHlrESKlC/ 
● Bailey, J. (2008). ‘First steps in qualitative data analysis: Transcribing’, 
Family Practice, 25(2), pp. 127–131. doi: 10.1093/fampra/cmn003. 
● Bakırlıoğlu, Y., Ramírez Galleguillos, M.L. and Coşkun, A. (2020). Dreaming 
of immersive interactions to navigate forced distributed collaboration during 
Covid-19. Interactions, 27(5), pp.20-21. 
● Barricelli, B. R., Casiraghi, E., & Fogli, D. (2019). A survey on digital twin: 
Definitions, characteristics, applications, and design implications. In IEEE 
Access (Vol. 7). Institute of Electrical and Electronics Engineers Inc. 
https://doi.org/10.1109/ACCESS.2019.2953499 
● Bazley N. (2022). [online]. LinkedIn post. posted 17 November 
https://www.linkedin.com/posts/nathan-bazley-518882a1_virtualproduction-
icvfx-activity-6998892741879373824-
jdfU?utm_source=share&utm_medium=member_desktop 
REFERENCES 
 
 
 
245 
● Bennett, J.C, and Carter, C. (2014). Adopting Virtual Production For 
Animated Filmaking. 81–86. https://doi.org/10.5176/2251-1679_cgat14.21 
● Bennett, J.C. (2020). Immersive Performance Environment: A framework for 
facilitating an actor in Virtual Production (Doctoral dissertation, Queensland 
University of Technology). 
● Bennett, J., Heath, C., Kilkelly, F., & Richardson, P. (2021). Virtual 
Production: A Global Innovation Opportunity for the UK (Academy Immersive 
Skills Report). StoryFutures. 
● Bertran, F.A., Pometko, A., Gupta, M., Wilcox, L., Banerjee, R. and Isbister, 
K., (2022). Designerly Tele-Experiences: A New Approach to Remote Yet Still 
Situated Co-Design. ACM Transactions on Computer-Human Interaction. 
● Bertrand, M., and Bouchard, S. (2008). Applying the technology acceptance 
model to VR with people who are favorable to its use. Journal of Cyber 
Therapy & Rehabilitation, 1(2), pp.200-210. 
● Blake J.H., (2019). The History of the Future: Oculus, Facebook, and the 
Revolution That Swept Virtual Reality. Dey Street Books 1st ed. 
● Bleecker, J. (2009). Design Fiction: A Short Essay. Available 
at: http://nearfuturelaboratory.com/2009/03/17/design-fiction-a-short-essay-
on-design-science-fact-and-fiction/ 
● Blomkamp, E. (2018). The Promise of Co-Design for Public Policy 1. 
In Routledge handbook of policy design (pp. 59-73). Routledge 
● Blondin, A. (2019). “Designing a film set in VR on “John Wick: Chapter 3 - 
Parabellum”, Unreal Engine . [Online]. Available at: 
https://www.unrealengine.com/en-US/spotlights/designing-a-film-set-in-vr-on-
john-wick-chapter-3---parabellum (Accessed: 20 Feb 2023) 
● Bodini, A. (2017). “Narrative Language of Virtual Reality”, 1st edn. World VR 
Forum. Geneva 
● Bodini, A., Colecchia, F., Manohar, A., Harrison, D. and Garaj, V., 2023. 
Using immersive technologies to facilitate location scouting in audiovisual 
media production: a user requirements study and proposed 
framework. Multimedia Tools and Applications, 82(8), pp.12379-12400 
REFERENCES 
 
 
 
246 
● Bødker, K., Kensing, F. & Simonsen, J. (2004). Participatory IT Design. 
Designing for Business and Workplace Realities. MIT press, Cambridge, MA. 
● Bogers, M., A. Afuah, and B. Bastian. (2010). “Users as Innovators: A 
Review, Critique, and Future Research Directions.” Journal of Management 
36 (4): 857– 875 
● Boland, J., Banks, S., Krabbe, R., Lawrence, S., Murray, T., Henning, T. and 
Vandenberg, M. (2021). A COVID-19-era rapid review: using Zoom and 
Skype for qualitative group research. Public Health Research & Practice, 
pp.1-9. 
● Borden, H.C., and Pighini, G.P. (1969). Solid-state displays. Hewlett-Packard 
J., 20, p.2 
● Bouville, R., Arnaldi, B., & Reality, V. (2016). Virtual Reality Rehearsals for 
Acting with Visual Effects To cite this version : International Conference on 
Computer Graphics & Interactive Techniques, 1–8. https://hal.inria.fr/hal-
01314839v2%0Ahttps://hal.inria.fr/hal-01314839 
● Blessing, L., and Chakrabarti, A. (2009). DRM, a design research 
methodology. London: Springer. 
● Brace, I., (2018). Questionnaire design: How to plan, structure and write 
survey material for effective market research. Kogan Page Publishers 
● Braun, V., & Clarke, V. (2006). Using thematic analysis in psychology. 
Qualitative Research in Psychology, 3(2), 77–101. 
● Broadley, C. and Smith, P. (2018). Co-design at a distance: Context, 
participation, and ownership in geographically distributed design 
processes. The Design Journal, 21(3), pp.395-415 
● Bryman, A. (2016). Social research methods. 5th ed. Oxford: Oxford 
University Press, 442 
● Brüggen, E., & Willems, P. (2009). A Critical Comparison of Offline Focus 
Groups, Online Focus Groups and E-Delphi. International Journal of Market 
Research, 51(3), 1–15. https://doi.org/10.1177/147078530905100301 
 
C 
 
REFERENCES 
 
 
 
247 
● Cambridge University Press (2022). Available at: 
https://dictionary.cambridge.org/dictionary/english/workshop (Accessed 20 
February 2023). 
● Cameron, J. (2009). Avatar. [Film]. 20th Century Fox. 
● Cameron, J. (2022). Avatar: The Way of Water [Film]. 20th Century Studios. 
● Chemical Wedding (2021). Helios Pro. Retrieved from Chemical 
Wedding: https://www.chemicalwedding.tv/. (Accessed 20 February 2023). 
● Cho, J. Y., and Lee, E.H. (2014). ‘Reducing confusion about grounded theory 
and qualitative content analysis: similarities and differences’, The Qualitative 
Report, 19(64), pp. 1–20. doi: http://www.nova.edu/ssss/QR/QR19/cho64.pdf. 
● Cifter, A. (2011). An inclusive approach towards designing medical devices 
for use in the home environment. PhD thesis, Brunel University London. 
● Cinematography Database (2014). Available at: 
https://www.youtube.com/user/cinematographydb/videos (Accessed 20 
February 2023). 
● Cinematography Database (2018). Leica BLK 360 | Is it for the Film 
Industry? YouTube. Available at: 
https://www.youtube.com/watch?v=hGOQ1lUysxY (Accessed 20 February 
2023). 
● Cinematography Database (2019). FMX 2019 | Matt Workman Cine Tracer 
Presentation. YouTube. Available at: 
https://www.youtube.com/watch?v=_mjB-2WONKA. (Accessed 20 February 
2023). 
● Creswell, J. W. (2013). Research design: Qualitative, Quantitative, and Mixed 
Methods approaches. 3rd ed. London: SAGE. 
● Cross, N., (1972). Design participation: proceedings of the Design Research 
Society's conference, Manchester, September 1971. London: Academy 
Editions. 
● Cross, N. (1999). Design Research: A Disciplined Conversation. Design 
Issues Vol. 15, Issue. 2, pp 5-10. 
● Crotty, M. (1998), The Foundations of Social Research – Meaning and 
perspectives in the research process. SAGE Publications. 
REFERENCES 
 
 
 
248 
 
D 
 
● Daniels, N., Gillen, P., Casson, K. and Wilson, I. (2019). STEER: Factors to 
consider when designing online focus groups using audiovisual technology in 
health research. International Journal of Qualitative Methods, 18, 
p.1609406919885786. 
● Davis, F. D. (1989). Perceived Usefulness, Perceived Ease of Use, and User 
Acceptance of Information Technology. MIS Quarterly, 13(3), 319–340. 
https://doi.org/10.2307/249008 
● De Goussencourt, T. (2015). A game engine as a generic platform for real-
time previz-on-set in cinema visual eﬀects. International Broadcasting 
Convention. Amsterdam, Netherlands. 
● Desowitz B. (2023). ‘The Mandalorian’: Jon Favreau on Expanding the Scale 
and Moving Beyond the Volume for Season. Retrieved March 20, 2023, from 
https://www.indiewire.com/2023/03/disney-plus-mandalorian-season-3-jon-
favreau-vfx-volume-1234816697/ 
● DJI (2022a). DJI Mavic 3 Specifications. https://www.dji.com/uk/mavic-
3/specs 
● DJI (2022b). DJI Mini 2 Specifications. https://www.dji.com/uk/mini-2/specs 
● Di Stefano, G., Pisano, G., & Staats, B. R. (2015). Learning by Thinking: How 
Reflection Aids Performance. Academy of Management Proceedings, 
2015(1), 12709. https://doi.org/10.5465/ambpp.2015.12709abstract 
● Dooley, K., (2017). Storytelling with virtual reality in 360-degrees: a new 
screen grammar. Studies in Australasian cinema, 11(3), pp.161-171 
● Dunlop, R. (2014). Production Pipeline Fundamentals for Film and Games. 
1st edn. CRC Press. 
 
E 
 
REFERENCES 
 
 
 
249 
● Ehn, P. (1993). Scandinavian Design: On Participation and Skill. In Schuler, 
D. and A. Namioka (Eds.), Participatory Design: Principles and Practices (pp. 
41–77). New Jersey: Lawrence Erlbaum Associates Publishes 
● Etikan, I., Musa, S.A. and Alkassim, R.S. (2016). Comparison of convenience 
sampling and purposive sampling. American journal of theoretical and applied 
statistics, 5(1), pp.1-4. 
● European Commission (2022). Internal Market, Industry, Entrepreneurship 
and SMEs. Retrieved from: https://single-market-
economy.ec.europa.eu/smes/sme-definition_en 
 
F 
 
● Favreau, J., (2016). The Jungle Book [Film]. Walt Disney Studios Motion 
Pictures. 
● Favreau, J., (2019). The Lion King. [Film]. Walt Disney Studios Motion 
Pictures. 
● Favreau, J., Filoni, D., Kennedy, K., & Wilson, C. (2019, Present). The 
Mandalorian [Series]. Disney Platform Distribution. 
● FCDO (2022). Small to medium sized enterprises (SME) action plan. 
Retrieved from: https://www.gov.uk/government/publications/fcdo-small-to-
medium-sized-enterprise-sme-action-plan/small-to-medium-sized-enterprise-
sme-action-plan. (Accessed 20 February 2023). 
● Feast L., Melles G. (2010). Epistemological Positions in Design Research: A 
Brief Review of the Literature. Proceedings of Connected 2010 - Second 
International Conference on Design Education, University of New South 
Wales, Sydney Australia 28 June - 1 July 2010. 
● Flick, U., Kardoff, E. von and Steinke, I. (2004). A Companion to Qualitative 
Research. London: SAGA Publishing. doi: 10.1899/08-053.1. 
● Flynn, R., Albrecht, L., & Scott, S. (2018). Two Approaches to Focus Group 
Data Collection for Qualitative Health Research: Maximizing Resources and 
Data Quality. International Journal of Qualitative Methods, 17(1), International 
Journal of Qualitative Methods, 13 January 2018, Vol.17(1). 
REFERENCES 
 
 
 
250 
● Forrestal, S. G., D’Angelo, A. V., & Vogel, L. K. (2015). Considerations for 
and lessons learned from online, synchronous focus groups. Survey Practice, 
8(2), 1-8. 
● Frankfort-Nachmias C., Nachmias D (1996). Research methods in the social 
sciences, 5th edition. St. Martin Press, Inc., London 
● Frey, J.H., and Fontana, A., (1991). The group interview in social 
research. The social science journal, 28(2), pp.175-187. 
● Furness III, T.A. (1986), September. The super cockpit and its human factors 
challenges. In Proceedings of the human factors society annual meeting (Vol. 
30, No. 1, pp. 48-52). Sage CA: Los Angeles, CA: SAGE Publications 
 
G 
 
● Gao, J., Shen, T., Wang, Z., Chen, W., Yin, K., Li, D., Litany, O., Gojcic, Z. 
and Fidler, S., 2022. Get3d: A generative model of high quality 3d textured 
shapes learned from images. arXiv preprint arXiv:2209.11163 
● Gallaugher, J.M. and Wang, Y.M., (2002). Understanding network effects in 
software markets: Evidence from web server pricing. MIS quarterly, pp.303-
327 
● Gaggioli, A. (2001). Using virtual reality in experimental psychology. Towards 
Cyberpsychology, pp.157-174 
● Gao, J., Shen, T., Wang, Z., Chen, W., Yin, K., Li, D., Litany, O., Gojcic, Z. 
and Fidler, S., (2022). GET3D: A Generative Model of High Quality 3D 
Textured Shapes Learned from Images. arXiv preprint arXiv:2209.11163 
● Genesis (2018). Technicolor. Available at: 
https://www.technicolor.com/sites/default/files/2019-03/Technicolor-Genesis-
Brochure-20190131.pdf  (Accessed 20 February 2023). 
● Giardina, C. (2019). “Behind The Screen”, The Hollywood Reporter . [Online]. 
Available at: https://www.hollywoodreporter.com/behind-screen/lion-king-vfx-
team-featured-thr-behind-screen-podcast-1234941 (Accessed 20 February 
2023).  
REFERENCES 
 
 
 
251 
● Giravolt (2021, June 28th). Estances de la Casa Gassia. Ecomuseu Valls 
Àneu. Retrieved from Sketchfab: https://sketchfab.com/3d-models/estances-
de-la-casa-gassia-ecomuseu-valls-aneu-
ffc6b346b10c447f9adae12ba1e950da 
● Goldsmith, B. (2010). Local Hollywood. Univ. of Queensland Press. 
● Google Maps (2022). Google. Retrieved from: https://www.google.com/maps 
● Gouraud, H. (1971). Continuous shading of curved surfaces. IEEE 
transactions on computers, 100(6), pp.623-629 
● Gray, D. (2004). Doing research in the real world. 1st ed. London [etc.]: 
SAGA Publications. 
● Grand, S., and Wiedmer, M. (2010). Design fiction: a method toolbox for 
design research in a complex world 
● Gravity Sketch (2022) available at: https://www.gravitysketch.com/ 
● Grieves, M. (2014). Digital twin: manufacturing excellence through virtual 
factory replication. White paper, 1, 1-7. 
 
H 
 
● Hammersely, M., and Atkinson, P., (1995). Ethnography: Principles in 
practice. London & New York: Routledge 
● Hanington, B., and Martin, B. (2019). Universal methods of design expanded 
and revised: 125 Ways to research complex problems, develop innovative 
ideas, and design effective solutions. Rockport publishers 
● Harrington, C., and Dillahunt, T.R. (2021). May. Eliciting tech futures among 
Black young adults: A case study of remote speculative co-design. 
In Proceedings of the 2021 CHI Conference on Human Factors in Computing 
Systems (pp. 1-15) 
● Harvey A. (2022). [online]. LinkedIn post. posted on Jan 2022. 
https://www.linkedin.com/posts/alextenchrivr_photogrammetry-activity-
6891876410181378048-
bLMd?utm_source=share&utm_medium=member_desktop 
REFERENCES 
 
 
 
252 
● Hayden (2022). “Tales from Soda Island is a Spectacular Animated Short 
Built Entirely in VR”, Road to VR . [Online]. Available at: 
https://www.roadtovr.com/tales-from-soda-island-quill-vr-quest-rift/ (Accessed 
20 February 2023). 
● Helsel, S. (1992). Virtual reality and education. Educational 
Technology, 32(5), pp.38-42 
● Helzle, V., Grau O., and Knop T., Virtual production. In M. Magnor A., Grau 
O., Sorkine-Hornung O., and Theobalt C. (2015). Digital Representations of 
the Real World, pages 347–358. CRC Press. 
● Hennink M.M., Kaiser B.N., Marconi, V.C. (2017). Code saturation versus 
meaning saturation: how many interviews are enough? Qual Health Res 
27(4):591–608. https://doi.org/10.1177/1049732316665344 
● Hesmondhalgh, D., and Baker, S., (2010). ‘A very complicated version of 
freedom’: Conditions and experiences of creative labour in three cultural 
industries. Poetics, 38(1), pp.4-20 
● Ho, J., Chan, W., Saharia, C., Whang, J., Gao, R., Gritsenko, A., Kingma, 
D.P., Poole, B., Norouzi, M., Fleet, D.J. and Salimans, T., 2022. Imagen 
video: High definition video generation with diffusion models. arXiv preprint 
arXiv:2210.02303 
● Horvat, N., Kunnen, S., Štorga, M., Nagarajah, A. and Škec, S., (2022). 
Immersive virtual reality applications for design reviews: Systematic literature 
review and classification scheme for functionalities. Advanced Engineering 
Informatics, 54, p.101760. 
● Humphreys, J. (2022). Screen Collab (Beta).  Available at:  
https://gravitysketch.zendesk.com/hc/en-us/articles/6266899654941-Screen-
Collab-Beta-  (Accessed 20 February 2023). 
● Huff, A. S. (2009). Designing research for publication. Los Angeles, CA: 
Sage. 
● Huusko, M., Wu, Y. and Roto, V. (2018). December. Structuring and 
engaging: The roles of design fictions in a co-design workshop. 
In Proceedings of the 30th Australian Conference on Computer-Human 
Interaction (pp. 234-241) 
REFERENCES 
 
 
 
253 
 
I 
 
• IBM (2022). SPSS Statistics. https://www.ibm.com/products/spss-
statistics/base 
• Ibrus, I., and Rohn, U. (2019). Small size matters: audiovisual media 
industries around the Baltic Sea. In Emergence of Cross-innovation Systems. 
Emerald Publishing Limited 
• IDEA Consult (2013). Survey on Access to Finance for Cultural and Creative 
Sectors, study commissioned by the European Commission. Retrieved from: 
https://ec.europa.eu/assets/eac/culture/library/studies/access-finance_en.pdf 
 
J 
 
● Jayaram, S., Connacher, H.I. and Lyons, K.W. (1997). Virtual assembly using 
virtual reality techniques. Computer-aided design, 29(8), pp.575-584 
● Jutan, M., and Ellis, S. (2017). Director-centric virtual camera production tools 
for rogue one. ACM SIGGRAPH 2017 Talks, SIGGRAPH 2017, 2–3. 
https://doi.org/10.1145/3084363.3085053 
 
K 
 
● Kadner, N. (2019). The Virtual Production Field Guide. 1st ed. [ebook] Epic 
Games. 
● Katy Perry (2020, May 18). Katy Perry - Daisies (Live From American Idol 
Finale, May 17 2020). https://www.youtube.com/watch?v=9UcHvzG1I1I 
● Kavakli, M. and Cremona, C. (2022). March. The Virtual Production Studio 
Concept–An Emerging Game Changer in Filmmaking. In 2022 IEEE 
Conference on Virtual Reality and 3D User Interfaces (VR) (pp. 29-37). IEEE 
REFERENCES 
 
 
 
254 
● Kelley, J.F. (1983). December. An empirical methodology for writing user-
friendly natural language computer applications. In Proceedings of the 
SIGCHI conference on Human Factors in Computing Systems (pp. 193-196) 
● Kirby, D. (2010). The future is now: Diegetic prototypes and the role of 
popular films in generating real-world technological development. Social 
Studies of Science, 40(1), 41–70. https://doi.org/10.1177/0306312709338325 
● Kite, J., & Phongsavan, P. (2017). Insights for conducting real-time focus 
groups online using a web conferencing service. F1000Research, 6, 122. 
● Konttori, U. (2020). Video Pass-Through XR Changes Reality As You Know 
it. Available at: https://varjo.com/blog/video-pass-through-xr-changes-reality-
as-you-know-it/ (Accessed 20 February 2023). 
● Kubrick, S. (1968). 2001: A Space Odyssey. [Film] Metro-Goldwyn-Mayer. 
● Kubrick, S. (1971). A Clockwork Orange. [Film] Warner Bros. 
● Kuchelmeister, V., 2020. Virtual Production and real-time filmmaking 
technologies for independent filmmakers. An overview. FKT-Fernseh-und 
Kinotechnik, 2020 
● Kujovic, E. (2022). “Import Best Practices”, Gravity Sketch. [Online]. 
Available at: https://gravitysketch.zendesk.com/hc/en-
us/articles/5902422101021-Import-Best-Practices (Accessed 20 February 
2023). 
 
L 
 
● La Torre, M. (2014). The economics of the audiovisual industry: Financing 
TV, film and web. Springer Nature 
● Landing Pad (2022) Gravity Sketch. https://landingpad.me/ 
● Langbehn, E., Lubos, P. and Steinicke, F. (2018). April. Evaluation of 
locomotion techniques for room-scale vr: Joystick, teleportation, and 
redirected walking. In Proceedings of the Virtual Reality International 
Conference-Laval Virtual (pp. 1-9) 
● Last Pixel (2019). I Am Mother - VR Storyboarding. 11 Sep. Available at: 
https://vimeo.com/359446829?fbclid=IwAR1hlcW6mv1M1ScFZ-
REFERENCES 
 
 
 
255 
DZQx3NrWY1qcJ45YtB_4J6ziGERcz8nhKJun-eXo0 (Accessed 20 February 
2023). 
● Leveille D. (2022) [Twitter] 05 Oct Available 
at: https://twitter.com/danlev/status/1577760869353607169 (Accessed 20 
February 2023). 
● Levy, E. (1999). Cinema of outsiders: The rise of American independent film. 
NYU Press. 
● Lewins, A. (2001). ‘CAQDAS: Computer Assisted Qualitative Data Analysis’, 
Researching social life, 0761972455, pp. 302–323. 
● Leipzig, A. (2014, January 22). Sundance Infographic 2014: Are 
independents the “8th Studio”? Retrieved 
from Culturalweekly.com: https://culturaldaily.com/sundance-infographic-
2014/. (Accessed 20 February 2023). 
● Lin, I. S., Galvane, Q, Li, T. Y., and Christie M. (2018). Design and evaluation 
of multiple role-playing in a virtual ﬁlm set. VRCAI 2018: 16th ACM 
SIGGRAPH International Conference on Virtual-Reality Continuum and Its 
Applications in Industry. Tokyo, Japan. 
● Litchi (2022). https://flylitchi.com/ 
● Liu, C. and Shen, S. (2020). October. An augmented reality interaction 
interface for autonomous drone. In 2020 IEEE/RSJ International Conference 
on Intelligent Robots and Systems (IROS) (pp. 11419-11424). IEEE 
● Lotz, A.D. (2021). In between the global and the local: Mapping the 
geographies of Netflix as a multinational service. International Journal of 
Cultural Studies, 24(2), pp.195-215. 
● Lucero, A., Dalsgaard, P., Halskov, K. and Buur, J. (2016). Designing with 
cards. Collaboration in creative design: Methods and tools, pp.75-95 
● Luckey P. (2016) [Twitter] 20 Jan Available 
at: https://twitter.com/palmerluckey/status/689643045097082880 (Accessed 
20 February 2023). 
● Lupton, D. (2020). “Doing fieldwork in a pandemic”, Available at: 
https://docs.google.com/document/d/1clGjGABB2h2qbduTgfqribHmog9B6P0
NvMgVuiHZCl8/edit?ts=5e88ae0a# (Accessed 20 February 2023). 
REFERENCES 
 
 
 
256 
 
M 
 
● Macer, T., and Wilson, S. (2014). Confirmit 2013 Annual MR Software 
Survey. Meaning ltd. 71-72. Available online at 
http://www.meaning.uk.com/resources/reports/2013-Confirmit-MRtechnology-
survey.pdf 
● Mademlis, I., Nikolaidis, N., Tefas, A., Pitas, I., Wagner, T. and Messina, A. 
(2018). Autonomous unmanned aerial vehicles filming in dynamic 
unstructured outdoor environments [applications corner]. IEEE Signal 
Processing Magazine, 36(1), pp.147-153. 
● Maloney, D., Freeman, G. and Wohn, D.Y. (2020). " Talking without a Voice" 
Understanding Non-verbal Communication in Social Virtual 
Reality. Proceedings of the ACM on Human-Computer 
Interaction, 4(CSCW2), pp.1-25 
● Marangunić, N., and Granić, A. (2015). Technology acceptance model: a 
literature review from 1986 to 2013. Universal access in the information 
society, 14(1), pp.81-95 
● Mares, J., and Weinberg, G. (2014). Traction: A Startup Guide to Getting 
Customers. S Curve Publishing 
● Markussen, T. and Knutz, E. (2013). September. The poetics of design 
fiction. In Proceedings of the 6th International Conference on Designing 
Pleasurable Products and Interfaces (pp. 231-240) 
● Martin-Brualla, R., Radwan, N., Sajjadi, M.S., Barron, J.T., Dosovitskiy, A. 
and Duckworth, D., 2021. Nerf in the wild: Neural radiance fields for 
unconstrained photo collections. In Proceedings of the IEEE/CVF Conference 
on Computer Vision and Pattern Recognition (pp. 7210-7219) 
● Masterclass (2020). Martin Scorsese Teaches Filmmaking | Official Trailer | 
Masterclass. Retrieved from: https://www.youtube.com/watch?v=W080qdCO-
_4 
● Meroni, A., Selloni, D. and Rossi, M. (2018). Massive Codesign: A proposal 
for a collaborative design framework. FrancoAngeli. 
REFERENCES 
 
 
 
257 
● Meske, C., Hermanns, T., Jelonek, M. and Doganguen, A., 2022. Enabling 
Human Interaction in Virtual Reality: An Explorative Overview of Opportunities 
and Limitations of Current VR Technology. In International Conference on 
Human-Computer Interaction (pp. 114-131). Springer, Cham. 
● Meta (2022). Meta Quest Pro. Retrived from: 
https://www.meta.com/quest/quest-pro/ 
● Metacosm Studios (2021). Into the Metaverse | Official Trailer (2023). 
Retrieved from https://www.youtube.com/watch?v=olSZuh7GnzI . (Accessed 
20 February 2023). 
● Microsoft (2023). HoloLens 2. https://www.microsoft.com/en-us/hololens/buy 
● Mildenhall, B., Srinivasan, P.P., Tancik, M., Barron, J.T., Ramamoorthi, R. 
and Ng, R., 2021. Nerf: Representing scenes as neural radiance fields for 
view synthesis. Communications of the ACM, 65(1), pp.99-106 
● Milgram, P,. and Kishino, F., (1994). A taxonomy of mixed reality visual 
displays. IEICE TRANSACTIONS on Information and Systems, 77(12), 
pp.1321-1329 
● Mirowski, P., Mathewson, K.W., Pittman, J. and Evans, R., 2022. Co-writing 
screenplays and theatre scripts with language models: An evaluation by 
industry professionals. arXiv preprint arXiv:2209.14958 
● Mok, A. (2023). “CEO of ChatGPT maker responds to schools' plagiarism 
concerns: 'We adapted to calculators and changed what we tested in math 
class”, Business Insider . [Online]. Available at: 
https://www.businessinsider.com/openai-chatgpt-ceo-sam-altman-responds-
school-plagiarism-concerns-bans-2023-1?r=US&IR=T (Accessed 20 February 
2023). 
● Morrison, A., Tronstad, R. and Martinussen, E.S. (2013). Design notes on a 
lonely drone. Digital Creativity, 24(1), pp.46-59 
● Move.ai, (2023). Digitasing movement for digital life. https://www.move.ai/ 
● Movie Trailer / PTP (2019). The Lion King 2019 - Making Of - How it was 
filmed in a realistic way. 12 Oct. Available at: 
https://www.youtube.com/watch?v=KCnayCnM6Zk (Accessed 20 February 
2023). 
REFERENCES 
 
 
 
258 
● Muender, T. (2018). Empowering creative people: Virtual reality for 
previsualization. Conference on Human Factors in Computing Systems, (pp. 
1-6). Montréal, Canada. 
● Muller, M. (1993). PICTIVE: Democratizing the Dynamics of the Design 
Session. In Schuler, D. and A. Namioka (Eds.), Participatory Design: 
Principles and Practices (pp. 211–237). New Jersey: Lawrence Erlbaum 
Associates Publishes 
● Muller, M.J., and Druin, A. (2012). Participatory design: The third space in 
human–computer interaction. In The Human–Computer Interaction 
Handbook (pp. 1125-1153). CRC Press. 
● MultiBrush (2022). www.oculus.com/experiences/quest/3438333449611263/ 
(Accessed 20 February 2023). 
 
N 
 
● Negri, E., Fumagalli, L. and Macchi, M., (2017). A review of the roles of digital 
twin in CPS-based production systems. Procedia manufacturing, 11, pp.939-
948 
● Netflix Studios (2022). “What is Virtual Production?.” Netflix Studios. 
https://partnerhelp.netflixstudios.com/hc/en-us/articles/1500002552642-What-
is-Virtual-Production- (Accessed 20 February 2023). 
● Newton, C. (2022). How DALL-E could power a creative revolution. [online] 
The Verge. Available at: <https://www.theverge.com/23162454/openai-dall-e-
image-generation-tool-creative-revolution> (Accessed 20 February 2023). 
● Nickpour F. (2012). Information behaviour in design. PhD thesis, Brunel 
University London. 
● Nowell-Smith, G. (1996). The Oxford history of world cinema. OUP Oxford. 
● Nvidia (2023) GeForce Experience. www.nvidia.com/geforce/geforce-
experience/ (Accessed 20 February 2023). 
 
O 
 
REFERENCES 
 
 
 
259 
● O'Leary, Z. (2010). The essential guide to doing your research project. Los 
Angeles: SAGE. 
● O’Reilly, M., and Parker, N. (2013). ‘Unsatisfactory Saturation’: a critical 
exploration of the notion of saturated sample sizes in qualitative 
research. Qualitative research, 13(2), pp.190-197 
● Oculus VR (2021). Mixed Reality Passthrough. Available at: 
https://developer.oculus.com/blog/mixed-reality-with-passthrough/ (Accessed 
20 February 2023). 
● Okun, J., and Zwerman, S. (2020). The VES Handbook of Visual Effects. 
https://doi.org/10.4324/9781351009409 
● Ørngreen, R., and Levinsen, K. (2017). Workshops as a Research 
Methodology. Electronic Journal of E-learning, 15(1), pp.70-81. 
 
P 
 
● Pandey, R., Escolano, S.O., Legendre, C., Haene, C., Bouaziz, S., Rhemann, 
C., Debevec, P. and Fanello, S. (2021). Total relighting: learning to relight 
portraits for background replacement. ACM Transactions on Graphics 
(TOG), 40(4), pp.1-21 
● Papanek, V., and Fuller, R.B. (1972). Design for the real world. 
● Parker, C., Scott, S. and Geddes, A. (2019). Snowball sampling. SAGE 
research methods foundations 
● Patton, M.Q. (1999). Enhancing the quality and credibility of qualitative 
analysis. Health Sciences Research, 34, 1189–1208 
● Petrov, H.T. (2018). Use of Virtual Reality in designing urban furniture. 
● Plask (2023). Ai-powered Mocap Animation tool. https://plask.ai/ (Accessed 
20 February 2023). 
● Pohl, B. (2019). “Virtual production: Stargate Studios creates final pixels on 
set”, Unreal Engine . [Online]. Available at: https://www.unrealengine.com/en-
US/spotlights/virtual-production-stargate-studios-creates-final-pixels-on-set 
(Accessed 20 February 2023). 
REFERENCES 
 
 
 
260 
● Polycam (2022). Polycam. Retrieved from https://poly.cam/ (Accessed 20 
February 2023). 
● Polycam Learn (2022). Polycam. Retrieved from https://learn.poly.cam/ 
(Accessed 20 February 2023). 
 
Q 
 
• QSR International (2021). Nvivo12. Retrieved from QSR 
International: https://www.qsrinternational.com/nvivo-qualitative-data-analysis-
software/about/nvivo. (Accessed 20 February 2023). 
 
R 
 
● Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M. 
and Sutskever, I. (2021). July. Zero-shot text-to-image generation. 
In International Conference on Machine Learning (pp. 8821-8831). PMLR.  
● Ramesh, A., Dhariwal, P., Nichol, A., Chu, C. and Chen, M. (2022). 
Hierarchical text-conditional image generation with clip latents. arXiv preprint 
arXiv:2204.06125. 
● Rayo, M.F., Pawar, C., Sanders, E.B.N., Liston, B.W. and Patterson, E.S. 
(2018). June. Participatory bullseye toolkit interview: Identifying physicians’ 
relative prioritization of decision factors when ordering radiologic imaging in a 
hospital setting. In Proceedings of the International Symposium on Human 
Factors and Ergonomics in Health Care (Vol. 7, No. 1, pp. 1-7). Sage CA: Los 
Angeles, CA: SAGE Publications 
● Rattay, S. (2019). Why Designers should read more Science Fiction. 
Medium.com. [Online] Availabe at: https://medium.com/swlh/why-designers-
should-read-more-science-fiction-5a186b8cc30a 
● Renée, V. (2015). Sundance Numbers in Independent Film. Retrieved 
November 22, 2015, from https://nofilmschool.com/2014/01/sundance-
infographic-numbers-in-independent-film 
REFERENCES 
 
 
 
261 
● Robertson, T., and Simonsen, J. (2012). Participatory Design: an 
introduction. In Routledge international handbook of participatory design (pp. 
1-17). Routledge 
● Robson C. (2002). Real World Research - A Resource for Social Scientists 
and Practitioner-Researchers, 2nd Edition, UK: Blackwell Publishers, Oxford. 
● Robson C. (2011). Real World Research, 3rd edn. Chichester: John Wiley 
and Sons. 
● Rogers, S. (2020). ‘Virtual production and the future of filmmaking - An 
interview with Ben Grossmann, Magnopus’, Forbes, 29 January [Online]. 
Available at: Virtual Production And The Future Of Filmmaking—An Interview 
with Ben Grossmann, Magnopus (forbes.com) (Accessed 20 February 2023). 
● Rohlfs, J. (1974). A theory of interdependent demand for a communications 
service. The Bell journal of economics and management science, pp.16-37 
● Rowley, J. (2014). Designing and using research 
questionnaires. Management research review 
● Ryan, M.L. (2009). From narrative games to playable stories: Toward a 
poetics of interactive narrative.  Storyworlds: A Journal of Narrative Studies, 1,  
(pp. 305-316) 43-59. 
 
S 
 
● Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., 
Ghasemipour, S.K.S., Ayan, B.K., Mahdavi, S.S., Lopes, R.G. and Salimans, 
T. (2022). Photorealistic Text-to-Image Diffusion Models with Deep Language 
Understanding. arXiv preprint arXiv:2205.11487. 
● Sanders, E.B.N. and Stappers, P.J., 2008. Co-creation and the new 
landscapes of design. Co-design, 4(1), pp.5-18. 
● Sanders, E.B.N., E. Brandt, and Binder, T. (2010). “A Framework for 
Organizing the Tools and Techniques of Participatory Design”. Proceedings of 
the 11th Biennial Participatory Design Conference. Sydney: ACM. 
REFERENCES 
 
 
 
262 
● Sanders, E.B.N. (2002). “From User-centered to Participatory Design 
Approaches.” In Design and the Social Sciences: Making Connections, edited 
by Frascara, Jorge, 1–8. Florida: CRC Press. 
● Sang, S. and Chandraker, M., 2020, August. Single-shot neural relighting and 
svbrdf estimation. In European Conference on Computer Vision (pp. 85-101). 
Springer, Cham 
● Satava, R.M. (1995). Medical applications of virtual reality. Journal of Medical 
Systems, 19(3), pp.275-280. 
● Schuler,D., and Namioka, A. (1993). Participatory Design: Principles and 
Practices 1st ed., CRC Press 
● Seymour, M. (2013). “Gravity: vfx that’s anything but down to earth”, fxguide . 
[Online]. Available at: 
https://www.fxguide.com/fxfeatured/gravity/?highlight=gravity (Accessed 20 
February 2023). 
● Seymour, M. (2018). Visual Disruptor. [podcast]Oct 2018. Available at: 
https://open.spotify.com/show/67MoECqWLs5wMTGzwk0yzp (Accessed 20 
February 2023).  
● Seymour, M. (2020a, March 4). Art of LED Wall Virtual Production, Part One: 
‘Lessons from the Mandalorian.’ Fxguide. 
https://www.fxguide.com/fxfeatured/art-of-ledwall-virtual-production-part-one-
lessons-from-the-mandalorian/ (Accessed 20 February 2023). 
● Seymour, M. (2020b, March 9). Art of (LED Wall) Virtual Production Sets, 
Part Two: ‘How you make one.’ Fxguide. 
https://www.fxguide.com/fxfeatured/art-of-ledwall-virtual-production-sets-part-
two-how-you-make-one/ (Accessed 20 February 2023). 
● Seymour, M. (2022, April 14). Heavenly Virtual Production.  Fxguide. 
https://www.fxguide.com/quicktakes/heavenly-virtual-production/ 
● SiteScape (2022). Retrieved from https://www.sitescape.ai/ 
● Sleeswijk Visser, F. (2009). Bringing the everyday life of people into design. 
● Slater, M., and Wilbur, S. (1997). A framework for immersive virtual 
environments (FIVE): Speculations on the role of presence in virtual 
environments. Presence, 6:603–616.  
REFERENCES 
 
 
 
263 
● Slingerland, G., Murray, M., Lukosch, S., McCarthy, J. and Brazier, F. 
(2022). Participatory Design Going Digital: Challenges and Opportunities for 
Distributed Place-Making. Computer Supported Cooperative Work (CSCW), 
pp.1 32 
● Ssozi-Mugarura, F., Blake, E. and Rivett, U. (2017). Codesigning with 
communities to support rural water management in Uganda. CoDesign, 13(2), 
pp.110-126 
● Spielberg, S. (2002). Minority Report. [Film]. 20th Century Fox. 
● Spielberg, S. (2018). Ready Player One. [Film]. Warner Bros. 
● Spielmann, S. (2018). VPET - Virtual production editing tools. ACM 
SIGGRAPH 2018 Emerging Technologies. Vancouver, Canada. 
● Spielmann, S., Trottnow, J., Helzle, V., Götz, K., Schuster, A., & Rohr, P. 
(2018). VPET - Virtual production editing tools. ACM SIGGRAPH 2018 
Emerging Technologies, SIGGRAPH 2018. 
https://doi.org/10.1145/3214907.3233760 
● Spinuzzi, C. (2005). The methodology of participatory design. Technical 
communication, 52(2), pp.163-174 
● Spirit Awards (2022). Film Independent. Retrieved from : 
https://www.filmindependent.org/spirit-awards/faq/ 
● Steam (2022). Steam Hardware and Software Survey: December 2022. 
https://store.steampowered.com/hwsurvey 
● Steen, M., Manschot, M. and De Koning, N. (2011). Benefits of co-design in 
service design projects. International Journal of Design, 5(2) 
● Stenum, J., Rossi, C. and Roemmich, R.T., 2021. Two-dimensional video-
based analysis of human gait using pose estimation. PLoS computational 
biology, 17(4), p.e1008935 
● Sterling, B. (2005). Shaping Things, Cambridge, MA: MIT Press 
● Sterling, B. (2013). Patently untrue: fleshy defibrillators and synchronised 
baseball are changing the future. Wired UK 
● Stickdorn, M. Schneider, J., Andrews, K., and Lawrence, A., (2011). This Is 
Service Design Thinking: Basics, Tools, Cases. Vol. 1. NJ: Wiley Hoboken. 
REFERENCES 
 
 
 
264 
● Strauss, W.A. (1991). Generations: the history of America’s future. Harper 
Perennial 
 
T 
 
● Tactivos Inc. (2022). Mural. Retrieved from Mural https://www.mural.co/ 
(Accessed 20 February 2023). 
● Tarantino Q. (1992). Reservoir Dogs [Film]. Miramax Films. 
● Thacker, J. (2012). “In Search of Virtual Production”, CG Channel . [Online]. 
Available at: http://www.cgchannel.com/2012/05/fmx-2012-in-search-of-
virtual-production/ (Accessed 20 February 2023). 
● The Third Floor Inc. (2020). Virtual Set Scouting | Virtual Visualization 
Series. YouTube. Available at: 
https://www.youtube.com/watch?v=i2hPyym0Q3U (Accessed 20 February 
2023). 
● Thomas, N. 2021. Innovative Thinking: Engineering Solutions. Architectural 
Design, 91(6), pp.30-37 
● Tovell, R., and Williams, N. (2018). Genesis: A pipeline for virtual production. 
Proceedings - DigiPro 2018: Digital Production Symposium, 1–5. 
https://doi.org/10.1145/3233085.3233090 
 
U 
 
● Unreal Engine (2018). “Virtual Production Roundtable Chat | Siggraph 2018 | 
Unreal Engine”. 25 Oct. 2018, Retrieved from: www.youtube.com/watch?v=r-
VjfI-kMi4. (Accessed 20 February 2023). 
● Unreal Engine (2019a)  “Behind the Scenes with UE4’s Next-Gen Virtual 
Production Tools | Project Spotlight | Unreal Engine.” YouTube, 12 Nov. 2019, 
www.youtube.com/watch?v=Hjb-AqMD-a4. (Accessed 20 February 2023). 
● Unreal Engine (2019b) “Solo: A Star Wars Story’ | Project Spotlight | Unreal 
Engine.” YouTube, 15 Feb. 2019, www.youtube.com/watch?v=iJStVptMqlw. 
(Accessed 20 February 2023). 
REFERENCES 
 
 
 
265 
● Unreal Engine (2019c). Cine Tracer - Cinematic Lighting with Emotion | 
SIGGRAPH 2019 | Unreal Engine. YouTube. Available at: 
https://www.youtube.com/watch?v=vjdSDuFS9DI (Accessed 20 February 
2023). 
● Unreal Engine (2022). “MetaHuman Creator.” Epic Games. 
https://www.unrealengine.com/en-US/metahuman-creator. (Accessed 20 
February 2023). 
 
V 
 
● van Rijn, H., and Stappers, P.J. (2008). October. Expressions of ownership: 
motivating users in a co-design process. In PDC (Vol. 8, pp. 178-81 
● Van Someren, M., Barnard, Y.F. and Sandberg, J. (1994). The think aloud 
method: a practical approach to modelling cognitive. London: 
AcademicPress, 11 
● Venkatesh, V., and Davis, F.D. (2000). A theoretical extension of the 
technology acceptance model: Four longitudinal field studies. Management 
science, 46(2), pp.186-204 
● Venkatesh, V., and Bala, H. (2008). Technology acceptance model 3 and a 
research agenda on interventions. Decision sciences, 39(2), pp.273-315 
● Villegas, R., Babaeizadeh, M., Kindermans, P.J., Moraldo, H., Zhang, H., 
Saffar, M.T., Castro, S., Kunze, J. and Erhan, D. (2022). Phenaki: Variable 
length video generation from open domain textual description. arXiv preprint 
arXiv:2210.02399 
● Vizrt 2022 https://www.vizrt.com/ 
 
W 
 
● Wang Y. (2015) Oriental cultural features for new product design 
development. PhD thesis, Brunel University London 
● Webster A. (2020). How Riot used tech from The Mandalorian o build Worlds’ 
astonishing Mixed Reality Stage. The Verge. [Online]. Available at: 
REFERENCES 
 
 
 
266 
https://www.theverge.com/2020/10/24/21529317/league-of-legends-world-
championship-high-tech-stage-riot-mandalorian (Accessed 20 February 
2023). 
● Weinberg, G. and Justin M. (2015). Traction: How any startup can achieve 
explosive customer growth. Penguin. 
● Weiss, A., Bernhaupt, R., Schwaiger, D., Altmaninger, M., Buchner, R. and 
Tscheligi, M., (2009). December. User experience evaluation with a wizard of 
oz approach: Technical and methodological considerations. In 2009 9th IEEE-
RAS International Conference on Humanoid Robots (pp. 303-308). IEEE. 
 
Y 
 
• Yadav, K., Ramrakhya, R., Ramakrishnan, S.K., Gervet, T., Turner, J., 
Gokaslan, A., Maestre, N., Chang, A.X., Batra, D., Savva, M. and Clegg, A.W. 
(2022). Habitat-matterport 3d semantics dataset. arXiv preprint 
arXiv:2210.05633. 
• Yu, R., Park, H. and Lee, J., 2021. Human dynamics from monocular video 
with dynamic camera movements. ACM Transactions on Graphics 
(TOG), 40(6), pp.1-14 
 
Z 
 
● Zhang, Z., Patricio, R., Carella, G. and Zurlo, F. (2022). Supporting a 
Sustainable and Engaging Online Transition for Co-Design through 
Gamification. Sustainability, 14(11), p.6716 
● Zhang, F., Hall, D., Xu, T., Boyle, S. and Bull, D. (2020). A simulation 
environment for drone cinematography. arXiv preprint arXiv:2010.01315. 
● Zimmer, C., Drochtert, D., Geiger, C., Brink, M., and Mütze, R. (2017). Mobile 
previsualization using augmented reality -A use case from film production. 
SIGGRAPH Asia 2017 Mobile Graphics and Interactive Applications, SA 
2017, 3–7. https://doi.org/10.1145/3132787.3132805 
 
REFERENCES 
 
 
 
267 
3 
 
• 
3dcreation_lyon (2021, Oct 18th) MONT ST MICHEL FRANCE Saint 
Michael’s Mount. Retrieved from Sketchfab: https://sketchfab.com/3d-
models/mont-st-michel-france-saint-michaels-mount-
1a871ac213f9473d9e865ddb39bdbb6a (Accessed 20 February 2023). 
 
 
 
 
 
 
268 
 
Appendix I – Diegetic Prototypes 
 
 
Story #1 – DEPERO 
 
Vincent is a set designer based in Liverpool while Martin is a cinematographer in 
Madrid. The two are working on their next short film and as usual they are using 
“DEPERO”. 
 
“DEPERO” is a virtual reality application commonly used by small teams of 
filmmakers during the pre-production phase to collaborate remotely and to carefully 
plan the shots. All the data are on the cloud and so accessible from everywhere and 
anytime if you are granted access to the project. Also, thanks to the advancements 
of 3D scanning technologies, is today possible to create a photorealistic digital 
replica of real-world locations both indoors and outdoors. 
 
The two are immersed within the digital replica of an old farmhouse situated in the 
middle of Andalusia. That’s the location where they are going to shoot some scenes 
in three months. The scan was already available on DEPERO’s “locations” and was 
considered the ideal setting for their short film. 
 
Using a controller, Vincenzo lift and reposition the virtual table in different positions 
to find the best spot. “Good, I think Chris will like it” says Martin. 
 
In that exact moment Chris, or better, its avatar shows up in the virtual location “Hi 
guys! Sorry for the delay”. Chris is the director of the short film and he’s currently 
connecting from London. 
 
“What a timing Chris, we were just talking about you…” says Martin and continue 
“…We were working on the dining scene, what do you think?”. 
 
Appendix I – Diegetic Prototypes 
 
 
 
269 
Chris presses a button on his controller to activate the viewfinder mode. He starts 
walking curiously around the dining room of this old farmhouse keeping the controller 
pointed like a camera, looking for the best angle from where to capture the scene. 
He starts experimenting with different virtual camera lenses that he can quickly 
switch. At some point he stops and locks mid-air the viewfinder saying “Well… I think 
that the 35mm would work. Martin, can you simulate a slow dolly movement from 
here?” “Sure thing” replies Martin. 
 
Martin moves towards the floating viewfinder and interact with it to select the 
“camera movements” mode. From this tab he can decide what camera movements 
to simulate. A virtual dolly appears in the scene and Martin starts simulating the 
camera movement requested by Chris. 
Chris looks at the result and quickly changes his mind “Wait, I got a different idea. 
What if we simulate a crane movement from outside the window for this shot? Let’s 
use the crane to slowly move the camera toward the window”. 
With the click of few buttons, Martin quickly makes the dolly disappear, teleports 
himself outside the room and place in the scene a seven-meters long crane and 
starts using it. “Lovely!” exclaims Chris “This is exactly what it’s needed for this shot”. 
 
Uncertain, Martin asks: “I like it too Chris, but wouldn’t be too expansive to rent a 
Crane?”. Chris replies “You’re right, but I’m sure that we can pitch to the Exec. 
Producer this new idea exporting a quick pre-viz draft from DEPERO. Hopefully that 
will justify the extra budget…I think this shot really adds something to the scene 
guys”. 
 
“Also, me and Martin were thinking about using diegetic lights to illuminate the 
scene, we were thinking about placing some candles here on the table” Vincent uses 
its controller to sketch in the space three different circles where he thinks would be 
better to place the candles. “Nice” exclaims Chris. Martin then selects “candles” from 
the “lighting” tab while Vincent materializes two dummies to place around the table. 
“Oh well, that’s a little bit too bright. Let’s go for just two candles then" says Chris 
Appendix I – Diegetic Prototypes 
 
 
 
270 
and concludes "Sorry guys but now I got to go, please share this with our new 
Producer Miriam to keep her posted. See you!" 
 
 
Figure I.1.0.1 Visual prompt for Story #1 - DEPERO 
 
 
Appendix I – Diegetic Prototypes 
 
 
 
271 
 
Story #2 – ALNINE  
 
6:30 AM. Hana’s alarm starts ringing to wake her up. 
“It’s going to be a long drive” she thinks “but I’m happy to direct such project…even if 
the budget isn't high”. 
Hana lives in the suburbs of Tokyo and is headed to the city of Fujiyoshida. This is in 
fact the chosen filming location for promoting the commercial of "National Dance 
Championships" taking place later that year. 
 
The script of the project Hana received from the creative agency it’s about a 
professional dancer performing some moves immersed in nature. All the scenes will 
be characterized by a unique background: the majestic mount Fuji. Also, in the script 
it’s indicated how different animals are going to interact and dance with the 
performer. More specifically butterflies, little birds and fireflies. 
 
Fifteen years ago such result could be achieved only through an advanced, long and 
expensive post-production process manually modelling, animating and compositing 
all these creatures in the live action footage. But since the introduction of “ALNINE” 
the making of digital visual effects changed radically. Thanks to the generative AI 
technology ALNINE combined to Augmented Reality, it is possible integrate in the 
real scene 2D and 3D elements in real-time. How? Just asking ALNINE to do so. 
 
Even if there is still space for improvement, most of the times is it possible to obtain 
the so-called “Final-pixel-in-camera” while shooting and so without dedicating much 
time in further finalizing the image in post-production. 
Today, almost every professional camera have ALNINE feature already 
integrated…like it was for the “autofocus” feature back in the days. For Hana and her 
team such technological solution enabled them to explore more creative ideas 
without the fear of adding VFX later in the process.  
 
As always Hana is the first one to arrive on set but after not much time, everyone 
Appendix I – Diegetic Prototypes 
 
 
 
272 
else shows up. 
After setting all the gear, Hana is closely observes the scene through her director 
monitor, giving indications to his Steadicam operator Hideo on how to move the 
camera in relation to the dancer. 
 
After some rehearsals Hana exclaims “Alright, let’s see now how we can integrate 
the creatures…ALNINE generate a butterfly with orange and black wings”. In a 
couple of seconds ALNINE is capable to analyze Hana’s voice input and generate 
the requested output. Thanks to its data set of millions of images and videos of 
butterflies and it’s complex Ultra Generative Adversarial Network (UGANs), it is able 
to create an original and never seen three-dimensional model of the animal. 
 
In an instant, both on Hana’s and Hideo’s respective monitors a static butterfly 
appears in the middle of the frame. “Do you want to animate this butterfly?” adds 
ALNINE. “I do. I want the butterfly to fly around the human subject” replies Hideo. 
“Sure, give me a moment to recognize the human body and track the 
environment….done” The butterfly starts animating. The dancer makes few steps 
forward and the little animal follows her smoothly. “Good. Now let’s try with five 
butterflies, maybe two-thirds of the current size…mmm…also I want the orange to be 
more reddish on the wings…nice I like it, we can start recording a first clip…Hideo 
you ready?” “Rolling” “aaaaaand action!”.  
 
Observing the scene in the backstage, the Art Director is astonished by the 
seamless integration of the virtual butterflies in the shot. Sometimes he’s confused 
when alternating his view from the monitor to the real scene and not seeing the 
butterflies around the dancer. Thanks to the “Final-pixel-in-camera” process, the Art 
Director can look at the final result and so it’s easy to give its approval to Hana on 
the current scene and move to the next one. Perhaps they will finish shooting before 
the sunset and enjoy the amazing view. 
 
Appendix I – Diegetic Prototypes 
 
 
 
273 
 
Figure I.1.0.2 Visual prompt for Story #2 - ALNINE 
 
 
 
 
 
Appendix I – Diegetic Prototypes 
 
 
 
274 
Story # 3 - OSMOS 
 
 
Alfonso, early-twenties, is a video editor living in a small apartment in the centre of a 
vibrant city.  
As usual, he loves to start the working day making his own coffee. At some point a 
notification sound comes from a pair of glasses on the dining table. The notification 
sound is followed by a voice assistant saying “Jenna just sent you a vocal message”. 
Jenna is a film Director in her early thirties, working mainly on music videos and 
fashion web contents. Alfonso turns toward the glasses saying: “play message” and 
Jenna’s message starts “Hi dear, we completed the LAST shot of the LAST scene of 
David’s new single…we finished yesterday at 11PM…how exhausting! Anyway, you 
got all the clips on the shared Cloud folder. Take look and hit me up when you feel 
confident with the first edit. Take care!” 
 
Alfonso downs the remaining coffee, put the mug in the sink, seats at the table and 
wears his Osmos 3 smart glasses.  
 
In the last years, Osmos devices became the standard device both in workplaces 
and daily lives of people, replacing2D screens. These smart glasses are capable to 
offer both Augmented Reality and Virtual Reality functionalities combined to 
advanced features such as ultra-high display resolution, eye-tracking, hand-tracking, 
6G cloud connectivity and Brilliant AI just to name a few. All in a lightweight form 
factor. “Editing rooms” filled desks, bulky 2D monitors, PCs cases, mouses, 
keyboards, hard drives and wires, are a memory of the past. Something Alfonso 
never had to deal with. 
 
Once he put on the glasses, a number of tabs elegantly appears all around Alfonso. 
He starts rearranging them and adding new ones to start working on Jenna’s project. 
He starts working in the “AR mode” and so he can still see the real environment. 
Alfonso uses gestures such as opening his fist to open folders or use voice 
commands to quickly navigate through the file directory and retrieve all the various 
Appendix I – Diegetic Prototypes 
 
 
 
275 
clips.  
 
When watching the footage, every time he finds something interesting and that might 
use in the final edit, he pitches with his fingers that specific clip creating a timestamp 
that he will be able to quickly retrieve later. 
 
After some hours, Alfonso thinks to have identified all the clips he needed to start the 
actual editing of the music video.  
Time for a break before the next phase. Here’s where the real creative process 
begins, here’s when it’s time to “enter the zone”. 
 
Alfonso stands up and proceeds to the living room where there is more free space 
around him. It feels good to do some movement after being seated all that time. He 
then pronounce “switch to VR” and the glasses switch instantly to the “VR mode” 
where the real world fades out leaving space to only the main clips selected and the 
virtual environment in the background. Since David produces electronic music, 
Alfonso decides to go for a cybernetic setting and select as background an 
environment similar to the one portrayed in the movie “Tron”. It’s now time to create. 
Alfonso starts playing David’s track at high volume and starts grabbing clips, 
manipulating them, applying effects, distortions, filters….From outside VR, Alfonso 
looks like an orchestral director, rapidly moving his hands around, making elegant 
gestures and sometimes performing little dance moves. “I’m so convinced that this 
thing of immersing yourselves and visualizing and interacting with 2D footage leads 
you to explore and iterate different creative ideas” said Jenna once after one of the 
first projects together. 
 
Time passes and Alfonso is quite satisfied with this first edit. He switches to AR 
mode while going back to the dinning table, turns the music down and makes the 
final adjustments before sending this “work in progress” to Jenna for feedback. 
 
Appendix I – Diegetic Prototypes 
 
 
 
276 
 
Figure I.1.0.3 Visual prompt for Story #3 - OSMOS 
 
 
 
 
 
277 
Appendix II – Online Questionnaire 
 
Appendix II – Online Questionnaire 
 
 
 
278 
Appendix II – Online Questionnaire 
 
 
 
279 
Appendix II – Online Questionnaire 
 
 
 
280 
Appendix II – Online Questionnaire 
 
 
 
281 
Appendix II – Online Questionnaire 
 
 
 
282 
Appendix II – Online Questionnaire 
 
 
 
283 
Appendix II – Online Questionnaire 
 
 
 
284 
Appendix II – Online Questionnaire 
 
 
 
285 
Appendix II – Online Questionnaire 
 
 
 
286 
Appendix II – Online Questionnaire 
 
 
 
287 
Appendix II – Online Questionnaire 
 
 
 
288 
Appendix II – Online Questionnaire 
 
 
 
289 
Appendix II – Online Questionnaire 
 
 
 
290 
Appendix II – Online Questionnaire 
 
 
 
291 
Appendix II – Online Questionnaire 
 
 
 
292 
Appendix II – Online Questionnaire 
 
 
 
293 
Appendix II – Online Questionnaire 
 
 
 
294 
Appendix II – Online Questionnaire 
 
 
 
295 
Appendix II – Online Questionnaire 
 
 
 
296 
Appendix II – Online Questionnaire 
 
 
 
297 
Appendix II – Online Questionnaire 
 
 
 
298 
 
Thi  c
e
 i  ei he  c ea ed 
 e d
ed b  Mic
f . The da a 
 
b
i  ill be e
 
 he f
e .
Mic
f  F
T  I
 a
 B
!
O
 
 
 
 
 
 
 
 
 
 
. I  
 
 
 
 
 
 
 
 
  B
 U
 
, 
 
 
 
 
 
 @
 
. T
 
 
 
 
 20 
, 
 
 
 
 
  
 
 
 
!
31
Appendix II – Online Questionnaire 
 
 
 
299 
ANSWERS TO Story #2 AND Story #3 
 
Q16 - Considering ALNINE's specific features, select which are "Must have", "Nice to 
have" or "Not necessary" 
 
Q17 - Compared with the current production workflow of the sector of the audiovisual 
industry where you are working in the most... 
 
 
 
 
Appendix II – Online Questionnaire 
 
 
 
300 
 
 
 
 
 
 
 
Q18 – Also… 
 
Q19 - After reading this story, in your opinion, what is something that may stop you 
from adopting ALNINE ? 
 
Some glitches due to the preset animation  
It seems super cool. Maybe the fact that you record live, you cannot change 
the model of the recreated elements later.  
Since I'm not using vfx a lot, I think that cameras may be more expensive to 
have a app integrated which will be useless for me. 
The usual agency and client workflow 
Other connections 
The same of the previous story 
A too complicated interface / software that i could not handle or test myself  
Difficulty in use 
Don't know 
The Price 
Appendix II – Online Questionnaire 
 
 
 
301 
An integration that still seems very difficult to make work (see voice assistants 
still very inefficient), but if the technologies will make it work as told it is very 
promising! 
Nothing 
Sector of industry I'm working with, relying on what's happening for real in front 
of the camera rather than fiction/generating specific scenarios.  
Nothing, from a production point of view. It more depends on the director. 
How realistic ALNINE can compose visual 
Nothing - I would encourage its use 
Cost,  
Pricing 
Same as before, price maybe for Mexico standards. 
The need to have a fast and easy Interaction Design, the ability to change the 
path, shape and any other kind of movement and speed of the 3D generated  
Not too in line with what i do 
Reliability and such technology causing us to slowdown versus the current 
method of just recording camera & movement metadata for handoff to a VFX 
team and the Director doing their job of getting the talent to imagine what will 
be happening in post, which this tech still wouldn't help with unfortunately. 
  
Q20 - After reading this story, in your opinion, what additional features would you like 
to have when using ALNINE ?  
 
It seems alright to me 
Maybe the chance to have a kind of “raw file” of the created elements that you can 
play a bit around after the shoot, like changing colors, fine tuning animation… 
It would be great being able to create some elements with a unique design with 
ALNINE, just talking with it and seeing the result in real time 
I think tracking models can be usefull for those who use vfx in their videos 
Budget control 
Appendix II – Online Questionnaire 
 
 
 
302 
An Ai that give you hints to improve the shot and give you the info of the species, 
in this case of the butterflies, if you want shoot someting real. For example, give 
you the real butterflies that lives on mt. Fuji 
Exporting both final real-time composition and the real footages Then it must also 
provide the alpha channel. 
Don't know 
The possibility to create a preview/pitch of the shot before going on location 
It already looks a lot like that! 
Meets for a team work 
Available library of different options when generating an animal/image? Also "path 
control" for the virtual animals. 
Layer replacement in post production work 
Sound design  
Seems already very complete 
None 
None 
Backup RWA image storage without the ALNINE intervention, behavioral setting, 
pre-production 3D modeling capabilities and behavioral checking to upload on the 
cloud 
Some way of the talent understanding were they should be looking or reacting in a 
virtual space, at the moment thats done by either a tennis ball on the end of a stick 
or a green mockup of something that will later be animated. 
  
 
 
Appendix II – Online Questionnaire 
 
 
 
303 
Q21 - Considering OSMOS 3's specific features, select which are "Must have", "Nice 
to have" or "Not necessary"
 
Q22 - Compared with the current post-production workflow of the sector of the 
audiovisual industry where you are working in the most...
 
Appendix II – Online Questionnaire 
 
 
 
304 
Q23 – Also..
 
Q24 - After reading this story, in your opinion, what is something that may stop you 
from adopting OSMOS 3 ? 
 
Just some fears of headache from the VR mode, but I'll definitely try it 
I dunno as I am not really involved on the editing that much, it is really hard for me 
to figure it out  
I think I can get distracted even in an immersive vr environment. I feel I can have 
the same results in the real world. 
Editing is already stressing our eyes. I dont think we need an immersive virtual 
workspace to make our work better. It's just not my cup of the... 
Relations with other members project 
Always the usabilty  
making a process faster and more approximative does not necessarily translate in 
higher quality output 
cost 
Don't know 
The Price 
certainly the ergonomic part is essential, wearing a viewer for many hours should 
not weigh down a traditional procedure. The resolution and the computing power 
will have to be up to par, as well as the imput tools. Find ways to replace a 
keyboard and mouse without losing their convenience and speed. 
Nothing 
Appendix II – Online Questionnaire 
 
 
 
305 
Probably the VR mode. AR mode feels a good in between but VR would feel quite 
daunting as being completely immersive.  
It only need to be very easy to use - otherwise this would bring me to say "let's go 
back to my computer". If very well constructed, if dynamic, if easy to use - I would 
use it right away! 
gesture fatique cause by hand movement within normal space. 
The potential damage that this technology could have on our eyes health  
Having been an editor, I understand the importance of getting up and moving 
around while working is key, I honestly don't believe editors want to be wearing 
something on their face and having to use their hands and arms so much to edit -- 
it could be tiring. The ease of sitting at a desk and just having to use one finger to 
click a mouse while resting your arm is fine. Though I believe the strain on the 
eyes of looking a big monitor all day is something that needs to be amended, I just 
don't think a eye piece device is going to be an industry norm anytime soon. I 
mean look what happened with Google Glass. Also editing stations don't take up a 
ton of space and can be quite compact even if you're in a tiny apartment. This just 
seems like a very drastic change in workflow and would take an editor a lot of time 
to get used. 
The huge frustation when a complex precision technology doesn't work as well as I 
hope, it happens with Premiere too. OSMOS 3 seems to make it even more 
complex. 
Money 
I'd need to know what the workflow is like, how well it handles camera formats, 
how well it can export files to other production software for audio or colour 
engineering. 
 
Q25 - After reading this story, in your opinion, what additional features would you like 
to have when using OSMOS 3 ? 
 
I dunno as I am not really involved on the editing that much, it is really hard for me 
to figure it out  
Interactivities with all crew 
Appendix II – Online Questionnaire 
 
 
 
306 
Ai that suggests the best shot to use  
it should be more of a "first feels pass" than a editing software. it feels like this 
could add a new step in the workflow, taken out of an editing software.  
For me it will be impossible to mange this virtual studio honestly. I have to touch 
my devices materially 
Don't know 
I would be interested in understand how the storage of the footage, and how to 
change it in terms of codecs, formats etc. 
The possibility of having a viewer not in direct contact with the face to reduce the 
burden of prolonged use. A lot of resolution so as to reach reality. 
Meeting rooms for the team 
I would say collaborative mode, with different team members entering the VR 
mode. Basically for Jenna and Alfonso to discuss feedback directly immersed in 
the edit.  
Possibility to work together in the same virtual space - but maybe it already has 
this option. Both as editor mode or viewer mode. So the editor can work with the 
director or colorist but maybe the client, when connected, can only be viewer! 
simulated weight on hand to reduce gesture fatique 
A notification that alerts you when you’ve been using the glasses for too long 
I could see this being a useful device for 'editing on the go'. For instance if you 
don't have the luxury to edit in your home or an edit suit/office -- i.e. if you need to 
get some editing done while traveling/while on the go, while in a taxi / Uber, on a 
plane, etc. 
The space required to implement the tech on a small office. 
A mouse or tracking gloves, AI that understands not only your movement but also 
your next intention 
Strong intergration with other existing industry tools like Davinci Resolve, Pro 
Tools and Nuke so that collaboration is seemless. 
 
 
 
 
 
 
307 
Appendix III – User Testing Procedure  
User Testing Study - Overview 
Objective 
 
1) Collect feedback about the degree of usability and ease of use of the 
immersive pre-production workflow proposed.   
Sample Size and Description 
 
• 29 participants divided into 11 groups 
• Each group is formed by stakeholders of the audiovisual industry covering 
different roles (Director, Producer, Director of Photography…) and working 
on small and medium productions.  
• Because participants are professionals working in the industry who’s time 
and knowledge is extremely valuable, they are gifted with a 50£/€ Amazon 
voucher. 
Duration 
 
120 minutes including: 
• 5 min break after 40 min (Introduction + AR activity + VR activity 2.0) 
• 5 min break after 25 min (VR activity 2.1) 
• 5 min break after 15 min (VR activity 2.2) 
Researcher 
 
Aimone Bodini (Brunel 
University) 
 
Moderating the study 
• Assessing participants feedback 
• Conducting the survey 
• Controlling time 
• Ensuring users feel supported and 
understood 
• Demonstrating VR/AR tasks for the 
participant 
• Safety control of the study 
Appendix III – User Testing Procedure  
 
 
 
308 
• Monitoring the work status of all 
devices 
Equipment 
 
• VR headset and controllers 
(Meta Quest 2) 
• Laptop 
• Smartphone  
• Video cameras 
• Audio recording equipment 
• Tablet 
Data Capture 
 
• Video recording of participants as they interact with the hardware and 
content 
• Audio recording of participant comments in response to hardware, content 
and interview 
• Screen recording of VR content 
Covid Measures 
To mitigate covid spread, it will required to participants to sanitize their hands 
before and after the session. Sanitizer will be provided by the researcher. 
In addition, all the equipment that will be used (controllers, VR headset,  iPad…) 
will be properly sanitized using wraps. Wraps will be provided by the researcher. 
Also, window will be kept open for a better air circulation in the room. 
Researcher will take a covid-19 test 48 hours prior each session. 
Location 
On-campus and Off-campus, in UK and Italy. Further details can be found in the 
“Risk Assessment form” document. 
 
Study Procedure 
Set-Up  
• 
Make sure you have consent form for participant 
• 
Check iPad Pro 2020 
• 
Check Meta Quest 2 headset and controllers  
Appendix III – User Testing Procedure  
 
 
 
309 
• 
Check video camera setup for  recording  
• 
Check microphone setup for recording   
General Introduction 
5 min 
Thank you for agreeing to participate in this study. Throughout this session I will be 
reading from a script to ensure that I give identical instructions to all participants. 
As a participant in this study, you will execute a number of tasks using an app called 
Polycam and one called Gravity Sketch. I will guide you and observe you as you 
interact with these immersive software applications. Afterwards, I will interview you 
about your experience. Finally, I will ask you to fill out a short questionnaire. This 
session will be recorded with a camera and a microphone and your data will be 
anonymized. 
Consent Form  
Before we begin, I will go over important information about the study with you. Your 
participation in this study in is voluntary and you are free to stop at any time. The 
risks of participating are minimal. At any point during this session you are free to ask 
me questions.  
 
Here is information about the study you can review and keep. Take as much time to 
read over it as you need and let me know if you have any questions or when you are 
ready to begin.  
[After receiving back the consent form signed by participants] 
Now, throughout the session, I will also be the Wizard, capable to give you the 
illusion of some additional features that do not actually exist within these software 
because of their current limitations. If you maintain this suspension of disbelief during 
the session, it will help us to further extend the discussion. 
 
Appendix III – User Testing Procedure  
 
 
 
310 
 Polycam – iPad Pro 
15 min 
 
INTRODUCTION & DEMONSTRATION (5 mins) 
To use Polycam, you will need to use the iPad Pro 2020. This device integrated a 
LiDAR scanner capable to capture geospatial data of the surrounding space and so, 
thanks to a software such as Polycam, to create a 3D object of the same space. 
Facilitator Demonstration 
i. 
You use the iPad Pro by holding the device in your hands. 
ii. 
To start scanning you have to tap on the record button.  
iii. 
Then you can point iPad Pro’s camera around the room to scan the 
surrounding. You will see little triangles forming meaning that you are 
capturing data. For a better output, you should scan all the blue areas 
as shown by the software. 
iv. 
Once the area is scanned, you can tap on  the red “stop” button 
v. 
Tap the “process” button. 
vi. 
Now you can observe the so called the 3D textured mesh of  scan. 
vii. 
Now you can upload on the cloud your scan tapping the  upload button 
STUDY PORTION – Polycam (10 mins) 
Task Instructions 
While you are using the iPad, I will be sit here and I’ll assist and observe you while 
you use Polycam. I’m now going to ask you to perform a scan of the space around 
us. 
Please remember to think aloud while you are performing the tasks. 
1.1 Hold the iPad Pro with your hands. [Hand over iPad] 
1.2 Tap on the “record button” icon 
1.3 You can now scan the room moving the iPad Pro around capturing the room 
from different perspectives. Try to cover all the blue area. 
1.4 You can now tap on the “stop” red button. 
1.5 Tap the “process” button. 
1.6 Now observe and interact with your capture on the 2D display of the iPad. 
1.7 Tap now on the “upload” button to sync the capture on the cloud. 
 
Appendix III – User Testing Procedure  
 
 
 
311 
• 
[Hands back iPad Pro 2020] 
Do you have any questions? 
Use of the “Wizard of Oz” method….the capture is magically imported into the VR 
software “Gravity Sketch” which will be used of the next activity. 
 
 
 Gravity Sketch – Meta Quest 2 
80 min 
 
INTRODUCTION & DEMONSTRATION - Gravity Sketch (20 min) 
To use Gravity Sketch, you will need to use the Meta Quest 2. You use the Meta 
Quest 2 by putting on that headset and holding those controllers.  
While you are using the Meta Quest 2, I will be use another one too and I’ll be 
present in the same virtual environment with you to guide and observe you. I will be 
observing how you use Gravity Sketch. I will ask you to perform several tasks using 
this software. 
First I will briefly explain you how to use the Meta Quest 2 controllers 
[Facilitator explain buttons and triggers to participants]  
I’m now going to give you a quick demonstration on Gravity Sketch functionalities to 
plan your pre-production phase but first I ask you to wear the headsets. 
 
[Facilitator gives headset#1, #2 and #3 to participants]  
How to wear Meta Quest 2 
After you get the headset on, I will explain you how to adjust the: 
• 
Head placement 
• 
Head straps 
• 
Eye lenses 
• 
Play area limited by Guardian 
Let me know when you are ready to begin, or if you have any questions.  
Facilitator Demonstration 
2.0 Virtual Location: La Casa Gassia (Interior) 
 
Pre-production activities 
Appendix III – User Testing Procedure  
 
 
 
312 
• General assessment of the location (*) 
• Import real photos of location 
• Import Google Maps location 
• Assess lights to remove 
• Assess set design elements to replace  
• Import props (softbox light)  (*) 
• Import puppet characters (*) 
• You can think about the lighting (Wizard of Oz) 
• We can now simulate a static shot 
• We can now simulate the crane movement (Wizard of Oz) 
• We can select the “tape” measures (*) 
• Day & Night  (*) (Wizard of Oz) 
• Sunlight position in a specific location given a specific date and time  (*) 
(Wizard of Oz) 
• Budgeting chart updated in real-time depending on what elements are added 
(props, light equipment, camera equipment…) (*) (Wizard of Oz) 
• You can now tap on “Export screenshots” 
 
* Activity suggested by participants who responded to the previous questionnaire 
 
 
[Hands back all headsets] 
Do you have any questions? 
 
Break (5 mins) 
Feel free to take off the headset and take a break. On the table you can find some 
water bottles. 
[…] 
All right, let’s jump back in VR 
 
STUDY PORTION – Gravity Sketch (40 mins total ) 
Now is your turn! 
Appendix III – User Testing Procedure  
 
 
 
313 
Please remember to think out loud as you perform these tasks and to communicate 
with your collaborators. I will be with you in the virtual environment in the case you 
don’t remember how to access and use certain tools. 
 
2.1 Virtual Location: Stairs (Interior) (20 min) 
Basic interactions 
2.1.1 
Look at your hands to see the different icons  
2.1.2 
Press the rear trigger on your right hand to draw  
2.1.3 
Place your controller inside the drawing and then press and hold the 
lateral trigger on your right controller to grab the drawing and reposition it in 
space 
2.1.4 
Press the blue menu button icon on your left controller to open the 
menu and import the 3D asset named “stairs”. 
2.1.5 
Repeat the process and now import its texture. 
2.1.6 
Navigate the directory to select the matching texture for the location 
2.1.7 
Apply texture using your controller’s buttons 
2.1.8 
Scale Location 
2.1.9 
Navigate/Teleport across location using the banana pointer 
 
Pre-production activities 
[Facilitator imports Script in the scene] “Now let’s read the script” 
 
Script prompt “In this scene Alex is walking down the stairs when he finds that his 
gang is waiting for him in the lobby of the building. It’s a surprise for Alex and asks 
them to what he owes the pleasure. After some silence, the gang sarcastically 
informs Alex on how things have changes lately due to Alex’s absence in the last 
days and so on how he’s not going to be the leader anymore. The conversation they 
are having seems calm with  smiles an sarcasm but underneath there is palpable 
tension growing between them. 
 
Set design prompts: “The lobby is dirty, trash is everywhere on the ground and the 
painting on the wall is vandalized with graffiti. In addition, there are two chairs” 
Appendix III – User Testing Procedure  
 
 
 
314 
Asses the location (*) as it is now (empty, no imported assets). [If needed Facilitators 
prompt them…”What do you think about the colour of the walls? About the light 
source?....] 
Now I will give you different tasks  
2.1.10 
Participant X Import props (garbage, chairs…)(*) 
2.1.11 
Participant Y Import puppet characters (*) 
2.1.12 
Participant Z Import reference images (painting) 
2.1.13 
Participant Z Take the measure on the wall in order to have the 
painting 2meters high (*) 
2.1.14 
Participant Z Scale the painting accordingly 
2.1.15 
Participant Y Apply the texture to the puppets 
2.1.16 
Participant X Apply texture on the objects 
2.1.17 
Participant XYZ Vandalize the painting with graffiti using your drawing 
tool with your right controller. 
[Meanwhile Facilitator fill the scene importing other assets if needed to make the 
process smoother and quicker] 
2.1.18 
We can now simulate a static shot pressing the purple icon on our left 
controller and selecting the “view points” tool. 
2.1.19 
Now we can move around choosing the right angle to convey the 
tension we have in this scene. 
2.1.20 
You can ask the wizard to change the time of day from Day to Night  (*) 
(Wizard of Oz) 
2.1.21 
You can now tap on “Export screenshots” 
• 
 
* Activity suggested by participants who responded to the previous 
questionnaire 
[Facilitator saves the sketch did by the group. “Save as”  02_groupX] 
• 
 
Break (5 mins) 
Feel free to take off the headset and take a break. On the table you can find some 
snacks. 
Also, take a look at this video:  
Appendix III – User Testing Procedure  
 
 
 
315 
 
[Facilitator show “Clockwork Orange” scene] 
If you feel ready, we can start the last activity wearing once again the VR headset. 
 
2.2 Virtual Location: Mont-Saint-Michael (Exterior) (20 min) 
Script prompt:  
The regional committee of tourism of Normandy asks you to promote a landmark 
such as Mont-Saint-Michael. They specifically ask you to make a spectacular long 
take shot with a drone. Plan your flight.  
• 
Now I will teleport you to the location and import for you a 3D drone in 
the scene. 
 
2.2.1 
Now discuss and draw the drone flight path you want to achieve. To 
draw the path, remember to use the “brush” tool 
2.2.2 
You can take notes what camera angle you want at each moment. 
2.2.3 
You can take notes on the drone speed. 
2.2.4 
Now switch on the “passthrough” feature to have a mixed reality 
viewing experience. 
[Facilitator saves the sketch did by the group] 
Also, take a look at this video:  
 
[Facilitator show reference video] 
 
Break (5 mins) 
Feel free to take off the headset and take a break. 
[…] 
Now, we are about to start a group discussion and talk about what you have done in 
the previous activity. If you like, we can jump back in VR and discuss in the virtual 
environment. Alternatively, we can have the group discussion in the traditional way 
around the table. 
[Facilitator saves the sketch did by the group. “Save as”  03_groupX] 
 
Appendix III – User Testing Procedure  
 
 
 
316 
Group Discussion  / Post Study (30 mins) 
We can now proceed to the interview portion of the study.  
[Main questions in bold, eventual sub-questions italic] 
OVERALL FEEDBACK 
Q.1 
How was your overall experience of the workflow? 
LOCATION SCOUTING & VISUAL REPRESENTATION 
Q.2 
How was the experience of being immersed in the location where you 
are going to shoot? 
Q.2.1 sub-question: How was the experience of navigating around the environment?  
Q.2.2 sub-question: How visually realistic did you find the experience?  
Q.2.3 sub-question: Is photorealism a deal-breaker? 
Q.2.4 sub-question: Do you think that doing location scouting physically is still 
needed in the pre-production phase? 
COMMUNICATION AND COLLABORATION 
Q.3 
How did you find communicating your ideas with the other participants 
in the virtual environment? 
 
Q.4 
How did you find collaborating at the same time with the other 
participants in the same virtual environment?  
INTERFACE AND INTERACTIONS 
Q.5 
How did you find interacting with the interface proposed? 
 
Q.6 
What did you find most difficult when interacting with the 
interface?  
 
Q 6.1 sub-question: Do you think it could have been easier to use your hands 
rather than the controllers to interact with the virtual interface? 
INTENTION TO USE THE PURPOSED WORKFLOW 
Q.7 
Would you use this exact workflow presented in a real-world scenario? 
Why or why not?  
Q.8 
What would you stop from using this workflow? 
 
Appendix III – User Testing Procedure  
 
 
 
317 
Q.8.1 sub-question: How much did you enjoy working in a virtual 
environment?  
Q.8.2 sub-question: What did you enjoy the most about this experience? 
 
ECONOMICAL ASPECT 
Q.9 
Do you think this workflow may be helpful in saving time and 
therefore money? How? 
Q.9.1 sub-question: How much are you willing to pay for a service offering a 
similar workflow (hardware and software)? 
 
EXTRA QUESTIONS 
Q.10 
Was there anything you wanted to do while planning your production 
that you were unable to do?  
Q.11 
How the purposed virtual pre-production workflow compare to the 
traditional pre-production?  
Follow-up Question:  
• Could you tell me more about …?  
 
 
Appendix III – User Testing Procedure  
 
 
 
318 
Thank you for answering all the questions. For the final part of this study, could you 
please fill out this questionnaire? 
[Get hard copies out, and hand them to participants]  
 
Questionnaire  (5 mins) 
Based on the experience you just had, for each statement, place a mark in the cell 
that best reflects how much you agree with each statement.   
 
Perceived Usefulness 
 
Compared with the current pre-production workflow you are experiencing in the AV 
industry, the proposed pre-production workflow... 
 
 
Strongly 
Disagree 
Disagree Neutral Agree 
Strongly 
Agree 
...may facilitate communication 
with other collaborators 
 
 
 
 
 
...may lead to explore more 
creative opportunities 
 
 
 
 
 
...may be more helpful in the 
decision making process 
 
 
 
 
 
...may be more helpful when 
pitching ideas asking for fundings 
 
 
 
 
 
...may reduce filmmakers' 
ecological footprint (travelling, 
energy consumption...) 
 
 
 
 
 
...may improve filmmakers' well-
being (mental health, safety, 
inclusivity, equity...) 
 
 
 
 
 
 
Perceived Ease of Use 
 
Appendix III – User Testing Procedure  
 
 
 
319 
 
Strongly 
Disagree 
Disagree Neutral Agree 
Strongly 
Agree 
Learning to use the proposed 
workflow may be easy for me 
 
 
 
 
 
It would be easy for me to become 
skilful at adopting the proposed 
workflow 
 
 
 
 
 
My interaction with the proposed 
workflow would be clear and 
understandable 
 
 
 
 
 
 
Wrap-up (5 mins) 
• 
Thank participants for coming in  
 
 
 
 
 
320 
Appendix IV – Ethical approvals and participant 
information sheets 
 
 
 
Participant Information Sheet for undertaking research 
Study title 
Virtual Production in Audiovisual Industry 
Invitation Paragraph 
You are being asked to take part in a research study. Before you decide, it is 
important for you to understand why the research is being done and what it will 
involve. Please take time to read the following information carefully and discuss it 
with others if you wish. Ask me/us if there is anything that is not clear or if you would 
like more information. Take time to decide whether or not you wish to take part. 
Thank you for reading this. 
 
What is the purpose of the study? 
 
The aim of this observation is to understand how immersive technologies (Virtual 
and Augmented Reality) can be employed and exploited in the pre-production phase 
of an audiovisual-production. 
Why have I been invited to participate? 
You are considered by the researcher as a potential stakeholder or expert of the 
subject of the study. 
Do I have to take part? 
It is up to you to decide whether or not to take part. If you do decide to take part you 
will be given this information sheet to keep and be asked to sign a consent form 
indicating your willingness to be involved. If you decide to take part you are still free 
to withdraw up until one week after the interview time without giving a reason. 
What will happen to me if I take part? 
Appendix IV – Ethical approvals and participant information sheets  
 
 
 
321 
You will be invited to share your experiences and comments about; 1.) the actual 
pre-production process with an emphasis on location scouting 2.) your knowledge of 
immersive and real-time technologies in terms of functioning and opportunities. 
Are there any lifestyle restrictions?  
There are no lifestyle restrictions 
What are the possible disadvantages and risks of taking part? 
 
There are no anticipated disadvantages or risks associated with taking part in this 
study. 
What are the possible benefits of taking part?  
The results of this study will be used as a part of my PhD research to better 
understand how Virtual and Augmented Reality could be exploited to solve everyday 
challenges when doing location scouting and approaching pre-production in the AV 
industry. 
 
What if something goes wrong? 
The person to be contacted if the participant wishes to complain about the 
experience should be the Chair of the relevant Research Ethics Committee 
Will my taking part in this study be kept confidential? 
All information that is collected from you during this research will be kept strictly 
confidential and anonymized.  
Will I be recorded, and how will the recording be used? 
Audio of the interview will be recorded using specific computer software. 
It will be kept confidential and stored on university devices until the end of study. 
What will happen to the results of the research study? 
The research findings will be communicated to designers and researchers wanting to 
gain insights into engaging the public with Virtual Production and issues related to 
that. 
Who is organising and funding the research? 
The research is organized and funded by the “StoryFutures” initiative. 
What are the indemnity arrangements? 
Appendix IV – Ethical approvals and participant information sheets  
 
 
 
322 
Brunel University London provides appropriate insurance cover for research which 
has received ethical approval. 
Who has reviewed the study? 
The study has been reviewed by Professor Hua Zhao 
Research Integrity 
Brunel University London is committed to compliance with the Universities UK Research 
Integrity Concordat. You are entitled to expect the highest level of integrity from the 
researchers during the course of this research 
 
Thank you for acknowledging the Participant Information Sheet. 
Contact for further information and complaints 
Researcher name and details: 
Aimone Luca Bodini. If you have any queries about this research please contact –
Aimone Luca Bodini: PhD Researcher, Brunel University, Uxbridge, UB8 3PH; E-
mail aimone.bodini@brunel.ac.uk 
Supervisor name and details:   
Dr. Vanja Garaj. Head of Design,  Brunel University, Uxbridge, UB8 3PH; E-mail 
vanja.garaj@brunel.ac.uk 
For complaints, Chair of the Research Ethics Committee:  
College of Engineering, Design and Physical Sciences Research Ethics Committee 
Chair – Professor Hua Zhao (Hua.Zhao@brunel.ac.uk) 
 
 
 
 
 
 
 
 
 
Appendix IV – Ethical approvals and participant information sheets  
 
 
 
323 
1. Ethical approval for undertaking Exploratory Interviews 
 
 
Appendix IV – Ethical approvals and participant information sheets  
 
 
 
324 
 
 
Appendix IV – Ethical approvals and participant information sheets  
 
 
 
325 
2. Ethical approval for undertaking Online Workshops
 
Appendix IV – Ethical approvals and participant information sheets  
 
 
 
326 
3. Ethical approval for undertaking Online Questionnaire
 
Appendix IV – Ethical approvals and participant information sheets  
 
 
 
327 
 
 
 
Appendix IV – Ethical approvals and participant information sheets  
 
 
 
328 
4. Ethical approval for undertaking in-person User Testing 
 
Appendix IV – Ethical approvals and participant information sheets  
 
 
 
329 
 
5. Ethical approval for undertaking drone experiment 
 
 
 
 
 
7 
 
Person(s) completing this assessment: 
(Person carrying out or managing/supervising the activity day-to-day) 
Name 
Aimone Luca Bodini 
Title 
Doctoral Researcher 
Signature 
 
Date 
06/10/22 
Person approving this assessment: 
(Person with overall responsibility for the activity Director of Professional Service (or delegated individual, e.g. manager or head of department), Senior Academic or 
Manager/Supervisor) 
Name 
Vanja Garaj 
Title 
Academic Staff 
Signature 
 
Date 
06/10/22 
 
Review of assessment, and revision if necessary 
(For continuing work: the assessment must be reviewed for each visit in a series; when there are significant changes to government guidance,  to work materials, equipment, methods, 
location or people involved; and if there are accidents, near misses or complaints associated with the work.  If none of these apply, the assessment must be reviewed at least annually) 
 
REVIEW DATE 
13/10/2022 
25/10/2022 
--/--/---- 
--/--/---- 
Name of reviewer 
Hua Dong  
Paul Josse 
 
 
Signature 
 
 
 
 
No revisions made 
 
 
 
 
Changes to activity, hazards, precautions or risks noted in 
text. 
Corrected Risk Rating 
calculation 1 (highlighted in 
red) 
Reviewed and risk controls 
added for take off and 
landing of drone  
 
 
 
 
 
 
 
330 
Appendix V – Images Miscellaneous 
 
Figure V.1.0.1 VP Staging Flowchart designed by Bazley (2022) - part 1 
 
 
 
 
331 
 
Figure V.1.0.2 VP Staging Flowchart designed by Bazley (2022) -  part 2 
 
 
 
 
 
332 
 
Figure V.1.0.3 Complete dataset of images captured by DJI Mavic 3 
 
 
 
 
333 
 
Figure V.1.0.4 Captures created by participants using Polycam 
 
 
 
 
334 
Figure V.1.0.5 Image generated using AI algorithm Stable Diffusion 
 
 
Parameters: 
Text-to-image model: Stable Diffusion 
Steps: 45 
Guidance Scale: 7.5 
Seed: 1226355953 
 
 
 
Prompt: Thesis’ title 
Filmmaking of the future: A co-design-led investigation into 
the potential of immersive technologies to enhance the 
small and medium audiovisual production processes 
 
 
 
 
 
335 
 
Figure V.1.0.6 Experimentation of VR Storyboarding made by participants 
 
 
 
 
336 
 
Figure V.1.0.7 Some of the tasks and activities done in the virtual environment 
 
