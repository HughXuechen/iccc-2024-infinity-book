muGen — Generative AI as Machinic Exploration of Cultural Archives 
 
Degree Project in Computer Science and Engineering, specializing in Interactive 
Media Technology  
Second Cycle 30.0 credits 
muGen — Generative AI as Machinic 
Exploration of Cultural Archives 
Click here to enter your subtitle 
YAN YU 
 
Stockholm, Sweden 2023 
Yan Yu 
ABSTRACT 
In recent years, generative AI has quickly become a new creative and artistic tool that could challenge our understanding of 
the creative process and the role of the machine. Despite having exhibited visually promising results, images generated by 
AI tools present various challenges, most notably their tendency to display cultural, gender and racial biases. The objective 
of the project is to speculate on the concept and prototype of an alternative text-to-image generation system, designed to 
mitigate biases from linguistic and cultural differences, and facilitate diversity in machine creativity. muGen, the final 
design, is a fictional system that allows the user to generate images using data in different languages, while adding user 
controls such as time period to better associate user’s idea with the system.  
CCS Concepts: • Human-centered computing → Human computer interaction (HCI). 
Additional Key Words and Phrases: AI art, creative AI, speculative design, text-to-image generation 
SAMMANFATTNING 
Under de senaste åren har generativ AI snabbt blivit ett nytt kreativt och konstnärligt verktyg som kan utmana vår 
förståelse av den kreativa processen och maskinens roll. Trots att bilder som genererats av AI-verktyg har uppvisat visuellt 
lovande resultat finns det flera utmaningar, framför allt deras tendens att visa kulturella, köns- och rasmässiga partiskhet. 
Syftet med projektet är att spekulera kring konceptet och prototypen för ett alternativt text-till-bild-genereringssystem, 
utformat för att mildra partiskhet från språkliga och kulturella skillnader, och underlätta mångfald i maskinkreativitet. 
muGen, den slutliga designen, är ett fiktivt system som låter användaren generera bilder med hjälp av data på olika språk, 
samtidigt som det lägger till användarkontroller som tidsperiod för att bättre associera användarens idé med systemet. 
Nyckelord: AI-konst, kreativ AI, spekulativ design, text-till-bild-generering 
 
 
 
 
 
 
 
Authors’ address: Yan Yu, yan8@kth.se, KTH Royal Institute of Technology, School of Electrical Engineering and Computer Science, Stockholm, Sweden, SE 100 
44. 
 
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or 
distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of 
this work must be honored. For all other uses, contact the authors. 
Swedish title: muGen — Generativ AI som maskinell utforskning av 
kulturarkiv © 2023 Copyright held by the authors. 
muGen — Generative AI as Machinic Exploration of Cultural Archives 
 
1 INTRODUCTION 
As AI and machine learning technology become increasingly prevalent in art and creative practices, it is worth exploring 
how new technologies challenge and redefine the concept and process of art-making. Generative AI, with the ability to 
create new images, music or text, have become the tool that grants machines the most autonomy in the creative process. 
From early computer art to deep learning and text-to-image models, humans have been engineering machines to make art 
that heavily depends on data and algorithms.  
There are certain similarities between machine’s creative process with that of humans, such as studying artwork from the 
past for inspiration to come up with something new. Both humans and machines deal with the existing archives of art and 
culture, albeit in different scales and magnitudes. How a generative machine learns and creates from data can be seen as 
fundamentally different from how humans create using memories, skills, feelings, experiences, etc. Datasets, which are 
central to the function and performance of generative AI, are acquired through the act of collecting and archiving. Yet this 
archiving process tends to contain uneven representation of different cultural groups, which is at odds with the all-
encompassing claim of generative AI systems. 
This project aims to propose a speculative design probe of a generative AI system that produces creative cultural 
combinations and reduces data bias. The focus is on text-to-image systems, a type of generative AI that produces images 
from users' text queries through language models and generative frameworks. While many of the current text-to-image 
models are already capable of generating artistic or photorealistic images, the biases embedded in the large-scale image-
text datasets will most likely carry over to the image output. 
The objective of the design is to highlight the machine’s interpretation of the human cultural archives, and offset certain 
cultural biases through the manipulation of datasets and generation pipeline. It introduces the user control of language and 
time period of the data being used, and presents the generated results in a search-engine-like fashion. The system is 
expected to function as a probe into the cultural archives from the perspectives of the machine. The text input query 
performs as the intersection that connects human creativity, machine creativity and cultural history. 
1 
2 BACKGROUND 
The background research is divided into 6 sections. Section 2.1 attempts to establish a theoretical foundation on AI and 
creativity, exploring the questions of why and how AI systems could be creative. Section 2.2 outlines the definition and a 
brief history of AI art, including notable art examples and critical perspectives. Section 2.3 is an overview of machine 
learning techniques that have been used for art, wherein the theories and applications of major generative models, 
including text-to-image generation, are discussed. Section 2.4 presents the details on the datasets used in text-to-image 
systems, connecting them to the concept of digital archive. Section 2.5 discusses researchers and artists’ criticism towards 
AI art and the biases in generative systems. 2.6 provides a brief definition of the speculative design practice, the main 
design method of this project.  
 
2.1 Creativity and AI Theories 
In regard to defining creativity, researchers often consider novelty as a key element. Margaret Boden defines creativity 
as “the ability to generate new and valuable ideas.” [1] For Boden, novelty implies the idea is either new to the person or 
new in the history of the field; valuable means the idea meets the approval or satisfies the values of the social group. 
Richard Buchanan argues “creativity moves us from the known to the unknown,” which involves “the ability to connect 
arguments and stories across disciplines.” [2] 
A classic model of human creativity related to the mechanics of AI is the associative theory. It is based on the premise 
that ideas are not created by the mind from scratch, but instead from new combinations of what already exists. Mednick 
first developed the theory in 1962, who defined the process of creative thinking as “the forming of associative elements 
Yan Yu 
into new combinations which either meet specific requirements or are in some way useful. The more mutually remote the 
elements of the new combination, the more creative the process or solution.” [3] Similarly, Arthur Koestler argues the 
creative act always operates on different planes of thinking. [4] What he called the ‘bisociative’ act is a juxtaposition of 
these planes or aspects of experience, a blending of two previously unrelated matrices into a new matrix. He believes 
bisociative thinking could result in a fusion in a new intellectual synthesis. It differs from associative thought, which refers 
to the habitual thinking that merely operates among elements of a single plane of thought. 
Boden categorizes creativity into three types: combinational, explorational and transformational. [1] Combinational 
creativity, similar to Koestler’s concept of bisociation, works by “making associations between ideas that were previously 
only indirectly linked.” Exploratory creativity refers to innovation within a “conceptual space” defined by culturally 
accepted styles of thinking; transformational creativity, the most innovative type, transforms the defining dimensions and 
the constraints of the established space and gives rise to entirely new ideas. She thinks whether computers can really be 
creative is currently a philosophical question that’s unanswerable, since scientific understanding of human’s psychological 
capacities is still ambiguous. Answering the question would involve whether a scientific theory of consciousness is possible, 
and whether computers could be accepted as part of the human moral community. Arthur I. Miller holds that if we accept 
humans as biological machines whose actions and emotions result from complex chemical reactions, then we’ll have to 
agree that computers will one day be creative and have consciousness, once the brain can be explained with a theory based 
on cause and effect. [5] 
Computational creativity is a subfield of AI research that studies AI’s creative capabilities. Geraint A. Wiggins defines it as 
"the study and support, through computational means and methods, of behaviour exhibited by natural and artificial 
systems, which would be deemed creative if exhibited by humans." [6] In other words, it is about stimulating creative 
behavior of humans through computational means. While many regard creativity as an innate part of human nature, 
exemplified by John Dewey’s view that a lived experience of inquiry and focus is essential to being creative [7], Minsky 
refutes the argument by pointing out the main steps of the creative process, including collecting domain knowledge, 
generating ideas, evaluating and revising, can all in principle be modeled by a computer. [8] This argument could also be 
applied to the field of artistic creativity, using Mace and Ward’s model that divides artists’ process into four stages: 
Conception, Development, Creation, and Finishing. [9] Qiao et al. argue that when faced with the task of drawing an image 
from text, humans tend to build a mental image of the object first and then add details and stylize it — this mental image 
stage can be emulated by programs. [10] 
Bruce G. Buachanan identifies four types of creative programs, including combinational, heuristic search, 
transformational, and layered search. [11] The heuristic search model, derived from problem-solving reasoning, is 
considered to be a common model for creative programs. It includes a generator that combines primitive elements into 
new ones, a goal test that determines if the goal is reached, and an evaluation function that finds the optimal paths to a 
solution. Buachanan argues that heuristic search is the ideal model that leads to combinatorial and exploratory creativity.  
An evaluation criterion is central to judging a creative program’s output, which is a task often attributed to humans. 
However, Loughran and O’Neill argue that computational creativity should not be measured by humans, instead computers 
should develop their own non-human standards. [12] They reference Boden’s argument, that ‘the ultimate vindication of 
AI-creativity would be a program that generated novel ideas which initially perplexed or even repelled us, but which was 
able to persuade us that they were indeed valuable’. [1] Many researchers have been working toward this path, by 
assigning evaluative functions to creative programs. Some examples include the FACE descriptive model, and Machado, et 
al.’s generative architecture that includes both a creator and an artificial art critic. [13] 
Despite the ability of AI programs to generate creative output, there are fundamental differences that distinguish 
human’s creative process from AI’s. Boden argues that combinational creativity, despite being the easiest type of the three 
for humans to achieve, is most difficult for AI to model, because “no current AI system has access to the rich and subtly 
structured stock of concepts that any normal adult human being has built up over a lifetime.” [1] She thinks the AI models 
function in ways that have no close relation to how the mind works—they aren’t really “models” of intelligence, but 
muGen — Generative AI as Machinic Exploration of Cultural Archives 
 
computer programs that are sometimes able to generate creative outcomes. Computer artists seem much more obsessed 
with the aesthetic value of their program's performance rather than human psychology.   
John Searle’s famous ‘Chinese Room Argument’ brings up the question of consciousness and symbolic understanding of 
AI. The argument hypothesizes a scenario, in which a native English speaker is locked in a room full of Chinese symbols and 
the instructions for using them. By following the instructions, the person could answer any questions in Chinese sent into 
the room, without actually understanding the language. Thus, this program could pass the Turing Test for understanding 
Chinese. With this argument Searle points out the difference between a program’s operation and that of human mind, 
“computation is defined purely formally or syntactically, whereas minds have actual mental or semantic contents, and we 
cannot get from syntactical to the semantic just by having the syntactical operations and nothing else.” [14] While current 
machine learning models are based on statistical methods instead of symbolic representations and logical rules, the 
argument about machine’s inability to have semantic understandings still stands.  
2.2 AI Art and Post-humanist Perspectives 
Throughout history, art has always been shaped by the most advanced technologies at the time, whether it being cave art, 
oil paintings, photographs, or digital images. Propelled by the technological development in artificial intelligence and machine 
learning, artists have adopted the most current technologies as creative tools, while AI art has since become a specific domain 
in digital media art. Regarding the definition of AI art, Media scholar Lev Manovich argues that “AI” is not a method but the 
amount and type of control we exercise over algorithmic processes. [15] Computer art or algorithmic art are valid instances 
of AI art, in which computer’s creative rules are preprogrammed by humans. Boden also attributes generative art to the 
creation of AI systems, in that the computer produces novel results that the human artist couldn’t predict or imagine. [16] 
The history of computer art dates back to the 1960s. Early computer artists, such as Ben Laposky, Vera Molnár and 
Desmond Paul Henry, wrote algorithms that directed mechanical or electronic devices to draw complex geometric shapes as 
art pieces. In the 90s, Karl Sims and William Latham were among the computer artists who created evolutionary art with 
genetic algorithms, which learn from experience and could be considered as a form of machine learning. Nowadays, creative 
coding languages and software designed for generative art and procedural design are readily available. The approach is 
prevalent in computational artworks, by artists such as Zach Lieberman, Casey REAS and George Legrady. Robotic art is 
another instance of machines creating art based on human-prescribed rules.  
Artists often consider their AI artwork as co-creation between artists and the machine. Leonel Moura, whose work involves 
automated robots drawing on a canvas, says that he designs some basic algorithmic rules for the robot, but the end result is 
ultimately the robot’s creation. [18] Harold Cohen, who created the iconic drawing machine AARON, rejects the usual 
dichotomy between the programmer and the program regarding creativity. AARON was written to understand color and form, 
whose behavior is determined by the complex rules programmed by Cohen. He believes “programming might involve trying 
to think in the computer's terms… rather than trying to get it to think in human terms.” [17] For computational artist Andy 
Lomas, the machine should not be considered merely as a medium for artwork but as “an active collaborator in the process 
of exploration and discovery.” [55]  
There are other researchers who acknowledge the potential of AI art from a non-human-centered or post-humanist 
perspective. Anastasiia Raina et al. propose that “we should move beyond the conception of AI as an assistant or collaborator 
and begin to think about it as an extension of ourselves—a by-product of a quintessentially human quest to expand human 
abilities and better understand the world around us.” [74] Contreras-Koterby & Mirocha argues that the work by artists and 
programmers in the post-digital age have become so independent from the creators’ full control. And it is in this autonomy 
can the new aesthetic be found. [54] Joanna Zylinska suggests not to simply approach AI with a human-against-the-machine 
mindset, but rather explore the human-with-the-machine, or human-as-a-machine scenario. [18] Luciana Parisi argues that 
if AI is rooted in uncertainty, then it must be understood as a non-conscious form of cognition which possesses its own non-
Yan Yu 
human way of learning. [19] Mathematician Marcus Du Satoy thinks machines have the potential to propel human creativity, 
coming up with something new that exceeds the pre-designed idea of the coder. [18] Manovich predicts that AI could create 
“what humans are unable to create because of limitations of our bodies, brains, and other constraints,” based on a 
systematicity that is unseen in even the most radical artwork. [15] Writer Stephen Marche holds that like photography, AI is 
not going to replace creativity, but instead reconfigure the nature of it. Creative AI is essentially the art of the archives, 
“derived from the massive cultural archives we already inhabit.” [56] 
2.3 Creative Machine Learning Technology 
With the breakthrough in machine learning and deep learning technology since the last decade, creative AI has entered a 
new territory, in which machines no longer create by human-prescribed rules, but instead learn to generate media based 
on preexisting data. Machine learning models are generally trained to either predict or produce the patterns of existing 
data, corresponding to the two main types of models, discriminative and generative. In Hannu Toivonen’s words, “machine 
learning can be characterized as search for generalisations from data. These generalisations then afford production of 
appropriate response in novel situations, as long as they are sufficiently similar to situations encountered before.” [20] 
2.3.1 Discriminative models 
Discriminative models learn to predict some output y given an input x. It is a task in which machine learning algorithms 
assign class labels to new samples based on existing data, often used for classification, such as image classification and 
facial recognition. The technology is prevalent in all kinds of industries including business, automation, entertainment, 
healthcare and transportation, but not frequently applied to art practices. There are artists who create work that explores 
and critiques AI’s capability (or incapability) in recognition, an example being Trevor Paglen’s Imagenet Roulette project, in 
which Paglen tries to reveal errors and biases in a neural network’s classification of humans. [21] The network was trained 
on ImageNet’s ‘person’ category, containing over 2500 labels of person. For new input photos of people, it might produce 
odd and false labels like “concert goer” or “chemist”, reflecting the deficiencies of the recognition system. 
The idea of predicting the class of new instances based on existing data have also been used in interactive art, sensor-
controlled digital musical instruments and performances. [22] Media artist Birk Schmithüsen’s project SpeculativeAI #1 is an 
example that made use of this concept—an LED device takes a number of audio-visual associations as input, and predicts 
the visual response that would be triggered by a new sound. [23] 
2.3.2 Generative models 
The goal of generative deep learning models is to produce synthetic data that resembles real input as close as possible. 
Google’s DeepDream, published in 2015, was the first milestone model that sparked massive interests in AI image 
generation. It uses a convolutional neural network to find enhanced patterns in images, making the original image resemble 
more into an archetypical image[xii] with patterns of, for instance, cats, dogs or eyes. Although Google defined it as “a 
visualization tool designed to help us understand how neural networks work,” [24] it was exploited by online communities 
and professional artists creatively for a short period of time. An example is Memo Atken’s work called “All watched over by 
machines of loving grace: Deepdream edition”. [25] 
Neural style transfer, released in 2015, is another model widely used for image manipulation. It is an optimization 
technique that takes a content image and a style reference image, to produce a blended output that looks like the content 
image in the style of the reference image. [26] Atken argues that since style transfer allows for much easier customization 
of aesthetics of the image, its popularity didn’t diminish as quickly as DeepDream. Mike Tyka’s Saxophone Dreams is an 
example that uses style transfer to transform a DeepDream image in the style of a saxophone. 
muGen — Generative AI as Machinic Exploration of Cultural Archives 
 
A General Adversarial Network (GAN) comprises a generative and a discriminative network that compete with each 
other. The discriminator learns to distinguish between real samples and generated samples, while the generator learns to 
produce images from random noise that pass as real to the discriminator. Since its conception several modified versions of 
GAN have been developed for different refinement purposes, including DCGAN, ProGAN, CycleGAN, BigGAN and StyleGAN. 
Some of the popular GAN tools include ArtBreeder and Runway ML. Robert Barrat, who was using a modified DCGAN to 
generate images from Renaissance paintings, considers the conceptual value of GAN to be its misinterpretation—he would 
modify the network and make it learn the rules regarding some features of the paintings, but failed to learn regarding some 
other features. [27] Echoing Barrat’s view, researcher Aaron Hertzmann thinks that the appeal of GAN art lies in its visual 
indeterminacy—they are good enough to produce realistic novel imagery, but not so good that all their outputs look like 
ordinary photographs. [28]  
As opposed to training GAN on historical artwork, some artists choose to collect images on their own to build the training 
dataset. Anna Ridler and Sofia Crespo’s work are examples of this approach. Mario Klingemann illustrates the curatorial 
aspect of the GAN process: he trains the model on selected datasets, tweaks its parameters, and then selects favorable 
ones from thousands of generated images. [29] Boden thinks that a gifted artist could use some random compilation from 
neural network results and come up with completely novel ideas that sparks new forms of composition. [30] Neil Leach 
argues that ‘search’, the common method to access information in today’s age, can be central to the creative process. To 
think through search in the context of design, if all possible solutions already exist, it is simply a matter of setting 
constraints for a search and then selecting the results. [31] 
Diffusion model is another type of generative model, which produces new data similar to the data on which the model is 
trained. It works by first sequentially adding noise to an image until it becomes all noise, and then the model learns to 
recover the data by gradually removing the noise. Many argue that currently diffusion models produce the state-of-the-art 
image quality. [32] They provide more stable performance than GANs because of the iterative and guided process of 
reverse diffusion, whereas GANs often suffer from unstable training and mode collapse (when there is no diversity in the 
generated samples). Diffusion models are applied in popular text-to-image tools such as Disco Diffusion, DALL-E, 
Midjourney and Stable Diffusion.  
Text-to-image generation is the task that aims to bridge the modalities of vision and language, by generating 
“semantically consistent and visually realistic image conditioned on a textual description.” [10] Current models such as 
DALL-E and Stable Diffusion usually involve two components, including a natural language supervision model that pairs 
images and texts, and an image generator. Many of the text-to-image systems use CLIP to assess the similarity between text 
and images, which is a neural network model trained from over 400 million image-text pairs over the internet. The image 
generator, whose architecture is based on diffusion models, then uses the text-image similarity scores to guide the 
generation to produce images corresponding to the input text. [33] For the users, the framing of text prompts is where 
human creativity plays its part. Writer Dean Kissick describes the process of using text-to-image generation to come up with 
new images, “You have to learn to describe something that may not exist, and to do so in language that’s tailored for the 
machine, that it can parse. It’s a radical jump from one form of creativity (writing) to another (computer-generated 
imagery) ...” [34] 
Text-to-image generation tools have been gaining massive public interest since their popularization and democratization. 
Tools such as DALL-E 2, Midjourney and Stable Diffusion have been widely used by artists and designers, and have 
superseded GANs as the most popular creative AI tools (Midjourney currently has over two million users). [35] Midjourney’s 
training set contains a lot of artwork and illustrations; it tends to generate surrealist images and is popular among artists. 
Stable Diffusion, developed by Stability AI, is the only open-source model of the three. Aside from these models, there are 
other community-built text-to-image architectures based on CLIP and GANs, including CLIP-GlaSS, BigSleep and VQGAN-
Yan Yu 
CLIP. Some of the artists using text-to-image generation include Holly Herndon & Mathew Dryhurst, Jon Rafman, Vadim 
Epstein and Xander Steenbrugge. [36]  
Japanese Stable Diffusion (2022) is the Japanese variant of Stable Diffusion, developed by the company rinna; it allows 
users to input text prompts in Japanese. [37] The original Stable Diffusion was trained on LAION2B-en, the English subset of 
the image-text dataset LAION-5B. Although other languages are accepted as prompt, they have to be translated into English 
before processing. The Japanese version fine-tuned Stable Diffusion on the Japanese subset of LAION-5B, a much smaller 
dataset of Japanese-captioned images. The model can take Japanese text prompts as input directly, as well as “Japanglish, 
Japanese unique onomatope, and Japanese proper nouns.” The authors express that their motivation for the model is to 
“understand Japanese culture, identity, and unique expressions including slang.”  
ruDALL-E is another text-to-image generation tool that uses a different language, designed to recreate DALL-E’s 
functionality with Russian. The model uses ruCLIP for image-text correlation, a model trained with a dataset of 120 million 
text-image pairs in Russian. [38] The generation pipeline includes ruDALL-E, ruCLIP and a superresolution model. Text 
prompts in other languages are supported and would be automatically translated into Russian. 
2.4 Datasets as Digital Archives 
Datasets play a central role in the current AI technologies. The trend of text-to-image models has been to constantly 
expand the scale of the training sets, since larger dataset would provide comprehensiveness, accuracy and variety. [39] An 
early example is ImageNet, the first major computer vision dataset containing over 14 million images. The tasks of adding 
and annotating the images for over 22,000 object categories were crowdsourced through Amazon Mechanical Turk, which 
required the labor of more than 25,000 workers. [40] Moments in Time is another large-scale dataset for videos, containing 
over a million videos of action moments. It was designed to help AI recognize actions such as “picking” or “running”. 
Similarly, the videos were collected from the internet, and the annotation task crowdsourced through Mechanical Turk. [41] 
Text-to-image models ditched the supervised learning method with labeled datasets, and opted for unsupervised 
learning with even larger-scale datasets acquired from the internet. CLIP is trained on LAION-400M, in which 400 million 
text-image pairs were extracted from random web pages between 2014 and 2021. [42] Stable Diffusion is trained on the 
English subset LAION2B-en of LAION-5B, an extensive dataset of 5.83 billion CLIP-filtered image-text pairs. [43] It is an 
uncurated large-scale dataset collected from the internet via Common Crawl. The English subset LAION2B-en contains 2.32 
billion image-text pairs; the subset LAION2B-multi, which is in over 100 other languages, contains 2.26 billion image-text 
pairs; LAION1B-nolang, the dataset in which language is undetected, contains 1.26 billion image-text pairs.  
These datasets, being specific instances of online digital archives, have been the foundation of machine cognition and AI 
creativity. This brings up a theoretical question of whether digital data function as records of cultural history on which new 
creative associations and artistic patterns could be built. According to Brouwer and Mulder, digital databases differ from 
traditional physical archives in their “complex linking technologies which no longer work linearly.” [44] Therefore, data 
retrieval tools like search engines are able to “build patterns where there seemed to be only fragments.” They expressed 
the significance of digital archives by saying “we live in an information society that is a digital archive. Understanding the 
world means understanding what digital databases can or cannot do.” In the words of Jean-François Lyotard, “Data banks 
are the Encyclopedia of tomorrow. They transcend the capacity of each of their users. They are ‘nature’ for postmodern 
man.” [45] 
Media theory Wolfgang Ernst points out that the archive does not represent the collective historical or cultural memory 
of a given society, but rather a data storage apparatus for administrative acts. [46] He regards the transition from 
traditional archives to digital archives as the transition from spatial and static to time-based and dynamic. Instead of the 
stable source, digital archives privileges interaction with active users, which is a time-critical, dynamic process. Now that 
digital images and sounds can be addressed down to the single pixel and pattern recognition algorithms, Ernst argues that 
muGen — Generative AI as Machinic Exploration of Cultural Archives 
 
such procedures would not only excavate from data but “generate unexpected optical statements,” in a way predicting the 
current generative algorithms that operate on the pixel level. Tyler Charlton argues that the concept of representation is 
embedded in archival processes. And to arrive at meaningful representations of marginalized groups requires focusing on 
how records and collections in an archive are “arranged, structured and labelled to reflect the community’s ontologies and 
knowledge structures.” [47] 
An example of a digital archive is the Wayback Machine - Internet Archive. It is a web archive that stores billions of web 
pages and online media dating back to 1996, most of which do not currently exist on the live web. It uses multiple web 
crawlers to gather web pages linked to each other, and allows users to query web pages through a search bar. AlNoamany 
et al. studied users’ requests on the Wayback Machine, and found that requests for English language pages took up around 
70% of the total requests, followed by Russian, German and Japanese. [48] Richard Rogers points out that the Wayback 
Machine is a web-historical object that tells the story of the Web in particular periods. [49] Bowyer argues the Wayback 
Machine is a photographic apparatus that captures ‘snapshots’ of websites. [50] 
2.5 Critiques of AI Art and generative AI biases 
Regarding AI art’s visual aesthetics, the most notable criticism is on its fixation on imitating the past. Dean Kissick regards 
generative AI’s approach as conservative, since it is trained on historical imagery and provocative text prompts are 
forbidden. The generated images are ‘kitsch’, “imitations of art and its effect,” whose beauty comes about by chance rather 
than purpose. [34] Manovich addresses the limit of forcing computers to create art like humans in a specific style of the 
past. He thinks the fascination with a consistent style is connected to modernist tradition, which remains unchallenged by 
digital technologies. [15] Emanuele Arielli illustrates the logic of generative AI, which is to “analyze pre-existing work and 
generate variants conforming to their patterns, while trying to introduce some level of variation.” They do not introduce 
styles of music or paintings that are entirely new, instead they are instances of “computational mannerism” – a kind of 
reproduction of pre-existing work. [51] Zylinska regards the generative images by artists like Kogan, Tyka, Atken and 
Klingemann as rather kitschy and banal, drawing on “mildly fascinating transformation of humanist representationalism…” 
For her, this kind of work reduces perception as visual consumption and art as mild bemusement. [18] Yet she 
acknowledges the fun factor of the AI-inspired work that proliferates on the internet, despite it often being visually kitsch 
and derivative. Zylinska suggests the potential for popular AI art to reboot the notion of ‘outsider art’, which could 
“transform the format of the museum and the gallery into a fluid display of experiment, joy and fun.” 
AI art’s dependence on corporate-developed technologies is another alarming issue for many artists and critics. Atken 
notes that while tech giants like Google and Nvidia have sponsored art created with their technologies such as DeepDream 
and StyleGAN, their marketing schemes don’t often highlight individual artists, but instead tend to shift the narrative in 
favor of their own technology and products. [52] Zylinska also criticizes AI artists for having their work more aligned with 
the “development trajectories of corporately-funded AI and the techno-evolutionary narrative of Silicon Valley.” Digital 
artist Sam Rolfes argues that corporation-sponsored art has resulted in “a lot of conceptually hollow tech demos 
masquerading as art, which largely only benefit the image of the manufacturer of the tech tools.” [53]  
From a critical standpoint, Claudia Aradau approaches biases in AI from the perspective of power: “power and 
domination are built into AI technologies through the data that makes algorithmic operations possible.” [57] Biases are 
created by training data that reflects historical or social inequities, because specific groups – such as people of color, 
minorities or women – are often underrepresented in the data gathering stage. She exemplifies it with the facial 
recognition dataset ‘Faces in the Wild’, in which 70% of the faces are male and 80% white. She contends that this type of 
bias making racialized subjects invisible is entwined with surveillance technologies that “render marginalized and oppressed 
communities hypervisible.” Even if values representing race, gender, etc. are removed, she argues, AI models will always 
tend to look for discriminatory patterns in other categories.  
Yan Yu 
Technically, biases in an AI system can originate from its dataset, problem formulation, algorithm and evaluation. Ramya 
Srinivasan and Ajay Chander identify the types of biases in the data creation stage, including sampling bias, measurement 
bias, label bias, and negative set bias. [58] Srinivasan and Uchino discuss how some of these biases would affect the results 
of generative AI art. [59] For sampling bias or representational bias, referring to imbalance selection in the training data, 
they bring up the example of ‘AIportraits’, the artwork portrait generator trained with 45000 Renaissance portraits of 
mostly white people. It would perform poorly with input of non-white faces because of the obvious biases in data selection. 
Label bias is caused by inconsistencies in annotation labels given to the data. An example is ArtGAN, a generative network 
whose discriminator is trained on images with genre labels such as ‘sketch’ and ‘portrait’. If some of the labels are not 
reliable indicators of genre, it would result in label bias and possible inconsistent generated results. 
Biases are also embedded in the training of natural language models such as GPT-3, exemplified by its issue of associating 
Muslims with terrorism. [60] For text-image systems that utilize such models, the gender, racial or cultural biases present in 
the language embeddings will carry over to the image space. Wang et al. studied gender bias in CLIP image search, in which 
images of men are over-represented in occupational search queries. [61] Goh et al. find that certain neurons in the CLIP 
image encoder have embedded biases, such as associating Muslims with terrorism, or illegal immigration with Latin 
American countries. [62] Wolfe and Caliskan reveal that language-and-image AI models CLIP, SLIP, and BLIP tend to 
automatically equate the American identity with being white. [63] 
A natural solution to reduce bias in AI models is to preprocess the training data to ensure it is diverse and representative 
of all groups. It often requires first quantifying the discriminatory effects within the data, and then removing or accounting 
for the biases. However, Leavy et al. argue that it is not always a just solution, since the act of collecting more data from 
underrepresented groups could potentially lead to issues of unethical data collection. [64] This is derived from the thinking 
that data is not neutral or objective, but political in nature. They call for the human labor and value involved in data 
curation to be more transparent.  
Aside from balancing the datasets which is a pre-processing method, there are also in-processing and post-processing 
methods designed to ensure fairer outputs. In-processing measures involve modifying the training algorithm, by either 
updating the objective function or imposing constraints on the model. Feldman and Peake discuss adversarial debiasing as 
an example technique, which uses a trained adversarial network as a discriminator to predict and mitigate the demographic 
information from biased labels. [65] Post-processing method functions by manipulating results from the model based on a 
fairness constraint. However, it is often considered as a suboptimal solution because it hinders the model’s performance.  
A research focus on text-to-image generation models has been their performance on understanding language. Gary 
Marcus et al. have made several preliminary observations regarding DALL-E 2’s limitations in semantic understandings. They 
generate a number of samples using DALL-E 2 and found it has issues with understanding compositionality, numbers, 
negation, and generalization in language. [66] Conwal’s study also finds that DALL-E lacks relational understanding of text, 
often struggling with prompts with spatial relations such as “in, on and under”. [67] User Swimmer963 summarizes DALL-E’s 
strengths and weaknesses with different text content. They found DALL-E performs well with categories like stock 
photography, pop culture media, art style transfer and digital art., but struggles with scenes involving two characters, 
foreground and background, spellings, and non-standard objects. [68] 
Liu and Chilton discuss text-to-image generation from the perspective of “prompt engineering”, which refers to using 
tricks and keywords in the text prompt to reach certain aesthetics in the generated image. [69] They consider a drawback of 
AI-based approaches to be the lack of meaningful and interpretable controls for users, despite their abilities to create 
numerous generations. Through a series of prompt experiments with the VQGAN+CLIP system, they found significant 
differences in generation qualities when using certain subject and style keywords as input—some visual styles and subjects 
are depicted better than others. For example, it does well with salient color scheme styles like glitch art and cyberpunk, but 
fails with styles that are more symbolic than visual, such as dadaism. 
muGen — Generative AI as Machinic Exploration of Cultural Archives 
 
2.6 Speculative Design and AI 
Speculative design is a design concept proposed by UK designers Anthony Dunne and Fiona Raby. [70] It is proposed as a 
method of critical design, which aims to break away from design’s commercialized nature, and use the medium of design to 
identify and debate crucial issues that might happen in the future. It frames design as “a means of speculating how things 
could be,” to open up new perspectives on ‘wicked problems’, create spaces for discussion and debate about alternative 
ways of being, and inspire people’s imaginations about future technology. Speculative design can act as a catalyst for 
critically examining technology. By speculating and exploring ideas “before they become products or even technologies, 
designers can look into the possible consequences of technological applications before they happen.”  
Betti Marenko argues the importance of speculation on AI emerges since machine learning’s way of working is highly 
inductive, compared to traditional deductive AI approaches. [71] The process of inductive data-retrieval and recursive 
training involves uncertainty, indeterminacy and unknowns. With the integration of technology into culture, the boundaries 
between ‘the natural and the artificial, the animate and the inanimate, the human and the non-human' have become 
blurred.” She references Murray Shananan’s opinion on the shift of understanding consciousness, from a monolithic notion 
made of memory, emotion, etc. to a more distributed form of consciousness. In this context she proposes FutureCrafting, a 
speculative design strategy on imaginative AI that “captures the future, grabs it and brings it back to the here and now, to 
inform the present.” 
3 METHODS 
The principal methods of the project include research through design (RtD) and speculative design. As a research-
through-design project, the aim is to employ design practice with the intention of generating knowledge [72] on creative-AI 
systems. The project attempts to answer the main research question: what elements could future text-to-image systems 
introduce to make image generation more culturally inclusive. The intention is not to design a fully-functional system, but 
to critically engage with the future of creative AI technology through the design concept and prototype. 
Specifically, the project attempts to build a speculative user experience of a text-to-image generation system, by 
incorporating new elements and controls that are absent in current systems. The focus is on creating a design probe in 
which the AI could creatively interpret the cultural archive and draw from diverse sources to stimulate combinational 
creativity. The workflow of the project is divided into three stages:  
(1) Online fieldwork: exploring and critiquing current technologies.  
(2) Developing a cultural design probe. 
(3) Evaluation and iteration of the design. 
 Firstly, experiments are conducted in order to examine the generative patterns and cultural biases that exist in the 
current text-to-image generations. Then I aim to devise the concept of the design probe, namely the structure of a 
generative system that provides a solution to the research question. The outcome takes shape in a video prototype that 
visualizes the workflow of the speculative system. It is designed to showcase a potential scenario of how the system 
functions and interacts with the user. Toward the later stage of the project, there are interviews conducted with artists, for 
feedback on the prototype and critical discussions leading to the further iterations of the design. 
4 RESULTS 
The results are divided into three sections. The first section discusses my observations and findings about how current 
text-to-image systems produce cultural biases. The second section presents the design probe of an alternative text-to-
image generation system. The third section reviews the interviews with artists and researchers as an evaluation stage of the 
design. 
Yan Yu 
4.1 Online fieldwork: exploring and critiquing current technologies 
The biases of text-to-image AI originate from its semantic understanding, which determines how it understands the 
correlation between text prompts and image output. For a language-image model like CLIP, the way it correlates texts and 
images depends heavily on the dataset on which it is trained. The function of the generative model is to produce new 
samples that the system recognizes as correlating to the instances in the original dataset, guided by the language model. 
An obvious bias in the dataset for text-to-image systems would be sampling bias, which refers to the bias created by 
selecting particular types of instances more than others, thereby rendering the data under-representative of the real world. 
Uncurated datasets could also be subjected to label bias, where the text description does not aptly describe the image. 
Since models like CLIP and Stable Diffusion use large uncurated datasets crawled from the internet, the image-text pairs 
contained in datasets would not represent different cultures evenly. Instead, they favor popular discourses and dominant 
cultures on the internet, which marginalizes under-represented groups and cultures and strengthens existing power 
imbalances. The generated output is a generalization from the most dominant data instances of the relevant textual 
categories, which disregards marginalized cultures as data outliers. The query for images of specific content or style is 
subjected to the statistical distribution of the training data deemed correlated by the machine. 
4.1.1 Bias from Language 
For text-to-image models, it is a major factor that results in sampling bias in the training datasets. Most of the current 
image-to-text models are trained using datasets of text-image pairs entirely in English. The generated results are then a 
reflection of the dominant cultural perceptions of the English web. It is the data origin of the various racial and gender 
biases discussed in section 2.5.2. 
The identity of AI is often considered to be neutral and non-human, while in fact it is shaped by specific datasets that 
represent the collective perceptions and cultures of selected groups — machine’s perception is not separable from the 
cultural divide in the real world. As a way to counter the cultural imbalances, it is worthwhile to speculate on creative AI 
technology that incorporates the experience and perception of non-dominant cultures. From the standpoint of 
manipulating and balancing the training dataset, a viable control variable would be language, as media in different 
languages can have vastly different cultural and ideological traditions. Concepts such as “modern” and “beauty” would have 
different connotations in different cultures. By incorporating data in different languages, an AI system could potentially 
diversify its cultural understanding and the range of generative results. 
In the following experiments I intend to demonstrate how models trained in different languages could generate different 
results. I generated a set of images using DALL-E 2 and ruDALL-E Malevich (XL), with the same text prompt in English and 
Russian respectively. The results show the differences in the models’ textual understanding while using two different 
languages. Although ruDALL-E’s generation mechanics differs from that of DALL-E 2, comparing the discrepancies in the 
results could still inform the power of the training data. I tested the models with two text prompts: first one is a prompt 
that doesn’t specify a cultural group, and the second one refers to a specific minority culture. The results are shown below. 
muGen — Generative AI as Machinic Exploration of Cultural Archives 
 
 
Fig. 1. Comparison of DALL-E and ruDALL-E output on the first prompt 
The first prompt is “crowd gathering in the front of a government building.” The DALL-E output is placed on the left, and 
ruDALL-E’s on the right. Disregarding the apparent stylistic contrast, one could spot the differences in the content being 
portrayed in the images, namely the buildings and the people. It appears that DALL-E images are more likely to refer to 
western European cultures, while the locations in ruDALL-E images look more Eastern European. Realistically, the use of 
language has been closely tied to globalization and geopolitical order. The preferences of an English-trained network that 
cater to the perception and imagination of western cultures would further this gap in power.  
 
Fig. 2. Comparison of DALL-E and ruDALL-E output on the second prompt 
The second prompt is “traditional Tartar wedding”, referring to the culture of Tartar people, the second largest ethnic 
group in Russia. The content of the DALL-E images is completely off, which interpret ‘Tartar’ as tartar sauce instead of the 
ethnic group. ruDALL-E correctly interprets the prompt because of its familiarity with the content from training data. DALL-
E’s failure here could partly be attributed to its issue in understanding compositionality in language, as mentioned in 
section 2.5. Nonetheless, its ability to understand specific minority cultures appears to be problematic. While DALL-E 
performs fairly accurately on some prompts related to Russian culture, including landscapes, specific locations, and 
renowned artists, the cultural bias is evident through more regional and minority demographics and cultures.  
Yan Yu 
4.1.2 Time as control factor 
In the context of art, the correlation between the labels and images are constantly subjected to cultural changes over 
time. As an example, James Cunning reveals how the “impressionist canon”, namely the most discussed impressionist 
artworks, constantly changes in art history books. [73] Compared to the impressionist movement which is over a century 
old, more current art genres or cultural terms would be subjected to even more drastic changes over time. A search for 
images in technology-infused styles such as “digital art” or “3d graphics” would produce very different results now 
compared to over 10 years ago. As an example, the images below show Flickr’s search results for “video game landscapes” 
over two periods: the images on the left were uploaded between 2004 to 2008; images on the right are from 2019-2021. 
The evolution of graphics technology and video game aesthetics result in great stylistic differences over different periods. 
 
 
Fig. 3. Comparison of “video game landscapes” search results. via Flickr. 
Current generative AI models rarely address this problem, unless the user actively inputs a time period in the prompt. 
Oftentimes a generated image would be a generalization of one specific style from the entire dataset, lacking enough 
stylistic variations to function as a trigger for cultural inspiration. Using time as a differentiator would be a means to let 
machines draw from documents from the past till now, and present its outcome as variations of historical versions. 
4.2 Design Probe 
The design probe is a speculative text-to-image generation AI that provides variations on generated results based on 
language and time period controls. It would give users the option to select languages and a time period for the images they 
intend to generate. Hypothetically, this would be achieved by having multiple datasets used for training instead of a 
singular one. Each language would have its own attributed dataset of image-text pairs. Each image is labeled by the date 
posted on the internet, which could divide the datasets into subsets by time period. The generative AI would still work as a 
creative recommendation system, which outputs different versions of the same prompt and lets the user evaluate its 
content and use it as a source of inspiration. It does not aim at maximizing the accuracy of image-text correlation, but 
instead including and displaying cultural subtleties and differences in its generation. 
4.2.1 Datasets 
In theory, the model would aim to include as many languages as possible, covering both the widely used ones and 
minority languages. For the purpose of the demo, a selected group of 8 languages are displayed. Each language has its own 
dataset of image-text pairs crawled from the internet and web archive, which are then used to train each language-specific 
model. The muGen system would continue to utilize internet-scale data, similar to the current language AI and text-to-
image models. A notable difference is that muGen would include archival web data in addition to data on the live web. The 
datasets would contain the info of when the image entry was posted on the internet, by which the dataset could be divided 
into yearly subsets. The starting date is set hypothetically to 1989, which marks the beginning of the World Wide Web. 
muGen — Generative AI as Machinic Exploration of Cultural Archives 
 
Using internet-scale data is not a perfect solution, but it’s comprehensive enough to cover different grounds without the 
need to construct entirely new datasets. Its limitations are still apparent: possible label bias, insufficient representation of 
marginalized content, etc. However, the multiple-language and time selection controls are designed to offset a significant 
amount of cultural bias shown in the generated results. 
4.2.2 Generation Pipeline 
User controls include selection of language, time period and abstraction level. The abstraction level is designed to 
provide more variation and indeterminacy on the generated results. Higher the value, the less representative the output 
images are of the prompt. The generation pipeline is illustrated below. 
1. User inputs a string of text, selects language, time period and abstraction level. 
2. The text is translated into the selected languages. 
3. The user selects a time period, each language-based dataset splits into subsets of the specific time. 
4. The model calculates the relevance scores of each language’s image-text datasets, and ranks the datasets based on the 
scores. 
5. Generate images that correlate to the text input, using each language-specific model. 
6. The system selects and displays the images in the result, including both the ones with large relevancy scores and small 
relevancy scores. 
 
 
Fig. 4. Flowchart of the generation pipeline 
4.2.3 Prototype 
The prototype of muGen is a hypothetical demo video that showcases the workflow of the system from a user’s 
perspective (video link). All user controls are included in the demo. The output images are displayed in constant rotation, in 
a fashion similar to image search engine. Below are several snapshots of the video prototype in different stages of the 
generation. 
Yan Yu 
 
Fig. 5. Prototype of the text query input page 
    
 
Fig. 6. Prototype of the output page, left image shows when abstraction set to low, right when set to high 
For each generated image, there is an additional page to which the user can navigate, which shows the generated image 
and its similar images acquired from the dataset. The system embeds a reverse search algorithm for finding the most similar 
images in the training dataset. The top similar images from the dataset would be displayed, functioning as an automated 
survey of how the dataset could have informed the generation, and conversely, how the generation fits within the existing 
archive. By correlating the generation back to the source data, the system would appear less than a black box, but a guided 
survey into the cultural archive. It attempts to reveal a particular logic of AI generation—a machinic understanding and 
approximation of the human cultural archive. 
 
muGen — Generative AI as Machinic Exploration of Cultural Archives 
 
Fig. 7. Prototype of the info page that shows the similarity search results 
4.3 Evaluation  
After the design probe was made, I interviewed a total of 5 people on the concept and prototype of the design. This 
process was designed to raise discussions about the cultural aspects of generative AI, and the potential practical use of the 
system from artists’ standpoints. The participants include artists and researchers, three of the participants have used 
existing generative AI tools for their work, and two other participants are familiar with various digital creative technologies. 
The interviews were conducted through online video call over five sessions, each lasting for about an hour. During each 
session, I first presented the concept, design and the prototype video of the muGen system, and then used the questions 
below to guide the interview: 
1. Have you experienced any cultural or language bias in using generative AI? 
2. What are the interesting aspects of the design concept of muGen? How do you see it in relation to the current and 
future landscapes of AI?  
3. How does the prototype convey the concept of the design? What could be changed regarding the prototype? 
4. Are there ways to make the design more conceptually critical? Are there other areas to explore? 
5. What impact could such a speculative design approach make on the future society? 
I will discuss the results of these interviews in the following analysis section. 
5 ANALYSIS 
This section provides a summary of the participants’ response from the interviews. The participants who have experience 
with creative AI acknowledge the deficiency in AI’s cultural sensitivity. Two of them notice that minority languages are not 
well-represented in current language AI models, and symbols and representation are lacking in the way AI algorithms 
function. They think muGen’s focus on language is a meaningful design that could potentially address these issues, by 
exploring linguistic differences and providing education on cultural nuances. Another artist is also aware of current 
generative AI’s tendency to cater to western cultures. With regard to muGen’s concept, she is curious how selecting a 
language like Japanese would be different from directly inputting the text “Japanese” in current systems like Midjourney. 
She suggests that the system should target culturally specific concepts in its design. 
Overall, the participants are positive toward the presentation of the video demo, saying it conveys the concept of the 
design rather clearly. A participant finds the initial interface design in a retro style to be incongruent with the concept (the 
visual design has since been changed), and gives advice on making the language and time controls more apparent. She also 
suggests adding more user controls to render more culturally specific generations, through the selection of countries and 
regions in addition to language. Another digital sculpture artist also speculates on more detailed controls in text-to-image 
generation, such as real-time interpolation between settings of abstraction and fittingness levels of the languages.  
Regarding the role of AI in the creative process, the participants mostly consider AI as a creative tool that assists the 
artist. The artist who uses Midjourney says that she’s most interested in generating images that imitate nature — she 
would edit and combine different generated images into a new work, using the medium of AI to explore machine’s 
interpretation of nature and reality. Another sound artist also expresses the view that artists shouldn’t be too dependent 
on AI, and generative tools should be a module in the creative process rather than the final stage. She thinks it would be 
more interesting for artists to explore their own ideas with AI than using it to imitate classics. She also mentions the 
educational value of AI from its data knowledge, which could be used as a valuable source of inspiration.  
Yan Yu 
Besides, several participants raise the question of how generative AIs like muGen would influence the future of art, and 
whether it would further democratize art-making toward the general public. An artist brings up the issue of ownership and 
copyright related to AI-generated art, which would need to be solved if the use of generative AI becomes standardized. The 
overall consensus from the interview is that it would be unlikely for AI to take over the role of artists in the future, as the 
creative direction of artists is unique and cannot be automated by the machine. 
6 DISCUSSION 
This section reviews and critically discusses the intentions, issues and possible future developments of the design.  
6.1 Intentions of the design 
6.1.1 Human and machine co-creation 
Along with the integration of AI into creative practices, the concept of creative agency has entered into a new debate: is 
human or AI creating the work? AI art has disrupted the anthropocentric view of the authorship and creative genius: it puts 
forward a new form of human-machine coexistence. The design of muGen is based on the concept of human-machine co-
creation. It does not intend to place either human or the AI as the sole author. Instead, they are assigned to different roles 
in the collaborative task. 
Text-to-image generation is essentially a human-guided AI system, in which the machine is tasked with interpreting 
human language in image form. In this context, the singular idea of human creative agency has dissolved, as the machine 
assumes a large portion of the creative act traditionally assigned to the human artist. Machine creativity thus becomes a 
central focus in the field of AI art. Despite certain similarities in how human artists create and how AI generates media—
both would need to collect knowledge on existing work and resource to use them as reference—they are fundamental 
different processes. While human creativity involves intuition, emotion and experience, machine learning AIs work by 
generating new media out of noise that they perceive as instances similar to the training data. The fact that machines 
possess a creative cognition so alien to humans makes their creations more intriguing, since they operate in the same 
mediums meant to be received by the human audience. This is why most artists working with AI strive to explore and 
manifest machine’s creativity with minimal human intervention. By stretching AI’s creative capacities human artists are able 
to explore novel creations and address topics concerning human-technology relationships.  
In the case of text-to-image generation, this does not negate human creativity completely—the human user is 
responsible for inputting the text prompt, which can be viewed as the ideation stage that maneuvers the direction of the 
generation. The AI covers the execution phase of the idea: the model derives its understanding of human language and 
visual representation on its training data and algorithmic architecture, for the purpose of generating images delimited by 
the text prompt. The novelty of the generation depends partly on the human user and partly on the generation mechanics. 
The task of the user is to creatively control the black-boxed AI generation: what the text query defines is creative 
constraint, an essential component in artistic creativity. The text-to-image AI, apart from being an easy solution to creative 
results for human users, should also be able inspire and stimulate ideas from the users as the initiator of the generation. 
The design of muGen, which extends the framework of existing text-to-image tools by diversifying the training data and 
user controls, is to provide an infrastructure that can help the AI better understand the intent of the user, and to facilitate 
human and machine creativity as they’re correlated in the system. 
Human artists always have to deal with existing styles and artistic conventions, and it is often the breaking and defying of 
artistic boundaries that lead to the most creative results. Through the addition of text-image datasets in different 
languages, more diverse cultural data are fed into muGen’s generation pipeline. This design aims at facilitating 
combinational creativity from the standpoints of both the human user and the machine. Combinational creativity, as 
defined by Margaret Boden, often involves a base idea and an additional idea. In theory, the further the conceptual 
distance between the two ideas, the more likely the combination will lead to novel and creative results. muGen’s 
muGen — Generative AI as Machinic Exploration of Cultural Archives 
 
incorporation of language-based data is designed to expand the AI’s scope of knowledge, so that it is better equipped at 
associating and visualizing human ideas in greater conceptual distances.  
From the standpoint of combinational creativity, the user of text-to-image model initiates a prompt that creatively 
correlates conceptually distant ideas, using their own imagination of existing cultural matrices. The system then offers its 
interpretation of the correlation, by presenting the blended visualization for the user to select and evaluate. It is a process 
in which humans and machines creatively collaborate on probing and excavating novel combinations from existing 
resources. The design intention for diversified data is to help the AI break away from a singular machinic perception, so that 
the user and the machine can communicate more efficiently and feed off each other’s creativity. 
6.1.2 Machine interpretation of cultural archives 
The design of muGen also attempts to recognize machine’s cognition as separate from humans, by extending and 
revealing the AI’s logic in its interpretation and simulation of the human cultural archives. Creative AI is a non-human 
agency that possesses human-like knowledge, based on its study of available archival records. While GANs require the user 
to curate specific sets of training data, text-to-image systems are designed to absorb as much data as possible in order to 
optimize its semantic capabilities. In a way, text-to-image AI can be considered as a speculative project: how will a non-
human entity creatively process an idea if it has access to the entire human database? There is a tension between 
generality and specificity regarding the generation: the system gains its semantic and visual understanding from massive 
internet-scale data, whereas the user needs to make the text prompt as specific and detailed as possible to create satisfying 
generations. In the case of current text-to-AI tools, this specificity is mostly delineated by the text prompt. muGen is 
designed to expand on user controls that define the specificity in the prompt. It is supposed to function as a query system 
guided by user input, which instructs the machine on where to look in the databases.  
The controls of language and time in muGen are features designed to better associate the user's idea to the execution of 
the system. This allows the user input to create correlations between databases in multiple languages, exhibiting how the 
same phrases differ in different linguistic and cultural contexts. The language control expands the scope of the dataset, and 
the time period control directs the system to specific subsets according to the user’s command. This creates a template 
with more varied and detailed controls than having to input lines of complicated descriptors as a single text prompt.  
The continuous display of generated images presents the results in parallel, randomly sorted by how much the content of 
the prompt is correlated in the dataset of each language. The display is intended to simulate search engine results, which 
might include both accurate and inaccurate representations of the prompt. The randomization setting, which distributes 
different interpretations of the text over the pages, is designed to prevent the system from conforming to a singular mode 
of interpretation. Apart from the utility of displaying novel generations, the result page can be regarded as a glimpse into 
AI’s understanding of human language and visual representation. The images, which may or may not appear accurate to the 
user’s eyes, are a reflection of both the machine’s cognition and human’s archival structures. The errors and imperfections 
in the generated images could imply imbalanced structures and misrepresentations in human’s archival footprints. The 
reverse search is a design that attempts to trace the generated image back to a particular location in the past archive, 
revealing that AI creativity is somehow correlated and embedded in the taxonomy of human memory. 
6.1.3 Reducing cultural biases in AI 
While generative AI can produce ‘apparently creative’ results to human eyes, it doesn’t possess the understanding of 
symbols, representations and cultural nuances. The internet-scraped source data of text-to-image models, intended to 
optimize the model’s performance and accuracy, is not curated to represent different cultural groups and categories in a 
fair manner. The misrepresentation in the dataset would carry over to AI’s understanding of textual terms, placing them in 
a context derived from the inherent cultural hierarchy in the data archive. The experiments in 4.1 exemplify how sampling 
bias and label bias could engender misrepresentations of minority cultures.  
Yan Yu 
Using language as control is intended as a solution to diversify the machine's understanding of the text, and avoid biases 
embedded in the dominant discourses on the English-speaking web. Diversifying the training data leads to varied visual 
correspondences of a text phrase, which would increase the robustness of the model. Rather than letting an all-
encompassing dataset determine the model’s semantic understanding, each language-specific model is designed to be 
trained independently as a means to maintain cultural specificity in the source data. Consequently, the AI’s visual 
representation of text doesn’t converge into singular and undifferentiated patterns, but are instead sensitive to 
representations in different linguistic contexts. 
6.2 Issues and possible future developments 
A practical issue that might hinder the performance of this generation pipeline is the translation of text prompt. With the 
current machine translation technology, the meaning of sophisticated words and phrases in one language would most 
certainly be lost after translation, leading to inaccurate generations. To improve the reliability of the system, more 
advanced translation mechanics would need to be in place.  
Regarding the dataset design of muGen, the choice of using internet-scale dataset for training derives from large 
language models’ requirement of high semantic capability. As a result, the biases that exist within each language-specific 
dataset can’t be eliminated, since uncurated data scraped from web archives is in itself prone to errors and prejudices. To 
make the model better represent minority cultures and subcultures, an alternative would be using curated datasets that 
represent specific cultural categories. However, the issue would be endless categorization and a GAN-like structure that 
ultimately deny the versatility of the text-to-image tool. If future AI is still based on model training, the tradeoff between 
making general-purpose and specific-purpose AI will likely remain. Rather than trying to create a comprehensive model as 
unbiased as possible, it might be more constructive for human users to be mindful of the mistakes embedded in AI’s logic, 
and put the tools to the best use according to personal need.  
The design of muGen is mainly devised at the dataset level. This left many other aspects of text-to-image AI unexamined, 
most ostensibly the impact of technical architecture. For text-to-image models, the language-visual correlator and the 
generator are the main technical components that determine the content and style of the image. This project hasn’t 
explored how these components (such as the types of generative models) affects the patterns and biases in the generation, 
which could be a direction for future research.  
Another perspective concerns the speculative nature of the project. On one hand, the project could make use of more 
practical trial-and-error approaches, and find better ways to effectively integrate user response into the design iteration. 
The interviews were able to help discuss the issues critically, but not test the intentions of the design in a concrete manner 
since the design cannot be realized. On the other hand, the project could aim at proposing a more intense speculation on 
the future of creative AI from societal perspective. Methods such as Futures Wheel or design fiction could be adopted to 
investigate the societal impact of a smarter and more accessible generative AI.  
7 CONCLUSION 
The paper investigates various kinds of cultural biases produced by text-to-image AIs, which can be traced back to how 
the training datasets are structured. To make text-to-image AI more diverse and inclusive of different cultures, the paper 
proposes the design probe muGen, a speculative system that extends user control and utilizes training data in different 
languages. The additional controls of choosing language and time period are designed to help the user better communicate 
with the system, reduce cultural and language bias, and diversify the generation. Interviews with artists are conducted and 
used as evaluation and hypothetical user study. The AI system is designed to function as a co-creator alongside the human 
artist, a cognitive machine entity that can interpret and reveal about the correlations and contradictions within the human 
cultural archive. 
muGen — Generative AI as Machinic Exploration of Cultural Archives 
 
REFERENCES 
[1] 
Margaret A. Boden. 2009. Computer Models of Creativity. AI Magazine, 30(3), 23. https://doi.org/10.1609/aimag.v30i3.2254 
[2] 
Danah Henriksen, Punya Mishra and The Deep-Play Research Group. 2018. Creativity as Invention, Discovery, Innovation and Intuition: an Interview with 
Dr. Richard Buchanan. TechTrends 62, 215–220. https://doi.org/10.1007/s11528-018-0279-4 
[3] 
Sarnoff Mednick. 1962. The associative basis of the creative process. Psychological Review, 69(3), 220–232. https://doi.org/10.1037/h0048850 
[4] 
Arthur Koestler. 1964. The Act of Creation. Penguin Books, New York. 
[5] 
Arthur I. Miller. 2019. The Artist in the Machine: The World of AI-Powered Creativity. 2019. MIT Press. 
[6] 
Bruce Buchanan. 2001. Creativity at the Metalevel: AAAI-2000 Presidential Address. AI Magazine, 22(3), 13. https://doi.org/10.1609/aimag.v22i3.1569 
[7] 
Arthur Still and Mark d’Inverno. 2019. Can Machines Be Artists? A Deweyan Response in Theory and Practice. Arts, 8(1), 36. ISSN 2076-0752. 
[8] 
Marvin Minsky. 1986. The Society of Mind. Simon and Schuster, New York. 
[9] 
Mary-Anne Mace and Tony Ward. 2002. Modeling the Creative Process: A Grounded Theory Analysis of Creativity in the Domain of Art Making, Creativity 
Research Journal, 14:2, 179-192, https://doi.org/10.1207/S15326934CRJ1402_5 
[10] Tingting Qiao, Jing Zhang, Duanqing Xu, and Dacheng Tao. 2019. Learn, imagine and create: text-to-image generation from prior knowledge. Proceedings 
of the 33rd International Conference on Neural Information Processing Systems. Curran Associates Inc., Red Hook, NY, USA, Article 80, 887–897. 
[11] Geraint A. Wiggins. 2006. Searching for computational creativity. New Generation Computing, 24, 209–222. https://doi.org/10.1007/BF03037332 
[12] Róisín Loughran and Michael O’Neill. 2016. Generative Music Evaluation: Why do We Limit to 'Human' ?  
[13] Penousal Machado, Juan Romero and Bill Manaris. 2008. Experiments in Computational Aesthetics. In: Romero, J., Machado, P. (eds) The Art of Artificial 
Evolution. Natural Computing Series. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-540-72877-1_18  
[14] David Cole, "The Chinese Room Argument", The Stanford Encyclopedia of Philosophy (Winter 2020 Edition), Edward N. Zalta (ed.). Retrieved December 
19, 2022 from https://plato.stanford.edu/archives/win2020/entries/chinese-room/ 
[15] Lev Manovich. 2019. Defining AI Arts: Three Proposals. AI and Dialog of Cultures, exhibition catalog, Hermitage Museum, Saint-Petersburg, 2019. 
[16] Margaret A. Boden and Ernest A. Edmonds. 2009. What is generative art?, Digital Creativity, 20:1-2, 21-46, http://doi.org/10.1080/14626260902867915 
[17] Louise Sundararajan. 2014. Mind, Machine, and Creativity: An Artist's Perspective. The Journal of creative behavior, 48(2), 136–151. 
https://doi.org/10.1002/jocb.44  
[18] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press. 
[19] Luciana Parisi. 2017. Reprogramming Decisionism. e-flux 85. Retrieved December 19, 2022 from https://www.e-
flux.com/journal/85/155472/reprogramming-decisionism/ 
[20] Hannu Toivonen. 2020. Computational creativity beyond machine learning. Physics of Life Reviews, vol. 34-35, pp. 52-53. 
https://doi.org/10.1016/j.plrev.2020.06.007 
[21] Kate Crawford and Trevor Paglen. 2019. Excavating AI: The Politics of Training Sets for Machine Learning. Retrieved December 19, 2022 from 
https://excavating.ai 
[22] Rebecca Fiebrink. 2019. Machine Learning Education for Artists, Musicians, and Other Creative Practitioners. ACM Trans. Comput. Educ. 19, 4, Article 31 
(December 2019), 32 pages. https://doi.org/10.1145/3294008 
[23] Birk Schmithüsen. 2019. SpeculativeAI Series. Retrieved December 19, 2022 from https://www.birkschmithuesen.com/_speculativeAI 
[24] Konstantinos Gkotzos. 2015. Google’s DeepDream: Algorithms on LSD. Retrieved December 19, 2022 from 
http://mastersofmedia.hum.uva.nl/blog/2015/10/30/googles-deepdream-algorithms-on-lsd/ 
[25] Memo Akten. 2015. #Deepdream is blowing my mind. Retrieved December 19, 2022 from https://memoakten.medium.com/deepdream-is-blowing-my-
mind-6a2c8669c698 
[26] Neural style transfer. TensorFlow tutorial. Retrieved December 19, 2022 from https://www.tensorflow.org/tutorials/generative/style_transfer 
[27] Robbie Barrat. 2018. Old Work - Landscapes And Nude Portraits. Retrieved December 19, 2022 from https://robbiebarrat.github.io/oldwork.html 
[28] Aaron Hertzmann. Visual Indeterminacy in GAN Art.Leonardo, Volume 53, Issue 4, August 2020. https://doi.org/10.48550/arXiv.1910.04639 
[29] Mario Klingemann. 2018. The Lumen Prize. Retrieved December 19, 2022 from https://www.lumenprize.com/2018winners/mario-klingemann 
[30] IBM. 2017. Q&A with an AI veteran scientist - Margaret Boden: “AI has given us a much greater understanding of the human mind.” Retrieved December 
19, 2022 from https://www.ibm.com/watson/advantage-reports/future-of-artificial-intelligence/margaret-boden.html 
[31] Neil Leach. In the mirror of AI: what is creativity?. ARIN 1, 15 (2022). https://doi.org/10.1007/s44223-022-00012-x 
[32] Ryan O'Connor. 2022. Introduction to Diffusion Models for Machine Learning. Retrieved December 19, 2022 from 
https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/ 
[33] Colin Conwell and Tomer Ullman. 2022. Testing Relational Understanding in Text-Guided Image Generation. arXiv. 
https://doi.org/10.48550/arxiv.2208.00005 
[34] Dean Kissick. 2022. The Downward Spiral: Text-to-Image. Spike Magazine. Retrieved December 19, 2022 from 
https://www.spikeartmagazine.com/?q=articles/downward-spiral-text-image 
[35] Rob Salkowitz. 2022. Midjourney Founder David Holz On The Impact Of AI On Art, Imagination And The Creative Economy. Forbes. Retrieved December 
19, 2022 from https://www.forbes.com/sites/robsalkowitz/2022/09/16/midjourney-founder-david-holz-on-the-impact-of-ai-on-art-imagination-and-the-
creative-economy/?sh=6d2f283c2d2b 
[36] Luba Elliott. CLIP Art and The New Aesthetics of AI. Right Click Save. Retrieved December 19, 2022 from https://www.rightclicksave.com/article/clip-art-
and-the-new-aesthetics-of-ai 
[37] Makoto Shing and Kei Sawada. 2022. Japanese Stable Diffusion. Retrieved December 19, 2022 from https://huggingface.co/blog/japanese-stable-
diffusion 
[38] Sber AI. 2022. ruDALL-E Malevich (XL). Retrieved December 19, 2022 from https://huggingface.co/sberbank-ai/rudalle-Malevich 
[39] Mohit Pandey. 2022. Top Used Datasets for Text to Image Synthesis Models. Retrieved December 19, 2022 from https://analyticsindiamag.com/top-used-
datasets-for-text-to-image-synthesis-models/ 
Yan Yu 
[40] Dave Gershgorn. 2017. The data that transformed AI research—and possibly the world. Quartz. Retrieved December 19, 2022 from 
https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world 
[41] Mathew Monfort et al. 2018. Moments in Time Dataset: one million videos for event understanding. https://doi.org/10.48550/arxiv.1801.03150 
[42] Christoph Schuhmann. 2022. LAION-400-MILLION Open Dataset. Retrieved December 19, 2022 from https://laion.ai/blog/laion-400-open-dataset/ 
[43] Romain Beaumont. 2022. LAION-5B: A New Era of Open Large-scale Multi-modal Datasets. Retrieved December 19, 2022 from https://laion.ai/blog/laion-
5b/ 
[44] Arjen Mulder and Joke Brouwer. 2003. Information Is Alive (Introduction). Arjen Mulder and Joke Brouwer (Ed.), Information Is Alive, V2_/NAi Publishers. 
[45] Jean-Francois Lyotard. 1984. The Postmodern Condition. Manchester University Press. 
[46] Wolfgang Ernst. 2004. The Archive as Metaphor: From Archival Space to Archival Time. Open 2004/Nr. 7/(No)Memory. 
[47] Tyler Charlton. 2017. The treachery of archives: Representation, power, and the urgency for self-reflexivity in archival arrangement and description. The 
iJournal, 3(1), 1–8.  
[48] Yasmin AlNoamany, Ahmed AlSum, Michele C. Weigle et al. Who and what links to the Internet Archive. Int J Digit Libr 14, 101–115 (2014). 
https://doi.org/10.1007/s00799-014-0111-5 
[49] Rogers, R. 2017. Doing Web history with the Internet Archive: Screencast documentaries. Internet Histories: Digital Technology, Culture and Society, 1(1-
2), 160-172. https://doi.org/10.1080/24701475.2017.1307542 
[50] Surya Bowyer. 2021. The Wayback Machine: notes on a re-enchantment. Arch Sci 21, 43–57. https://doi.org/10.1007/s10502-020-09345-w 
[51] Emanuele Arielli. 2021. Extended Aesthetics: Art and Artificial Intelligence. Vítor Moura and Connell Vaughan (Ed.), Proceedings of the European Society 
for Aesthetics, Volume 13. 
[52] Memo Akten. 2021. Deep Visual Instruments: Realtime Continuous, Meaningful Human Control over Deep Neural Networks for Creative Expression. 
Doctoral thesis, Goldsmiths, University of London [Thesis] 
[53] Agata Kik. 2019. SAM ROLFES, L’Enfant terrible of digital arts. CLOT Magazine. Retrieved December 19, 2022 from 
https://www.clotmag.com/interviews/sam-rolfes-lenfant-terrible-of-digital-arts 
[54] Scott Contreras-Koterbay and Łukasz Mirocha. 2016. The New Aesthetic and Art:Constellations of the Postdigital. 2016. Print on Demand. 
[55] Jonathan P. Bowen, Tula Giannini and Rachel Ara et al. 2019. Digital Art, Culture and Heritage: New constructs and consciousness. Electronic Visualisation 
and the Arts (EVA 2019). London 08 - 11 Jul 2019 BCS. https://doi.org/10.14236/ewic/EVA2019.1 
[56] Stephen Marche. 2022. We’re Witnessing the Birth of a New Artistic Medium. The Atlantic. Retrieved December 19, 2022 from 
https://www.theatlantic.com/technology/archive/2022/09/ai-art-generators-future/671568/ 
[57] Claudia Aradau and Mercedes Bunz. 2022. Dismantling the apparatus of domination? - Left critiques of AI. Radical Philosophy. Retrieved December 19, 
2022 from https://www.radicalphilosophy.com/article/dismantling-the-apparatus-of-domination#fn16 
[58] Ramya Srinivasan and Ajay Chander. 2021. Biases in AI systems. Commun. ACM 64, 8 (August 2021), 44–49. https://doi.org/10.1145/3464903 
[59] Ramya Srinivasan, Kanji Uchino. 2020. Biases in Generative Art -- A Causal Look from the Lens of Art History. arXiv:2010.13266. Retrieved from 
https://arxiv.org/abs/2010.13266 
[60] Abubakar Abid, Maheen Farooqi & James Zou. 2021. Large language models associate Muslims with violence. Nat Mach Intell 3, 461–463 (2021). 
https://doi.org/10.1038/s42256-021-00359-2 
[61] Wang, Jialu and Liu, Yang and Wang, Xin Eric. 2021. Are Gender-Neutral Queries Really Gender-Neutral? Mitigating Gender Bias in Image Search. 
https://doi.org/10.48550/arxiv.2109.05433 
[62] Gabriel Goh et al. 2021. Multimodal Neurons in Artificial Neural Networks. Distill. 
[63] Robert Wolfe and Aylin Caliskan. 2022. American == White in Multimodal Language-and-Image AI. In Proceedings of the 2022 AAAI/ACM Conference on 
AI, Ethics, and Society (AIES '22). Association for Computing Machinery, New York, NY, USA, 800–812. https://doi.org/10.1145/3514094.3534136 
[64] Leavy, Susan and O'Sullivan, Barry and Siapera, Eugenia. 2020. Data, Power and Bias in Artificial Intelligence. https://doi.org/10.48550/arxiv.2008.07341 
[65] Tal Feldman and Ashley Peake. 2021. End-To-End Bias Mitigation: Removing Gender Bias in Deep Learning. arXiv:2104.02532. Retrieved from 
https://arxiv.org/abs/2104.02532 
[66] Gary Marcus, Ernest Davis, Scott Aaronson. A very preliminary analysis of DALL-E 2. https://doi.org/10.48550/arXiv.2204.13807 
[67] Colin Conwell and Tomer Ullman. 2022. Testing Relational Understanding in Text-Guided Image Generation. https://doi.org/10.48550/arxiv.2208.00005 
[68] Swimmer963. What DALL-E 2 can and cannot do. Retrieved December 19, 2022 from https://www.lesswrong.com/posts/uKp6tBFStnsvrot5t/what-dall-e-
2-can-and-cannot-do#DALLE_s_weaknesses 
[69] Vivian Liu and Lydia B Chilton. 2022. Design Guidelines for Prompt Engineering Text-to-Image Generative Models. In Proceedings of the 2022 CHI 
Conference on Human Factors in Computing Systems (CHI '22). Association for Computing Machinery, New York, NY, USA, Article 384, 1–23. 
https://doi.org/10.1145/3491102.3501825 
[70] Anthony Dunne and Fiona Raby. 2013. Speculative Everything: Design, Fiction, and Social Dreaming. The MIT Press. 
[71] Betti Marenko. 2018. FutureCrafting. A Speculative Method for an Imaginative AI. AAAI Spring Symposia. 
[72] John Zimmerman, Jodi Forlizzi. 2014. Research Through Design in HCI. In: Olson J., Kellogg W. (eds) Ways of Knowing in HCI. Springer, New York, NY. 
https://doi.org/10.1007/978-1-4939-0378-8_8 
[73] James Cunning. 2005. Impressionism and its Canon. University Press of America. 
[74]  Anastasiia Raina, L. Coleman, M. Binnette, Y. Hu, D. Huang, Z. Davey, and Q. Li, “Machines Have Eyes,” in Big Data, Big Design: Why Designers Should Care 
About Artificial Intelligence, H. Armstrong, Ed. New York: Princeton Architectural Press, 2021. 
 
 
TRITA-EECS-EX-2023:749
www.kth.se 
